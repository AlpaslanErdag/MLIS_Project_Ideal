{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SGD_Classifier_with_main_data.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO/EMPr/gHyZtcw51EEp+KS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anshuman-37/MLIS_Project_Ideal/blob/main/SGD_Classifier_with_main_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATA and Stuff \n"
      ],
      "metadata": {
        "id": "O6LmdMvEbb8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## I am adding the data cleaning done by yixin here \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.style.use('ggplot')\n",
        "import zipfile\n",
        "import scipy\n",
        "\n",
        "# Pandas display options\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.max_colwidth', 500)\n",
        "pd.set_option('display.max_info_columns', 500)\n",
        "pd.set_option('display.max_info_rows', 4000)\n",
        "pd.set_option('display.expand_frame_repr', True)\n",
        "pd.set_option('display.width', 2000)\n",
        "pd.set_option('display.max_rows', 500)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "0ytTJqu3bfZq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting the data"
      ],
      "metadata": {
        "id": "vpvqEHIDqJYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = '/content/breast-cancer-wisconsin.data'"
      ],
      "metadata": {
        "id": "Dne1fwvvpa7W"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Content in the data\n",
        "with open(data) as f:\n",
        "    print(f.read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GyaslYspi0g",
        "outputId": "3d2c6c08-1f04-428f-d96b-140249ad7b07"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000025,5,1,1,1,2,1,3,1,1,2\n",
            "1002945,5,4,4,5,7,10,3,2,1,2\n",
            "1015425,3,1,1,1,2,2,3,1,1,2\n",
            "1016277,6,8,8,1,3,4,3,7,1,2\n",
            "1017023,4,1,1,3,2,1,3,1,1,2\n",
            "1017122,8,10,10,8,7,10,9,7,1,4\n",
            "1018099,1,1,1,1,2,10,3,1,1,2\n",
            "1018561,2,1,2,1,2,1,3,1,1,2\n",
            "1033078,2,1,1,1,2,1,1,1,5,2\n",
            "1033078,4,2,1,1,2,1,2,1,1,2\n",
            "1035283,1,1,1,1,1,1,3,1,1,2\n",
            "1036172,2,1,1,1,2,1,2,1,1,2\n",
            "1041801,5,3,3,3,2,3,4,4,1,4\n",
            "1043999,1,1,1,1,2,3,3,1,1,2\n",
            "1044572,8,7,5,10,7,9,5,5,4,4\n",
            "1047630,7,4,6,4,6,1,4,3,1,4\n",
            "1048672,4,1,1,1,2,1,2,1,1,2\n",
            "1049815,4,1,1,1,2,1,3,1,1,2\n",
            "1050670,10,7,7,6,4,10,4,1,2,4\n",
            "1050718,6,1,1,1,2,1,3,1,1,2\n",
            "1054590,7,3,2,10,5,10,5,4,4,4\n",
            "1054593,10,5,5,3,6,7,7,10,1,4\n",
            "1056784,3,1,1,1,2,1,2,1,1,2\n",
            "1057013,8,4,5,1,2,?,7,3,1,4\n",
            "1059552,1,1,1,1,2,1,3,1,1,2\n",
            "1065726,5,2,3,4,2,7,3,6,1,4\n",
            "1066373,3,2,1,1,1,1,2,1,1,2\n",
            "1066979,5,1,1,1,2,1,2,1,1,2\n",
            "1067444,2,1,1,1,2,1,2,1,1,2\n",
            "1070935,1,1,3,1,2,1,1,1,1,2\n",
            "1070935,3,1,1,1,1,1,2,1,1,2\n",
            "1071760,2,1,1,1,2,1,3,1,1,2\n",
            "1072179,10,7,7,3,8,5,7,4,3,4\n",
            "1074610,2,1,1,2,2,1,3,1,1,2\n",
            "1075123,3,1,2,1,2,1,2,1,1,2\n",
            "1079304,2,1,1,1,2,1,2,1,1,2\n",
            "1080185,10,10,10,8,6,1,8,9,1,4\n",
            "1081791,6,2,1,1,1,1,7,1,1,2\n",
            "1084584,5,4,4,9,2,10,5,6,1,4\n",
            "1091262,2,5,3,3,6,7,7,5,1,4\n",
            "1096800,6,6,6,9,6,?,7,8,1,2\n",
            "1099510,10,4,3,1,3,3,6,5,2,4\n",
            "1100524,6,10,10,2,8,10,7,3,3,4\n",
            "1102573,5,6,5,6,10,1,3,1,1,4\n",
            "1103608,10,10,10,4,8,1,8,10,1,4\n",
            "1103722,1,1,1,1,2,1,2,1,2,2\n",
            "1105257,3,7,7,4,4,9,4,8,1,4\n",
            "1105524,1,1,1,1,2,1,2,1,1,2\n",
            "1106095,4,1,1,3,2,1,3,1,1,2\n",
            "1106829,7,8,7,2,4,8,3,8,2,4\n",
            "1108370,9,5,8,1,2,3,2,1,5,4\n",
            "1108449,5,3,3,4,2,4,3,4,1,4\n",
            "1110102,10,3,6,2,3,5,4,10,2,4\n",
            "1110503,5,5,5,8,10,8,7,3,7,4\n",
            "1110524,10,5,5,6,8,8,7,1,1,4\n",
            "1111249,10,6,6,3,4,5,3,6,1,4\n",
            "1112209,8,10,10,1,3,6,3,9,1,4\n",
            "1113038,8,2,4,1,5,1,5,4,4,4\n",
            "1113483,5,2,3,1,6,10,5,1,1,4\n",
            "1113906,9,5,5,2,2,2,5,1,1,4\n",
            "1115282,5,3,5,5,3,3,4,10,1,4\n",
            "1115293,1,1,1,1,2,2,2,1,1,2\n",
            "1116116,9,10,10,1,10,8,3,3,1,4\n",
            "1116132,6,3,4,1,5,2,3,9,1,4\n",
            "1116192,1,1,1,1,2,1,2,1,1,2\n",
            "1116998,10,4,2,1,3,2,4,3,10,4\n",
            "1117152,4,1,1,1,2,1,3,1,1,2\n",
            "1118039,5,3,4,1,8,10,4,9,1,4\n",
            "1120559,8,3,8,3,4,9,8,9,8,4\n",
            "1121732,1,1,1,1,2,1,3,2,1,2\n",
            "1121919,5,1,3,1,2,1,2,1,1,2\n",
            "1123061,6,10,2,8,10,2,7,8,10,4\n",
            "1124651,1,3,3,2,2,1,7,2,1,2\n",
            "1125035,9,4,5,10,6,10,4,8,1,4\n",
            "1126417,10,6,4,1,3,4,3,2,3,4\n",
            "1131294,1,1,2,1,2,2,4,2,1,2\n",
            "1132347,1,1,4,1,2,1,2,1,1,2\n",
            "1133041,5,3,1,2,2,1,2,1,1,2\n",
            "1133136,3,1,1,1,2,3,3,1,1,2\n",
            "1136142,2,1,1,1,3,1,2,1,1,2\n",
            "1137156,2,2,2,1,1,1,7,1,1,2\n",
            "1143978,4,1,1,2,2,1,2,1,1,2\n",
            "1143978,5,2,1,1,2,1,3,1,1,2\n",
            "1147044,3,1,1,1,2,2,7,1,1,2\n",
            "1147699,3,5,7,8,8,9,7,10,7,4\n",
            "1147748,5,10,6,1,10,4,4,10,10,4\n",
            "1148278,3,3,6,4,5,8,4,4,1,4\n",
            "1148873,3,6,6,6,5,10,6,8,3,4\n",
            "1152331,4,1,1,1,2,1,3,1,1,2\n",
            "1155546,2,1,1,2,3,1,2,1,1,2\n",
            "1156272,1,1,1,1,2,1,3,1,1,2\n",
            "1156948,3,1,1,2,2,1,1,1,1,2\n",
            "1157734,4,1,1,1,2,1,3,1,1,2\n",
            "1158247,1,1,1,1,2,1,2,1,1,2\n",
            "1160476,2,1,1,1,2,1,3,1,1,2\n",
            "1164066,1,1,1,1,2,1,3,1,1,2\n",
            "1165297,2,1,1,2,2,1,1,1,1,2\n",
            "1165790,5,1,1,1,2,1,3,1,1,2\n",
            "1165926,9,6,9,2,10,6,2,9,10,4\n",
            "1166630,7,5,6,10,5,10,7,9,4,4\n",
            "1166654,10,3,5,1,10,5,3,10,2,4\n",
            "1167439,2,3,4,4,2,5,2,5,1,4\n",
            "1167471,4,1,2,1,2,1,3,1,1,2\n",
            "1168359,8,2,3,1,6,3,7,1,1,4\n",
            "1168736,10,10,10,10,10,1,8,8,8,4\n",
            "1169049,7,3,4,4,3,3,3,2,7,4\n",
            "1170419,10,10,10,8,2,10,4,1,1,4\n",
            "1170420,1,6,8,10,8,10,5,7,1,4\n",
            "1171710,1,1,1,1,2,1,2,3,1,2\n",
            "1171710,6,5,4,4,3,9,7,8,3,4\n",
            "1171795,1,3,1,2,2,2,5,3,2,2\n",
            "1171845,8,6,4,3,5,9,3,1,1,4\n",
            "1172152,10,3,3,10,2,10,7,3,3,4\n",
            "1173216,10,10,10,3,10,8,8,1,1,4\n",
            "1173235,3,3,2,1,2,3,3,1,1,2\n",
            "1173347,1,1,1,1,2,5,1,1,1,2\n",
            "1173347,8,3,3,1,2,2,3,2,1,2\n",
            "1173509,4,5,5,10,4,10,7,5,8,4\n",
            "1173514,1,1,1,1,4,3,1,1,1,2\n",
            "1173681,3,2,1,1,2,2,3,1,1,2\n",
            "1174057,1,1,2,2,2,1,3,1,1,2\n",
            "1174057,4,2,1,1,2,2,3,1,1,2\n",
            "1174131,10,10,10,2,10,10,5,3,3,4\n",
            "1174428,5,3,5,1,8,10,5,3,1,4\n",
            "1175937,5,4,6,7,9,7,8,10,1,4\n",
            "1176406,1,1,1,1,2,1,2,1,1,2\n",
            "1176881,7,5,3,7,4,10,7,5,5,4\n",
            "1177027,3,1,1,1,2,1,3,1,1,2\n",
            "1177399,8,3,5,4,5,10,1,6,2,4\n",
            "1177512,1,1,1,1,10,1,1,1,1,2\n",
            "1178580,5,1,3,1,2,1,2,1,1,2\n",
            "1179818,2,1,1,1,2,1,3,1,1,2\n",
            "1180194,5,10,8,10,8,10,3,6,3,4\n",
            "1180523,3,1,1,1,2,1,2,2,1,2\n",
            "1180831,3,1,1,1,3,1,2,1,1,2\n",
            "1181356,5,1,1,1,2,2,3,3,1,2\n",
            "1182404,4,1,1,1,2,1,2,1,1,2\n",
            "1182410,3,1,1,1,2,1,1,1,1,2\n",
            "1183240,4,1,2,1,2,1,2,1,1,2\n",
            "1183246,1,1,1,1,1,?,2,1,1,2\n",
            "1183516,3,1,1,1,2,1,1,1,1,2\n",
            "1183911,2,1,1,1,2,1,1,1,1,2\n",
            "1183983,9,5,5,4,4,5,4,3,3,4\n",
            "1184184,1,1,1,1,2,5,1,1,1,2\n",
            "1184241,2,1,1,1,2,1,2,1,1,2\n",
            "1184840,1,1,3,1,2,?,2,1,1,2\n",
            "1185609,3,4,5,2,6,8,4,1,1,4\n",
            "1185610,1,1,1,1,3,2,2,1,1,2\n",
            "1187457,3,1,1,3,8,1,5,8,1,2\n",
            "1187805,8,8,7,4,10,10,7,8,7,4\n",
            "1188472,1,1,1,1,1,1,3,1,1,2\n",
            "1189266,7,2,4,1,6,10,5,4,3,4\n",
            "1189286,10,10,8,6,4,5,8,10,1,4\n",
            "1190394,4,1,1,1,2,3,1,1,1,2\n",
            "1190485,1,1,1,1,2,1,1,1,1,2\n",
            "1192325,5,5,5,6,3,10,3,1,1,4\n",
            "1193091,1,2,2,1,2,1,2,1,1,2\n",
            "1193210,2,1,1,1,2,1,3,1,1,2\n",
            "1193683,1,1,2,1,3,?,1,1,1,2\n",
            "1196295,9,9,10,3,6,10,7,10,6,4\n",
            "1196915,10,7,7,4,5,10,5,7,2,4\n",
            "1197080,4,1,1,1,2,1,3,2,1,2\n",
            "1197270,3,1,1,1,2,1,3,1,1,2\n",
            "1197440,1,1,1,2,1,3,1,1,7,2\n",
            "1197510,5,1,1,1,2,?,3,1,1,2\n",
            "1197979,4,1,1,1,2,2,3,2,1,2\n",
            "1197993,5,6,7,8,8,10,3,10,3,4\n",
            "1198128,10,8,10,10,6,1,3,1,10,4\n",
            "1198641,3,1,1,1,2,1,3,1,1,2\n",
            "1199219,1,1,1,2,1,1,1,1,1,2\n",
            "1199731,3,1,1,1,2,1,1,1,1,2\n",
            "1199983,1,1,1,1,2,1,3,1,1,2\n",
            "1200772,1,1,1,1,2,1,2,1,1,2\n",
            "1200847,6,10,10,10,8,10,10,10,7,4\n",
            "1200892,8,6,5,4,3,10,6,1,1,4\n",
            "1200952,5,8,7,7,10,10,5,7,1,4\n",
            "1201834,2,1,1,1,2,1,3,1,1,2\n",
            "1201936,5,10,10,3,8,1,5,10,3,4\n",
            "1202125,4,1,1,1,2,1,3,1,1,2\n",
            "1202812,5,3,3,3,6,10,3,1,1,4\n",
            "1203096,1,1,1,1,1,1,3,1,1,2\n",
            "1204242,1,1,1,1,2,1,1,1,1,2\n",
            "1204898,6,1,1,1,2,1,3,1,1,2\n",
            "1205138,5,8,8,8,5,10,7,8,1,4\n",
            "1205579,8,7,6,4,4,10,5,1,1,4\n",
            "1206089,2,1,1,1,1,1,3,1,1,2\n",
            "1206695,1,5,8,6,5,8,7,10,1,4\n",
            "1206841,10,5,6,10,6,10,7,7,10,4\n",
            "1207986,5,8,4,10,5,8,9,10,1,4\n",
            "1208301,1,2,3,1,2,1,3,1,1,2\n",
            "1210963,10,10,10,8,6,8,7,10,1,4\n",
            "1211202,7,5,10,10,10,10,4,10,3,4\n",
            "1212232,5,1,1,1,2,1,2,1,1,2\n",
            "1212251,1,1,1,1,2,1,3,1,1,2\n",
            "1212422,3,1,1,1,2,1,3,1,1,2\n",
            "1212422,4,1,1,1,2,1,3,1,1,2\n",
            "1213375,8,4,4,5,4,7,7,8,2,2\n",
            "1213383,5,1,1,4,2,1,3,1,1,2\n",
            "1214092,1,1,1,1,2,1,1,1,1,2\n",
            "1214556,3,1,1,1,2,1,2,1,1,2\n",
            "1214966,9,7,7,5,5,10,7,8,3,4\n",
            "1216694,10,8,8,4,10,10,8,1,1,4\n",
            "1216947,1,1,1,1,2,1,3,1,1,2\n",
            "1217051,5,1,1,1,2,1,3,1,1,2\n",
            "1217264,1,1,1,1,2,1,3,1,1,2\n",
            "1218105,5,10,10,9,6,10,7,10,5,4\n",
            "1218741,10,10,9,3,7,5,3,5,1,4\n",
            "1218860,1,1,1,1,1,1,3,1,1,2\n",
            "1218860,1,1,1,1,1,1,3,1,1,2\n",
            "1219406,5,1,1,1,1,1,3,1,1,2\n",
            "1219525,8,10,10,10,5,10,8,10,6,4\n",
            "1219859,8,10,8,8,4,8,7,7,1,4\n",
            "1220330,1,1,1,1,2,1,3,1,1,2\n",
            "1221863,10,10,10,10,7,10,7,10,4,4\n",
            "1222047,10,10,10,10,3,10,10,6,1,4\n",
            "1222936,8,7,8,7,5,5,5,10,2,4\n",
            "1223282,1,1,1,1,2,1,2,1,1,2\n",
            "1223426,1,1,1,1,2,1,3,1,1,2\n",
            "1223793,6,10,7,7,6,4,8,10,2,4\n",
            "1223967,6,1,3,1,2,1,3,1,1,2\n",
            "1224329,1,1,1,2,2,1,3,1,1,2\n",
            "1225799,10,6,4,3,10,10,9,10,1,4\n",
            "1226012,4,1,1,3,1,5,2,1,1,4\n",
            "1226612,7,5,6,3,3,8,7,4,1,4\n",
            "1227210,10,5,5,6,3,10,7,9,2,4\n",
            "1227244,1,1,1,1,2,1,2,1,1,2\n",
            "1227481,10,5,7,4,4,10,8,9,1,4\n",
            "1228152,8,9,9,5,3,5,7,7,1,4\n",
            "1228311,1,1,1,1,1,1,3,1,1,2\n",
            "1230175,10,10,10,3,10,10,9,10,1,4\n",
            "1230688,7,4,7,4,3,7,7,6,1,4\n",
            "1231387,6,8,7,5,6,8,8,9,2,4\n",
            "1231706,8,4,6,3,3,1,4,3,1,2\n",
            "1232225,10,4,5,5,5,10,4,1,1,4\n",
            "1236043,3,3,2,1,3,1,3,6,1,2\n",
            "1241232,3,1,4,1,2,?,3,1,1,2\n",
            "1241559,10,8,8,2,8,10,4,8,10,4\n",
            "1241679,9,8,8,5,6,2,4,10,4,4\n",
            "1242364,8,10,10,8,6,9,3,10,10,4\n",
            "1243256,10,4,3,2,3,10,5,3,2,4\n",
            "1270479,5,1,3,3,2,2,2,3,1,2\n",
            "1276091,3,1,1,3,1,1,3,1,1,2\n",
            "1277018,2,1,1,1,2,1,3,1,1,2\n",
            "128059,1,1,1,1,2,5,5,1,1,2\n",
            "1285531,1,1,1,1,2,1,3,1,1,2\n",
            "1287775,5,1,1,2,2,2,3,1,1,2\n",
            "144888,8,10,10,8,5,10,7,8,1,4\n",
            "145447,8,4,4,1,2,9,3,3,1,4\n",
            "167528,4,1,1,1,2,1,3,6,1,2\n",
            "169356,3,1,1,1,2,?,3,1,1,2\n",
            "183913,1,2,2,1,2,1,1,1,1,2\n",
            "191250,10,4,4,10,2,10,5,3,3,4\n",
            "1017023,6,3,3,5,3,10,3,5,3,2\n",
            "1100524,6,10,10,2,8,10,7,3,3,4\n",
            "1116116,9,10,10,1,10,8,3,3,1,4\n",
            "1168736,5,6,6,2,4,10,3,6,1,4\n",
            "1182404,3,1,1,1,2,1,1,1,1,2\n",
            "1182404,3,1,1,1,2,1,2,1,1,2\n",
            "1198641,3,1,1,1,2,1,3,1,1,2\n",
            "242970,5,7,7,1,5,8,3,4,1,2\n",
            "255644,10,5,8,10,3,10,5,1,3,4\n",
            "263538,5,10,10,6,10,10,10,6,5,4\n",
            "274137,8,8,9,4,5,10,7,8,1,4\n",
            "303213,10,4,4,10,6,10,5,5,1,4\n",
            "314428,7,9,4,10,10,3,5,3,3,4\n",
            "1182404,5,1,4,1,2,1,3,2,1,2\n",
            "1198641,10,10,6,3,3,10,4,3,2,4\n",
            "320675,3,3,5,2,3,10,7,1,1,4\n",
            "324427,10,8,8,2,3,4,8,7,8,4\n",
            "385103,1,1,1,1,2,1,3,1,1,2\n",
            "390840,8,4,7,1,3,10,3,9,2,4\n",
            "411453,5,1,1,1,2,1,3,1,1,2\n",
            "320675,3,3,5,2,3,10,7,1,1,4\n",
            "428903,7,2,4,1,3,4,3,3,1,4\n",
            "431495,3,1,1,1,2,1,3,2,1,2\n",
            "432809,3,1,3,1,2,?,2,1,1,2\n",
            "434518,3,1,1,1,2,1,2,1,1,2\n",
            "452264,1,1,1,1,2,1,2,1,1,2\n",
            "456282,1,1,1,1,2,1,3,1,1,2\n",
            "476903,10,5,7,3,3,7,3,3,8,4\n",
            "486283,3,1,1,1,2,1,3,1,1,2\n",
            "486662,2,1,1,2,2,1,3,1,1,2\n",
            "488173,1,4,3,10,4,10,5,6,1,4\n",
            "492268,10,4,6,1,2,10,5,3,1,4\n",
            "508234,7,4,5,10,2,10,3,8,2,4\n",
            "527363,8,10,10,10,8,10,10,7,3,4\n",
            "529329,10,10,10,10,10,10,4,10,10,4\n",
            "535331,3,1,1,1,3,1,2,1,1,2\n",
            "543558,6,1,3,1,4,5,5,10,1,4\n",
            "555977,5,6,6,8,6,10,4,10,4,4\n",
            "560680,1,1,1,1,2,1,1,1,1,2\n",
            "561477,1,1,1,1,2,1,3,1,1,2\n",
            "563649,8,8,8,1,2,?,6,10,1,4\n",
            "601265,10,4,4,6,2,10,2,3,1,4\n",
            "606140,1,1,1,1,2,?,2,1,1,2\n",
            "606722,5,5,7,8,6,10,7,4,1,4\n",
            "616240,5,3,4,3,4,5,4,7,1,2\n",
            "61634,5,4,3,1,2,?,2,3,1,2\n",
            "625201,8,2,1,1,5,1,1,1,1,2\n",
            "63375,9,1,2,6,4,10,7,7,2,4\n",
            "635844,8,4,10,5,4,4,7,10,1,4\n",
            "636130,1,1,1,1,2,1,3,1,1,2\n",
            "640744,10,10,10,7,9,10,7,10,10,4\n",
            "646904,1,1,1,1,2,1,3,1,1,2\n",
            "653777,8,3,4,9,3,10,3,3,1,4\n",
            "659642,10,8,4,4,4,10,3,10,4,4\n",
            "666090,1,1,1,1,2,1,3,1,1,2\n",
            "666942,1,1,1,1,2,1,3,1,1,2\n",
            "667204,7,8,7,6,4,3,8,8,4,4\n",
            "673637,3,1,1,1,2,5,5,1,1,2\n",
            "684955,2,1,1,1,3,1,2,1,1,2\n",
            "688033,1,1,1,1,2,1,1,1,1,2\n",
            "691628,8,6,4,10,10,1,3,5,1,4\n",
            "693702,1,1,1,1,2,1,1,1,1,2\n",
            "704097,1,1,1,1,1,1,2,1,1,2\n",
            "704168,4,6,5,6,7,?,4,9,1,2\n",
            "706426,5,5,5,2,5,10,4,3,1,4\n",
            "709287,6,8,7,8,6,8,8,9,1,4\n",
            "718641,1,1,1,1,5,1,3,1,1,2\n",
            "721482,4,4,4,4,6,5,7,3,1,2\n",
            "730881,7,6,3,2,5,10,7,4,6,4\n",
            "733639,3,1,1,1,2,?,3,1,1,2\n",
            "733639,3,1,1,1,2,1,3,1,1,2\n",
            "733823,5,4,6,10,2,10,4,1,1,4\n",
            "740492,1,1,1,1,2,1,3,1,1,2\n",
            "743348,3,2,2,1,2,1,2,3,1,2\n",
            "752904,10,1,1,1,2,10,5,4,1,4\n",
            "756136,1,1,1,1,2,1,2,1,1,2\n",
            "760001,8,10,3,2,6,4,3,10,1,4\n",
            "760239,10,4,6,4,5,10,7,1,1,4\n",
            "76389,10,4,7,2,2,8,6,1,1,4\n",
            "764974,5,1,1,1,2,1,3,1,2,2\n",
            "770066,5,2,2,2,2,1,2,2,1,2\n",
            "785208,5,4,6,6,4,10,4,3,1,4\n",
            "785615,8,6,7,3,3,10,3,4,2,4\n",
            "792744,1,1,1,1,2,1,1,1,1,2\n",
            "797327,6,5,5,8,4,10,3,4,1,4\n",
            "798429,1,1,1,1,2,1,3,1,1,2\n",
            "704097,1,1,1,1,1,1,2,1,1,2\n",
            "806423,8,5,5,5,2,10,4,3,1,4\n",
            "809912,10,3,3,1,2,10,7,6,1,4\n",
            "810104,1,1,1,1,2,1,3,1,1,2\n",
            "814265,2,1,1,1,2,1,1,1,1,2\n",
            "814911,1,1,1,1,2,1,1,1,1,2\n",
            "822829,7,6,4,8,10,10,9,5,3,4\n",
            "826923,1,1,1,1,2,1,1,1,1,2\n",
            "830690,5,2,2,2,3,1,1,3,1,2\n",
            "831268,1,1,1,1,1,1,1,3,1,2\n",
            "832226,3,4,4,10,5,1,3,3,1,4\n",
            "832567,4,2,3,5,3,8,7,6,1,4\n",
            "836433,5,1,1,3,2,1,1,1,1,2\n",
            "837082,2,1,1,1,2,1,3,1,1,2\n",
            "846832,3,4,5,3,7,3,4,6,1,2\n",
            "850831,2,7,10,10,7,10,4,9,4,4\n",
            "855524,1,1,1,1,2,1,2,1,1,2\n",
            "857774,4,1,1,1,3,1,2,2,1,2\n",
            "859164,5,3,3,1,3,3,3,3,3,4\n",
            "859350,8,10,10,7,10,10,7,3,8,4\n",
            "866325,8,10,5,3,8,4,4,10,3,4\n",
            "873549,10,3,5,4,3,7,3,5,3,4\n",
            "877291,6,10,10,10,10,10,8,10,10,4\n",
            "877943,3,10,3,10,6,10,5,1,4,4\n",
            "888169,3,2,2,1,4,3,2,1,1,2\n",
            "888523,4,4,4,2,2,3,2,1,1,2\n",
            "896404,2,1,1,1,2,1,3,1,1,2\n",
            "897172,2,1,1,1,2,1,2,1,1,2\n",
            "95719,6,10,10,10,8,10,7,10,7,4\n",
            "160296,5,8,8,10,5,10,8,10,3,4\n",
            "342245,1,1,3,1,2,1,1,1,1,2\n",
            "428598,1,1,3,1,1,1,2,1,1,2\n",
            "492561,4,3,2,1,3,1,2,1,1,2\n",
            "493452,1,1,3,1,2,1,1,1,1,2\n",
            "493452,4,1,2,1,2,1,2,1,1,2\n",
            "521441,5,1,1,2,2,1,2,1,1,2\n",
            "560680,3,1,2,1,2,1,2,1,1,2\n",
            "636437,1,1,1,1,2,1,1,1,1,2\n",
            "640712,1,1,1,1,2,1,2,1,1,2\n",
            "654244,1,1,1,1,1,1,2,1,1,2\n",
            "657753,3,1,1,4,3,1,2,2,1,2\n",
            "685977,5,3,4,1,4,1,3,1,1,2\n",
            "805448,1,1,1,1,2,1,1,1,1,2\n",
            "846423,10,6,3,6,4,10,7,8,4,4\n",
            "1002504,3,2,2,2,2,1,3,2,1,2\n",
            "1022257,2,1,1,1,2,1,1,1,1,2\n",
            "1026122,2,1,1,1,2,1,1,1,1,2\n",
            "1071084,3,3,2,2,3,1,1,2,3,2\n",
            "1080233,7,6,6,3,2,10,7,1,1,4\n",
            "1114570,5,3,3,2,3,1,3,1,1,2\n",
            "1114570,2,1,1,1,2,1,2,2,1,2\n",
            "1116715,5,1,1,1,3,2,2,2,1,2\n",
            "1131411,1,1,1,2,2,1,2,1,1,2\n",
            "1151734,10,8,7,4,3,10,7,9,1,4\n",
            "1156017,3,1,1,1,2,1,2,1,1,2\n",
            "1158247,1,1,1,1,1,1,1,1,1,2\n",
            "1158405,1,2,3,1,2,1,2,1,1,2\n",
            "1168278,3,1,1,1,2,1,2,1,1,2\n",
            "1176187,3,1,1,1,2,1,3,1,1,2\n",
            "1196263,4,1,1,1,2,1,1,1,1,2\n",
            "1196475,3,2,1,1,2,1,2,2,1,2\n",
            "1206314,1,2,3,1,2,1,1,1,1,2\n",
            "1211265,3,10,8,7,6,9,9,3,8,4\n",
            "1213784,3,1,1,1,2,1,1,1,1,2\n",
            "1223003,5,3,3,1,2,1,2,1,1,2\n",
            "1223306,3,1,1,1,2,4,1,1,1,2\n",
            "1223543,1,2,1,3,2,1,1,2,1,2\n",
            "1229929,1,1,1,1,2,1,2,1,1,2\n",
            "1231853,4,2,2,1,2,1,2,1,1,2\n",
            "1234554,1,1,1,1,2,1,2,1,1,2\n",
            "1236837,2,3,2,2,2,2,3,1,1,2\n",
            "1237674,3,1,2,1,2,1,2,1,1,2\n",
            "1238021,1,1,1,1,2,1,2,1,1,2\n",
            "1238464,1,1,1,1,1,?,2,1,1,2\n",
            "1238633,10,10,10,6,8,4,8,5,1,4\n",
            "1238915,5,1,2,1,2,1,3,1,1,2\n",
            "1238948,8,5,6,2,3,10,6,6,1,4\n",
            "1239232,3,3,2,6,3,3,3,5,1,2\n",
            "1239347,8,7,8,5,10,10,7,2,1,4\n",
            "1239967,1,1,1,1,2,1,2,1,1,2\n",
            "1240337,5,2,2,2,2,2,3,2,2,2\n",
            "1253505,2,3,1,1,5,1,1,1,1,2\n",
            "1255384,3,2,2,3,2,3,3,1,1,2\n",
            "1257200,10,10,10,7,10,10,8,2,1,4\n",
            "1257648,4,3,3,1,2,1,3,3,1,2\n",
            "1257815,5,1,3,1,2,1,2,1,1,2\n",
            "1257938,3,1,1,1,2,1,1,1,1,2\n",
            "1258549,9,10,10,10,10,10,10,10,1,4\n",
            "1258556,5,3,6,1,2,1,1,1,1,2\n",
            "1266154,8,7,8,2,4,2,5,10,1,4\n",
            "1272039,1,1,1,1,2,1,2,1,1,2\n",
            "1276091,2,1,1,1,2,1,2,1,1,2\n",
            "1276091,1,3,1,1,2,1,2,2,1,2\n",
            "1276091,5,1,1,3,4,1,3,2,1,2\n",
            "1277629,5,1,1,1,2,1,2,2,1,2\n",
            "1293439,3,2,2,3,2,1,1,1,1,2\n",
            "1293439,6,9,7,5,5,8,4,2,1,2\n",
            "1294562,10,8,10,1,3,10,5,1,1,4\n",
            "1295186,10,10,10,1,6,1,2,8,1,4\n",
            "527337,4,1,1,1,2,1,1,1,1,2\n",
            "558538,4,1,3,3,2,1,1,1,1,2\n",
            "566509,5,1,1,1,2,1,1,1,1,2\n",
            "608157,10,4,3,10,4,10,10,1,1,4\n",
            "677910,5,2,2,4,2,4,1,1,1,2\n",
            "734111,1,1,1,3,2,3,1,1,1,2\n",
            "734111,1,1,1,1,2,2,1,1,1,2\n",
            "780555,5,1,1,6,3,1,2,1,1,2\n",
            "827627,2,1,1,1,2,1,1,1,1,2\n",
            "1049837,1,1,1,1,2,1,1,1,1,2\n",
            "1058849,5,1,1,1,2,1,1,1,1,2\n",
            "1182404,1,1,1,1,1,1,1,1,1,2\n",
            "1193544,5,7,9,8,6,10,8,10,1,4\n",
            "1201870,4,1,1,3,1,1,2,1,1,2\n",
            "1202253,5,1,1,1,2,1,1,1,1,2\n",
            "1227081,3,1,1,3,2,1,1,1,1,2\n",
            "1230994,4,5,5,8,6,10,10,7,1,4\n",
            "1238410,2,3,1,1,3,1,1,1,1,2\n",
            "1246562,10,2,2,1,2,6,1,1,2,4\n",
            "1257470,10,6,5,8,5,10,8,6,1,4\n",
            "1259008,8,8,9,6,6,3,10,10,1,4\n",
            "1266124,5,1,2,1,2,1,1,1,1,2\n",
            "1267898,5,1,3,1,2,1,1,1,1,2\n",
            "1268313,5,1,1,3,2,1,1,1,1,2\n",
            "1268804,3,1,1,1,2,5,1,1,1,2\n",
            "1276091,6,1,1,3,2,1,1,1,1,2\n",
            "1280258,4,1,1,1,2,1,1,2,1,2\n",
            "1293966,4,1,1,1,2,1,1,1,1,2\n",
            "1296572,10,9,8,7,6,4,7,10,3,4\n",
            "1298416,10,6,6,2,4,10,9,7,1,4\n",
            "1299596,6,6,6,5,4,10,7,6,2,4\n",
            "1105524,4,1,1,1,2,1,1,1,1,2\n",
            "1181685,1,1,2,1,2,1,2,1,1,2\n",
            "1211594,3,1,1,1,1,1,2,1,1,2\n",
            "1238777,6,1,1,3,2,1,1,1,1,2\n",
            "1257608,6,1,1,1,1,1,1,1,1,2\n",
            "1269574,4,1,1,1,2,1,1,1,1,2\n",
            "1277145,5,1,1,1,2,1,1,1,1,2\n",
            "1287282,3,1,1,1,2,1,1,1,1,2\n",
            "1296025,4,1,2,1,2,1,1,1,1,2\n",
            "1296263,4,1,1,1,2,1,1,1,1,2\n",
            "1296593,5,2,1,1,2,1,1,1,1,2\n",
            "1299161,4,8,7,10,4,10,7,5,1,4\n",
            "1301945,5,1,1,1,1,1,1,1,1,2\n",
            "1302428,5,3,2,4,2,1,1,1,1,2\n",
            "1318169,9,10,10,10,10,5,10,10,10,4\n",
            "474162,8,7,8,5,5,10,9,10,1,4\n",
            "787451,5,1,2,1,2,1,1,1,1,2\n",
            "1002025,1,1,1,3,1,3,1,1,1,2\n",
            "1070522,3,1,1,1,1,1,2,1,1,2\n",
            "1073960,10,10,10,10,6,10,8,1,5,4\n",
            "1076352,3,6,4,10,3,3,3,4,1,4\n",
            "1084139,6,3,2,1,3,4,4,1,1,4\n",
            "1115293,1,1,1,1,2,1,1,1,1,2\n",
            "1119189,5,8,9,4,3,10,7,1,1,4\n",
            "1133991,4,1,1,1,1,1,2,1,1,2\n",
            "1142706,5,10,10,10,6,10,6,5,2,4\n",
            "1155967,5,1,2,10,4,5,2,1,1,2\n",
            "1170945,3,1,1,1,1,1,2,1,1,2\n",
            "1181567,1,1,1,1,1,1,1,1,1,2\n",
            "1182404,4,2,1,1,2,1,1,1,1,2\n",
            "1204558,4,1,1,1,2,1,2,1,1,2\n",
            "1217952,4,1,1,1,2,1,2,1,1,2\n",
            "1224565,6,1,1,1,2,1,3,1,1,2\n",
            "1238186,4,1,1,1,2,1,2,1,1,2\n",
            "1253917,4,1,1,2,2,1,2,1,1,2\n",
            "1265899,4,1,1,1,2,1,3,1,1,2\n",
            "1268766,1,1,1,1,2,1,1,1,1,2\n",
            "1277268,3,3,1,1,2,1,1,1,1,2\n",
            "1286943,8,10,10,10,7,5,4,8,7,4\n",
            "1295508,1,1,1,1,2,4,1,1,1,2\n",
            "1297327,5,1,1,1,2,1,1,1,1,2\n",
            "1297522,2,1,1,1,2,1,1,1,1,2\n",
            "1298360,1,1,1,1,2,1,1,1,1,2\n",
            "1299924,5,1,1,1,2,1,2,1,1,2\n",
            "1299994,5,1,1,1,2,1,1,1,1,2\n",
            "1304595,3,1,1,1,1,1,2,1,1,2\n",
            "1306282,6,6,7,10,3,10,8,10,2,4\n",
            "1313325,4,10,4,7,3,10,9,10,1,4\n",
            "1320077,1,1,1,1,1,1,1,1,1,2\n",
            "1320077,1,1,1,1,1,1,2,1,1,2\n",
            "1320304,3,1,2,2,2,1,1,1,1,2\n",
            "1330439,4,7,8,3,4,10,9,1,1,4\n",
            "333093,1,1,1,1,3,1,1,1,1,2\n",
            "369565,4,1,1,1,3,1,1,1,1,2\n",
            "412300,10,4,5,4,3,5,7,3,1,4\n",
            "672113,7,5,6,10,4,10,5,3,1,4\n",
            "749653,3,1,1,1,2,1,2,1,1,2\n",
            "769612,3,1,1,2,2,1,1,1,1,2\n",
            "769612,4,1,1,1,2,1,1,1,1,2\n",
            "798429,4,1,1,1,2,1,3,1,1,2\n",
            "807657,6,1,3,2,2,1,1,1,1,2\n",
            "8233704,4,1,1,1,1,1,2,1,1,2\n",
            "837480,7,4,4,3,4,10,6,9,1,4\n",
            "867392,4,2,2,1,2,1,2,1,1,2\n",
            "869828,1,1,1,1,1,1,3,1,1,2\n",
            "1043068,3,1,1,1,2,1,2,1,1,2\n",
            "1056171,2,1,1,1,2,1,2,1,1,2\n",
            "1061990,1,1,3,2,2,1,3,1,1,2\n",
            "1113061,5,1,1,1,2,1,3,1,1,2\n",
            "1116192,5,1,2,1,2,1,3,1,1,2\n",
            "1135090,4,1,1,1,2,1,2,1,1,2\n",
            "1145420,6,1,1,1,2,1,2,1,1,2\n",
            "1158157,5,1,1,1,2,2,2,1,1,2\n",
            "1171578,3,1,1,1,2,1,1,1,1,2\n",
            "1174841,5,3,1,1,2,1,1,1,1,2\n",
            "1184586,4,1,1,1,2,1,2,1,1,2\n",
            "1186936,2,1,3,2,2,1,2,1,1,2\n",
            "1197527,5,1,1,1,2,1,2,1,1,2\n",
            "1222464,6,10,10,10,4,10,7,10,1,4\n",
            "1240603,2,1,1,1,1,1,1,1,1,2\n",
            "1240603,3,1,1,1,1,1,1,1,1,2\n",
            "1241035,7,8,3,7,4,5,7,8,2,4\n",
            "1287971,3,1,1,1,2,1,2,1,1,2\n",
            "1289391,1,1,1,1,2,1,3,1,1,2\n",
            "1299924,3,2,2,2,2,1,4,2,1,2\n",
            "1306339,4,4,2,1,2,5,2,1,2,2\n",
            "1313658,3,1,1,1,2,1,1,1,1,2\n",
            "1313982,4,3,1,1,2,1,4,8,1,2\n",
            "1321264,5,2,2,2,1,1,2,1,1,2\n",
            "1321321,5,1,1,3,2,1,1,1,1,2\n",
            "1321348,2,1,1,1,2,1,2,1,1,2\n",
            "1321931,5,1,1,1,2,1,2,1,1,2\n",
            "1321942,5,1,1,1,2,1,3,1,1,2\n",
            "1321942,5,1,1,1,2,1,3,1,1,2\n",
            "1328331,1,1,1,1,2,1,3,1,1,2\n",
            "1328755,3,1,1,1,2,1,2,1,1,2\n",
            "1331405,4,1,1,1,2,1,3,2,1,2\n",
            "1331412,5,7,10,10,5,10,10,10,1,4\n",
            "1333104,3,1,2,1,2,1,3,1,1,2\n",
            "1334071,4,1,1,1,2,3,2,1,1,2\n",
            "1343068,8,4,4,1,6,10,2,5,2,4\n",
            "1343374,10,10,8,10,6,5,10,3,1,4\n",
            "1344121,8,10,4,4,8,10,8,2,1,4\n",
            "142932,7,6,10,5,3,10,9,10,2,4\n",
            "183936,3,1,1,1,2,1,2,1,1,2\n",
            "324382,1,1,1,1,2,1,2,1,1,2\n",
            "378275,10,9,7,3,4,2,7,7,1,4\n",
            "385103,5,1,2,1,2,1,3,1,1,2\n",
            "690557,5,1,1,1,2,1,2,1,1,2\n",
            "695091,1,1,1,1,2,1,2,1,1,2\n",
            "695219,1,1,1,1,2,1,2,1,1,2\n",
            "824249,1,1,1,1,2,1,3,1,1,2\n",
            "871549,5,1,2,1,2,1,2,1,1,2\n",
            "878358,5,7,10,6,5,10,7,5,1,4\n",
            "1107684,6,10,5,5,4,10,6,10,1,4\n",
            "1115762,3,1,1,1,2,1,1,1,1,2\n",
            "1217717,5,1,1,6,3,1,1,1,1,2\n",
            "1239420,1,1,1,1,2,1,1,1,1,2\n",
            "1254538,8,10,10,10,6,10,10,10,1,4\n",
            "1261751,5,1,1,1,2,1,2,2,1,2\n",
            "1268275,9,8,8,9,6,3,4,1,1,4\n",
            "1272166,5,1,1,1,2,1,1,1,1,2\n",
            "1294261,4,10,8,5,4,1,10,1,1,4\n",
            "1295529,2,5,7,6,4,10,7,6,1,4\n",
            "1298484,10,3,4,5,3,10,4,1,1,4\n",
            "1311875,5,1,2,1,2,1,1,1,1,2\n",
            "1315506,4,8,6,3,4,10,7,1,1,4\n",
            "1320141,5,1,1,1,2,1,2,1,1,2\n",
            "1325309,4,1,2,1,2,1,2,1,1,2\n",
            "1333063,5,1,3,1,2,1,3,1,1,2\n",
            "1333495,3,1,1,1,2,1,2,1,1,2\n",
            "1334659,5,2,4,1,1,1,1,1,1,2\n",
            "1336798,3,1,1,1,2,1,2,1,1,2\n",
            "1344449,1,1,1,1,1,1,2,1,1,2\n",
            "1350568,4,1,1,1,2,1,2,1,1,2\n",
            "1352663,5,4,6,8,4,1,8,10,1,4\n",
            "188336,5,3,2,8,5,10,8,1,2,4\n",
            "352431,10,5,10,3,5,8,7,8,3,4\n",
            "353098,4,1,1,2,2,1,1,1,1,2\n",
            "411453,1,1,1,1,2,1,1,1,1,2\n",
            "557583,5,10,10,10,10,10,10,1,1,4\n",
            "636375,5,1,1,1,2,1,1,1,1,2\n",
            "736150,10,4,3,10,3,10,7,1,2,4\n",
            "803531,5,10,10,10,5,2,8,5,1,4\n",
            "822829,8,10,10,10,6,10,10,10,10,4\n",
            "1016634,2,3,1,1,2,1,2,1,1,2\n",
            "1031608,2,1,1,1,1,1,2,1,1,2\n",
            "1041043,4,1,3,1,2,1,2,1,1,2\n",
            "1042252,3,1,1,1,2,1,2,1,1,2\n",
            "1057067,1,1,1,1,1,?,1,1,1,2\n",
            "1061990,4,1,1,1,2,1,2,1,1,2\n",
            "1073836,5,1,1,1,2,1,2,1,1,2\n",
            "1083817,3,1,1,1,2,1,2,1,1,2\n",
            "1096352,6,3,3,3,3,2,6,1,1,2\n",
            "1140597,7,1,2,3,2,1,2,1,1,2\n",
            "1149548,1,1,1,1,2,1,1,1,1,2\n",
            "1174009,5,1,1,2,1,1,2,1,1,2\n",
            "1183596,3,1,3,1,3,4,1,1,1,2\n",
            "1190386,4,6,6,5,7,6,7,7,3,4\n",
            "1190546,2,1,1,1,2,5,1,1,1,2\n",
            "1213273,2,1,1,1,2,1,1,1,1,2\n",
            "1218982,4,1,1,1,2,1,1,1,1,2\n",
            "1225382,6,2,3,1,2,1,1,1,1,2\n",
            "1235807,5,1,1,1,2,1,2,1,1,2\n",
            "1238777,1,1,1,1,2,1,1,1,1,2\n",
            "1253955,8,7,4,4,5,3,5,10,1,4\n",
            "1257366,3,1,1,1,2,1,1,1,1,2\n",
            "1260659,3,1,4,1,2,1,1,1,1,2\n",
            "1268952,10,10,7,8,7,1,10,10,3,4\n",
            "1275807,4,2,4,3,2,2,2,1,1,2\n",
            "1277792,4,1,1,1,2,1,1,1,1,2\n",
            "1277792,5,1,1,3,2,1,1,1,1,2\n",
            "1285722,4,1,1,3,2,1,1,1,1,2\n",
            "1288608,3,1,1,1,2,1,2,1,1,2\n",
            "1290203,3,1,1,1,2,1,2,1,1,2\n",
            "1294413,1,1,1,1,2,1,1,1,1,2\n",
            "1299596,2,1,1,1,2,1,1,1,1,2\n",
            "1303489,3,1,1,1,2,1,2,1,1,2\n",
            "1311033,1,2,2,1,2,1,1,1,1,2\n",
            "1311108,1,1,1,3,2,1,1,1,1,2\n",
            "1315807,5,10,10,10,10,2,10,10,10,4\n",
            "1318671,3,1,1,1,2,1,2,1,1,2\n",
            "1319609,3,1,1,2,3,4,1,1,1,2\n",
            "1323477,1,2,1,3,2,1,2,1,1,2\n",
            "1324572,5,1,1,1,2,1,2,2,1,2\n",
            "1324681,4,1,1,1,2,1,2,1,1,2\n",
            "1325159,3,1,1,1,2,1,3,1,1,2\n",
            "1326892,3,1,1,1,2,1,2,1,1,2\n",
            "1330361,5,1,1,1,2,1,2,1,1,2\n",
            "1333877,5,4,5,1,8,1,3,6,1,2\n",
            "1334015,7,8,8,7,3,10,7,2,3,4\n",
            "1334667,1,1,1,1,2,1,1,1,1,2\n",
            "1339781,1,1,1,1,2,1,2,1,1,2\n",
            "1339781,4,1,1,1,2,1,3,1,1,2\n",
            "13454352,1,1,3,1,2,1,2,1,1,2\n",
            "1345452,1,1,3,1,2,1,2,1,1,2\n",
            "1345593,3,1,1,3,2,1,2,1,1,2\n",
            "1347749,1,1,1,1,2,1,1,1,1,2\n",
            "1347943,5,2,2,2,2,1,1,1,2,2\n",
            "1348851,3,1,1,1,2,1,3,1,1,2\n",
            "1350319,5,7,4,1,6,1,7,10,3,4\n",
            "1350423,5,10,10,8,5,5,7,10,1,4\n",
            "1352848,3,10,7,8,5,8,7,4,1,4\n",
            "1353092,3,2,1,2,2,1,3,1,1,2\n",
            "1354840,2,1,1,1,2,1,3,1,1,2\n",
            "1354840,5,3,2,1,3,1,1,1,1,2\n",
            "1355260,1,1,1,1,2,1,2,1,1,2\n",
            "1365075,4,1,4,1,2,1,1,1,1,2\n",
            "1365328,1,1,2,1,2,1,2,1,1,2\n",
            "1368267,5,1,1,1,2,1,1,1,1,2\n",
            "1368273,1,1,1,1,2,1,1,1,1,2\n",
            "1368882,2,1,1,1,2,1,1,1,1,2\n",
            "1369821,10,10,10,10,5,10,10,10,7,4\n",
            "1371026,5,10,10,10,4,10,5,6,3,4\n",
            "1371920,5,1,1,1,2,1,3,2,1,2\n",
            "466906,1,1,1,1,2,1,1,1,1,2\n",
            "466906,1,1,1,1,2,1,1,1,1,2\n",
            "534555,1,1,1,1,2,1,1,1,1,2\n",
            "536708,1,1,1,1,2,1,1,1,1,2\n",
            "566346,3,1,1,1,2,1,2,3,1,2\n",
            "603148,4,1,1,1,2,1,1,1,1,2\n",
            "654546,1,1,1,1,2,1,1,1,8,2\n",
            "654546,1,1,1,3,2,1,1,1,1,2\n",
            "695091,5,10,10,5,4,5,4,4,1,4\n",
            "714039,3,1,1,1,2,1,1,1,1,2\n",
            "763235,3,1,1,1,2,1,2,1,2,2\n",
            "776715,3,1,1,1,3,2,1,1,1,2\n",
            "841769,2,1,1,1,2,1,1,1,1,2\n",
            "888820,5,10,10,3,7,3,8,10,2,4\n",
            "897471,4,8,6,4,3,4,10,6,1,4\n",
            "897471,4,8,8,5,4,5,10,4,1,4\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setting the columns names that will be used for the data visualization\n",
        "col_name = ['Samplecodenumber','ClumpThickness','UniformityofCellSize','UniformityofCellShape',\n",
        "            'MarginalAdhesion','SingleEpithelialCellSize','BareNuclei',\n",
        "            'BlandChromatin','NormalNucleoli','Mitoses','Class']\n",
        "cancerdata = pd.read_csv(data,low_memory=False,names=col_name)\n",
        "cancerdata.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "s6cpcXIVpi3U",
        "outputId": "2a504abc-93b0-4968-b5b0-7b6327b09ebd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b06c4f4d-2282-438b-8ced-6ee0152e5ac5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Samplecodenumber</th>\n",
              "      <th>ClumpThickness</th>\n",
              "      <th>UniformityofCellSize</th>\n",
              "      <th>UniformityofCellShape</th>\n",
              "      <th>MarginalAdhesion</th>\n",
              "      <th>SingleEpithelialCellSize</th>\n",
              "      <th>BareNuclei</th>\n",
              "      <th>BlandChromatin</th>\n",
              "      <th>NormalNucleoli</th>\n",
              "      <th>Mitoses</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000025</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1002945</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1015425</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1016277</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1017023</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b06c4f4d-2282-438b-8ced-6ee0152e5ac5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b06c4f4d-2282-438b-8ced-6ee0152e5ac5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b06c4f4d-2282-438b-8ced-6ee0152e5ac5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Samplecodenumber  ClumpThickness  UniformityofCellSize  UniformityofCellShape  MarginalAdhesion  SingleEpithelialCellSize BareNuclei  BlandChromatin  NormalNucleoli  Mitoses  Class\n",
              "0           1000025               5                     1                      1                 1                         2          1               3               1        1      2\n",
              "1           1002945               5                     4                      4                 5                         7         10               3               2        1      2\n",
              "2           1015425               3                     1                      1                 1                         2          2               3               1        1      2\n",
              "3           1016277               6                     8                      8                 1                         3          4               3               7        1      2\n",
              "4           1017023               4                     1                      1                 3                         2          1               3               1        1      2"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preperation "
      ],
      "metadata": {
        "id": "xOaN5YrJqEE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cancerdata = cancerdata.drop(['Samplecodenumber'], 1)"
      ],
      "metadata": {
        "id": "bW8EjXnRpi7P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the loan status and distinct the target value.\n",
        "cancerdata['Class'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-kjOAXTqQ3d",
        "outputId": "e79e71bc-e9e7-4f55-c478-f61d3be0545b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    458\n",
              "4    241\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Select the finished loan including repaid and late, delete the 'current' loan\n",
        "Benign = cancerdata[(cancerdata.Class == 2) ].sample(240).index\n",
        "Malignant = cancerdata[(cancerdata.Class == 4) ].sample(240).index\n",
        "cancer = cancerdata.loc[Benign|Malignant]\n",
        "cancer = cancer.reset_index(drop=True)\n",
        "cancer['classes'] = cancer.Class.map({2:0,4:1})\n",
        "cancer = cancer.drop(['Class'], 1)\n",
        "cancer.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "QLGrA-VfqQ6b",
        "outputId": "473d714f-c8ba-43e4-bdd9-d4183e37ab97"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0fcfd870-852e-40f6-86fa-5cee0b1f5b43\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ClumpThickness</th>\n",
              "      <th>UniformityofCellSize</th>\n",
              "      <th>UniformityofCellShape</th>\n",
              "      <th>MarginalAdhesion</th>\n",
              "      <th>SingleEpithelialCellSize</th>\n",
              "      <th>BareNuclei</th>\n",
              "      <th>BlandChromatin</th>\n",
              "      <th>NormalNucleoli</th>\n",
              "      <th>Mitoses</th>\n",
              "      <th>classes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0fcfd870-852e-40f6-86fa-5cee0b1f5b43')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0fcfd870-852e-40f6-86fa-5cee0b1f5b43 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0fcfd870-852e-40f6-86fa-5cee0b1f5b43');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   ClumpThickness  UniformityofCellSize  UniformityofCellShape  MarginalAdhesion  SingleEpithelialCellSize BareNuclei  BlandChromatin  NormalNucleoli  Mitoses  classes\n",
              "0               5                     1                      1                 1                         2          1               3               1        1        0\n",
              "1               5                     4                      4                 5                         7         10               3               2        1        0\n",
              "2               3                     1                      1                 1                         2          2               3               1        1        0\n",
              "3               4                     1                      1                 3                         2          1               3               1        1        0\n",
              "4               8                    10                     10                 8                         7         10               9               7        1        1\n",
              "5               1                     1                      1                 1                         2         10               3               1        1        0\n",
              "6               2                     1                      1                 1                         2          1               1               1        5        0\n",
              "7               1                     1                      1                 1                         1          1               3               1        1        0\n",
              "8               2                     1                      1                 1                         2          1               2               1        1        0\n",
              "9               5                     3                      3                 3                         2          3               4               4        1        1"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cancer['classes'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXu36ek3qQ9M",
        "outputId": "a51262be-200b-45fc-b39e-955db2752b52"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    240\n",
              "0    240\n",
              "Name: classes, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data preprocessing by attributes "
      ],
      "metadata": {
        "id": "JtRJF8OiqdW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot date variables and find the variables with similar distributions, keep only one of them.\n",
        "#['ClumpThickness','UniformityofCellSize','UniformityofCellShape','MarginalAdhesion',\n",
        "#'SingleEpithelialCellSize','BareNuclei','BlandChromatin','NormalNucleoli','Mitoses']\n",
        "fig, axs = plt.subplots(3, 3, figsize=(18,18))\n",
        "axs[0,0].hist(cancer['ClumpThickness'])\n",
        "axs[0,0].set_title(\"ClumpThickness\")\n",
        "axs[0,1].hist(cancer['UniformityofCellSize'])\n",
        "axs[0,1].set_title(\"UniformityofCellSize\")\n",
        "axs[0,2].hist(cancer['UniformityofCellShape'])\n",
        "axs[0,2].set_title(\"UniformityofCellShape\")\n",
        "axs[1,0].hist(cancer['MarginalAdhesion'])\n",
        "axs[1,0].set_title(\"MarginalAdhesion\")\n",
        "axs[1,1].hist(cancer['SingleEpithelialCellSize'])\n",
        "axs[1,1].set_title(\"SingleEpithelialCellSize\")\n",
        "axs[1,2].hist(cancer['BareNuclei'])\n",
        "axs[1,2].set_title(\"BareNuclei\")\n",
        "axs[2,0].hist(cancer['BlandChromatin'])\n",
        "axs[2,0].set_title(\"BlandChromatin\")\n",
        "axs[2,1].hist(cancer['NormalNucleoli'])\n",
        "axs[2,1].set_title(\"NormalNucleoli\")\n",
        "axs[2,2].hist(cancer['Mitoses'])\n",
        "axs[2,2].set_title(\"Mitoses\")\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JI_0oUH-qnWw",
        "outputId": "a44d12f0-5e88-4487-9ccb-fd7ec3edbd17"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABQgAAAUICAYAAADnYD1uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdfZxtV10f/s8iA7YV2ghDY4ZEAhLQEDWCghaLkaACTRNQX6ukFRKIuVJBaouVB2nhJz9bVBDTH4reGExS0yRLHvOjVB5SMaAEmkAKQqQEDJKY3GRISMAoeMPuH3vfcHIyk9x75sycubPf79frvObstR/Od6+Ze9Y937MeStd1AQAAAADG6T6LDgAAAAAAWBwJQgAAAAAYMQlCAAAAABgxCUIAAAAAGDEJQgAAAAAYMQlCAAAAABgxCUJ2nFLKOaWU9y46jgNRSnlfKeV37+WYV5ZSrj6Aax509QCwk5VSulLKT05s/8NSyltLKbcO+45aQEwH1LbM4fV+tpRybSnla6WUV8752ne5l1LKaaWUvQd4jaOG38UPzDM2gO1Ee3RQtEfHD7+LI+YZG9wTCUIOOqWUB5VSfrWU8qlSyt+WUm4spVxaSnl2KWVp0fFNKqVcM7yxr/s4gMu9Jsn3bVasANzdel/gzJhIOjzJmya2/3WS70/yA8O+z28o2NncpW0ppby8lHLNZrxQKWUlyW8k+c9JHjK8dkopS8MHtQ+XUr5USrmtlPLRUsovllK+ac4xnFRK+UAp5eZSyl+XUq4upZxfSvmHwyGfT/+7+NA8Xxdgo7RH83OQtEew5bZVMgXuTSnlyCQfSLI3yX9M8tEkf5fknyT5+SQfW1x0a/reJIcMz49M8uEkJw8/D0jXdV9O8uX5hQbAVuq67oapoqOTfKLruo9v5LqllPt1XffVGWPayrbl4em/nL6467rrk6SUct8k70j/wfSXkvxxkpuSHJP+A+tfp/8Qt2GllCcleUuSVyXZleQrSR6R5OlJviFJuq67I8n07wlgR9Eebf/2CBZBD0IONr+V/k3zMV3Xnd913Se7rvt013XnJnlskk9Pn7DWUNtSyk9O9t7b1w28lFJLKZ8updxeSnnb0N3+x4beil8qpbyplPKPpq9dSvm3pZTrhvP+oJTywCTpuu6mrutuGBrhm4bTbt5XNt04l1L+QynlhuGbpPNKKfefjnHq+CeXUt4/vO6tpZQ/LqV861oVV0p5aCnlqlLKhaWU+010W//hoQfm7aWUT5ZSnjp13mHDfd401MGflFKeOLH/vqWUXy99F/2vlFKuL6VcOLH/0aWUd5VSvjh8O3ZVKeVZa8UIcDA6gPfTO4d0Db0iTk/ypKH8fUP5A0opvzO8536llHJ5KeVHJq6xr6fIvyqlvLOU8tdJXrWBduzOtqWUclr6DysPLV/v6f7K4fGpNe77jaWUSya2n1ZKuWKI+8ZSym+VUr5x3+skef9w6F+Wrw9he2GSH07yo13Xvabruv/Vdd01Xde9s+u6f57k3Inr//DQBv3N0Ob+XinlQQfwqzopyZVd1/0/w/8fPtN13bu6rvvXXdfdNFW/PzBsn1PWHgHwyom4nllKubL0oxquGdrEbzyAuADmQnt05/ZB3x5N+PZ7+V3+cuk/X91eSvl8KeW3p+r1tFLK3tJ/bvzE0FZ9qJRy3NR1HltKeXcp5cvD7/wtpZSHHsA9sQNIEHLQKH3S7WlJXt913a3T+7uu+7uu6/56Ay9xeJJTk/x4kqcmeUL6rvc/laQOZf80ycumzntckh9K8pQhvuOSnD3D6/9EkgcmOT7JM5OcmOTF6x1cSnlykncluSL9N12PT3Jekvuucex3JfngcPwpU9/svSbJf0ryXemHVF1Uhi70pZS/n+SPkjwg/f1/d5J3JnlPKeXbh/N/Nn39/GT6bx9PSnLZxPUvSPKF9L08vyPJv0tyy71XB8BBZ9330zV8b5KW/kPK4Ul+bCh/Y5IfTf+eelySP0nyjlLKt02d/ytJzk9ybJLfHspmbcf2uWi47rXDtQ4f7ul3k3xrKeUH9x1YSnnAcM3dw/Z3Jrk4yaXD/Z+avh3bF9trhriS5DH5+hC2ZyX5n13XfXCtgLquu2W4/pOSvD3JhUm+M30vi6OSvKWUUta5n2nXJ3lEKeVx+3l8kvybfL0uDk/y00nuyPDhcvgQ+4Ykr03fy+TZSZ6cr983wCJoj3ZOe3Rvv8u/Sd8L8Zgkp6X/LPlfpq5xnyS/muRn0n92vSnJfx8+66WUckz6HpMfTPI9SZ6Uvq17Tynl7+3nPbETdF3n4XFQPNK/mXVJfuxejjsnyXvX2x7KfrL/879z+5Xphy0vT5T9Zvo3xgdPlJ2Z5PKpa385yT+aKPuRIc5HTL3mUUP5D6wR8/uS/O+psjck+eBUjFdPbL8/yTvurR7Sv8F/McmLp/YfP12fSQ4byn502D4tfcO8NHXu/0zyGxN18j+TlHXiuDXJaYv++/Hw8PCY5TG8P//uGuV3vqfvz/vpUNYl+cmJ7en26hHDMU+beq2PJHnj1Ov+h6ljZm3HptuWlye5Zo37vTjJ709s/3T6Dxj3G7b/a5IPT51zcpKvJXnosL2vno6YOOb2JP9lP38Pr54q+5bhesetcy+nJdk7sf0Phvvo0n84e3v6BOCD1vq9rhHDcenb/J+ZKLsmyfOmjnvicI1vWvTfr4eHx855aI/uLB9Le7Rfv8s14ntG+iHL95l47S7JCRPHfFP69uz0id//hVPX+YahTp6+6L99j6176EHIwWR/v5GZ1XVd161ObN+Q5Iburt28b0jyj6fO+2R31x6NfzL8POYAX/9/T23/VfpGYD2PTfLue7nmdyT5H0l+seu6X1nnmCv3Pem6bk/6xnvf635vkm9O8sWhu/mXSylfTv+N39HDMb83vM7VQ5f2Hy+l3G/i+q9J8ruln1j5laWUx9xLzAAHq3t6P90f+9qNS6fKL03y6KmyteaynbUd2x+/k+THJ3otnJHk3O7rPdIfvUbcf5y+7b6n9nB/2/bvTfJzU23RJ4d9R9/DeXfquu72rutOSvKwJC9Nct3w81MTveLXDrKUw5P8/+k/nP/WUPbgJA9N8utTcf2P4bRH7Oe9Acyb9uiuDub26B5/l8Ow7UtLKX81xHJ+kvul/ww36YMT17klyVX5+u/ye5M8Y+qevpDk7+3vPbEzSBByMPl0+m9+DjTx9rXc/Q3/bsNw0y92Mqlbp2yz/t1MT+g7j9f6y/SNyk9OzkVxL6+bide9T/rG47ipx7enb4zTdd2V6Ru3nx+udWaSK8uwAlfXda9K8sj0QxeOTXJZKeX/3eB9AWyVW5Os9f556PDzbyfK7un9dN7WmlJjM9ux/5HkxiTPGuYtemySs2a4zrRPZf/a9fukH2423R4dna8n5PZL188pdU7XdT+Tvj3rkvzCeseXUvb19Pho+mkyJmNK+l4fkzF91xDXhib7B5iiPeqNrT1a93dZSnl8kj9InxB9Rvoh088bjrnfGuet5z7pe15O39Mj0w/rZiQkCDlodF13c/o33Reslewq/WIZa00KfmOSlamyefZi+/Zy1+Xo/8nw85NrHTxHV6QfznxPbk0/2e7Xkrz3HuYeWc/l6Vf5uq3ruqunHn+176Cu677cdd1bu657Yfp5K749yQ9O7P9s13W/1XXdT6RfffpfH2AcAIvy50keW0o5ZKr8cem/xb/67qfM7BPDzydOlT8xyZ/N8XXuyVeTTN9ruq77WvoPYGcMj0u7rpucKP4TuXvcP5j+w84nsr7fTz8x/vevtXOi3bo8yaPXaIuu7vqVL2cy9KJYtxfLMJ/UeUmW0s/h+7WJc/ekn7fqUevE9bdrXRNgRtqjjLc9WscPJFntuu7lXdd9qOu6/5PkiHWO/b59T0oph6b/vLbv8+rl6edT/Mwa92Tu+BGRIORg8zPpv326opTyL0spx5RSHlH6Vbguz9pdoN+b5NtKKc8vpXxrKeWM9BPZzkuX5LxSyrGlX933N5Nc3HXdPBvptbwqyVNLKb9RSvnOUsqjhlWqHnWX4LrutvQTDN+e5JIDXGHr/CR/kX4S2x8p/Wpljy+lvLSU8vQkKaX8+9KvXvboUsrDkjw3/X9S/k8p5f6llN8spTyplPKwUsp3p1/MZbOTpwDz8lvph/L83rDC37eWUk5J/x78e13XfXFeL9R13WfS9wT4rVLKj5ZSvq2Ucmb63te/Nq/XuRd/keSbSynfX0pZHnrP7XN2km9LP8n87qnzfi3JY0oprxvifkqS/y/J+V3X/eU9vN6ZSS5J8q5Sys+XUr6nlPLQUspTSilvS7/oR9J/uXRy6VcIPm74PTyllHL2vknW780wzcVrSik/NLRJ31FKeU36+n3rOqe9Iv1cvj+V5AGllG8eHvcf9v9ikheWUn5x+H/Ao0opTy+l/M7+xARwALRHXzfG9mgtn0ry4FLK6aWUh5dSnp3+8/K0LsmvllKeWEr5jvRffH0pyX8b9v+n9AnD3y+lPG6I6YdKKWeWUh5+APFwkJMg5KAyvKk/Jsnb0k/++pEkf5r+26NfyxrfaHVd9970k9y+LP08f09K8ktzDOvDST6Q5D1J/jD9kKLnzvH6a+q67t3pV01+fPoVrT6cfpWu6e77Gb7Nemr61YP/qJSyX99MDb0ffjB98vX3kvyfJG9J/03l54bDbks/5OqD6e/9GUl+fPgmb2/6SXDPTj9U+V1J9iT5lwd8wwAL0HXd59L3DP+m9HPQfSx9e/JrWfs/4Rv1U+nfK38/fZv1hCQndl3355vwWmt5W/oPhf89/aTvdw516rru+iTvSD+x+ZsmT+q67mPpV7F/Yvq4/+twjeflHnRd93fp26f/kOSZ6eeJ+niS/5y+XTt3OO6P0rff35l+ka6PJXld+g84d2v31vHHSY5M355dleSPknx/+on61xtCdXz63/3l6SeS3/f4+SGu/5r+S8cTh3j/V/r/n1y3nzEB7Bft0ejbo7VifkeSX06f4Pv4EPe/X+PQr6X/W/md9O3ZNyf5Z13X3T5c56r0f1v3T/87/2T6Xpp/P/1il4xE6foVaoAZlFLOSb/61ZMXHQsAbLZSyoeT/EnXdf920bEAMF7ao/1TSjkt/QJbS4uOhe3PHwkAAPeolLKcvpfcY9L3UACALac9gs0jQQgAwL25Kf00FS/suu6ziw4GgNHSHsEmMcQYAABgC9Vaj0y/UMBh6RcQ2N1aO7PW+sAkFyU5Ksk1SWpr7ZZaa0m/iMLT0i88d1pr7SOLiB2AnckiJQAAAFtrb5IXtdaOSfJ9SZ5faz0myUuSXNJaOzr9iqovGY5/apKjh8euJG/Y+pAB2Mm2yxBj3RgBWE9ZdABTtFkArGW/26vW2r4VsdNa+1Kt9aokD0lycvrVs5N+1dT3JXnxUH5ea61Lclmt9dBa6+HDddajvQJgPXdrs7ZLgjB/9Vd/tegQNt3y8nJWV1cXHcZBSd3NTt3NTt3Nbl51t7KyModo5m+nt1n+9men7man7man7ma3HdqrWutRSb47yYeSHDaR9Lsh/RDkpE8efn7itGuHsrskCGutu9L3MExrLV/96ldnjutgsLS0lL179y46jIOW+pudupudupvdvOrufve739rX3/CVAQAAOGC11vsneXOSn2ut3VZrvXNfa62rtR5QL8DW2u4ku4fNbqcnjiXHN0b9zU7dzU7dzW6zv9QyByEAAMAWq7XeN31y8PzW2luG4j211sOH/YcnuXEovy7JkROnHzGUAcBc6EEIAACwhYZVic9OclVr7dcndl2c5NQkrx5+vn2i/AW11guTPD7Jrfcy/yAAHBAJQgAAgK31hCTPSvLxWuuVQ9nL0icGW6319CSfS7JvzPE7kzwtydVJbk/ynK0NF4CdToIQAABgC7XWPpD1Vz0+YY3juyTP39SgABg1cxACAAAAwIjdaw/CWusbk5yY5MbW2rFD2QOTXJTkqCTXJKmttVuGuTTOTN/9/fYkp7XWPrI5oQMAAAAAG7U/PQjPSfKUqbKXJLmktXZ0kkuG7SR5apKjh8euJG+YT5gAAAAAwGa41wRha+3SJDdPFZ+c5Nzh+blJnj5Rfl5rrWutXZbk0Frr4fMKFgAAAACYr1kXKTmstXb98PyGJIcNzx+S5PMTx107lF2fKbXWXel7Gaa1luXl5RlDOXgsLS2N4j43g7qbnbqbnbqbnboDAAA4eGx4FePWWldr7WY4b3eS3cNmt7q6utFQtr3l5eWM4T43g7qbnbqbnbqb3bzqbmVlZQ7RAAAAcE9mXcV4z76hw8PPG4fy65IcOXHcEUMZAAAAALANzdqD8OIkpyZ59fDz7RPlL6i1Xpjk8UlunRiKDACbqtZ6ZJLz0k990SXZ3Vo7s9b6wCQXJTkqyTVJamvtllprSXJmkqcluT3Jaa21jywidgAAgEW51x6EtdYLknwwyaNqrdfWWk9Pnxj84Vrrp5M8edhOkncm+WySq5OcleRnNiVqAFjb3iQvaq0dk+T7kjy/1npMkpckuaS1dnSSS4btJHlqkqOHx64kb9j6kAEAABbrXnsQttZOWWfXCWsc2yV5/kaDAoBZDL3Wrx+ef6nWelX6xbJOTnL8cNi5Sd6X5MVD+XlD+3VZrfXQWuvher8DAABjsuFFSgBgO6q1HpXku5N8KMlhE0m/G9IPQU765OHnJ067dii7S4Kw1rorfQ/DtNZ2/ArNVqGenbqbnbqbnbqbnboDgJ4EIQA7Tq31/knenOTnWmu31Vrv3Nda62qt3YFcr7W2O8nuYbPb6atbW8F7dupudupudupudvOqu5WVlTlEAwCLI0HI6N1xxkmLDuEuDjnr4kWHAAe1Wut90ycHz2+tvWUo3rNv6HCt9fAkNw7l1yU5cuL0I4ayTeV9B4CDxXZqs7RXAJtHghCAHWNYlfjsJFe11n59YtfFSU5Nv6jWqUnePlH+glrrhUken+RW8w8CAABjI0EIwE7yhCTPSvLxWuuVQ9nL0icGW6319CSfS7JvzPE7kzwtydVJbk/ynK0NFwAAYPEkCAHYMVprH0hS1tl9whrHd0mev6lBAQAAbHP3WXQAAAAAAMDiSBACAAAAwIhJEAIAAADAiEkQAgAAAMCISRACAAAAwIhJEAIAAADAiEkQAgAAAMCISRACAAAAwIhJEAIAAADAiEkQAgAAAMCISRACAAAAwIhJEAIAAADAiEkQAgAAAMCISRACAAAAwIhJEAIAAADAiEkQAgAAAMCISRACAAAAwIhJEAIAAADAiEkQAgAAAMCISRACAAAAwIhJEAIAAADAiEkQAgAAAMCISRACAAAAwIgtLToAAACAMam1vjHJiUlubK0dO5RdlORRwyGHJvlia+24WutRSa5K8qlh32WttedtccgA7HAShAAAAFvrnCSvT3LevoLW2r/Y97zW+tokt04c/5nW2nFbFh0Ao2OIMQAAwBZqrV2a5Oa19tVaS5Ka5IItDQqAUdODEAAAYPv4p0n2tNY+PVH2sFrrR5PcluTlrbX3r3VirXVXkl1J0lrL8vLyhoPZs+ErzM/0/SwtLc3lHsdK/c1O3c1O3c1us+tOghAAAGD7OCV37T14fZJvaa19odb62CRvq7U+urV22/SJrbXdSXYPm93q6urmR7uFpu9neXn5bmXsP/U3O3U3O3U3u3nV3crKyprlhhgDAABsA7XWpSQ/luSifWWtta+01r4wPL8iyWeSPHIxEQKwU0kQAgAAbA9PTvLnrbVr9xXUWh9caz1keP7wJEcn+eyC4gNgh5IgBAAA2EK11guSfDDJo2qt19ZaTx92PTN3X5zkiUk+Vmu9MsmbkjyvtbbmAicAMCtzEAIAAGyh1top65SftkbZm5O8ebNjAmDc9CAEAAAAgBGTIAQAAACAEZMgBAAAAIARkyAEAAAAgBGTIAQAAACAEbOKMQA7Rq31jUlOTHJja+3YoeyiJI8aDjk0yRdba8fVWo9KclWSTw37LmutPW+LQwYAAFg4CUIAdpJzkrw+yXn7Clpr/2Lf81rra5PcOnH8Z1prx21ZdAAAANuQIcYA7BittUuT3LzWvlprSVKTXLClQQEAAGxzehACMBb/NMme1tqnJ8oeVmv9aJLbkry8tfb+tU6ste5KsitJWmtZXl7eUCB7NnT2/E3fz9LS0obvcazU3ezU3ezU3ezUHQD0JAgBGItTctfeg9cn+ZbW2hdqrY9N8rZa66Nba7dNn9ha251k97DZra6ubn60W2j6fpaXl+9Wxv5Rd7NTd7NTd7ObV92trKzMIRoAWBxDjAHY8WqtS0l+LMlF+8paa19prX1heH5Fks8keeRiIgQAAFgcCUIAxuDJSf68tXbtvoJa64NrrYcMzx+e5Ogkn11QfAAAAAsjQQjAjlFrvSDJB5M8qtZ6ba319GHXM3P3xUmemORjtdYrk7wpyfNaa2sucAIAALCTmYMQgB2jtXbKOuWnrVH25iRv3uyYAAAAtjs9CAEAAABgxCQIAQAAAGDEJAgBAAAAYMQkCAEAAABgxCQIAQAAAGDEJAgBAAAAYMQkCAEAAABgxCQIAQAAAGDEJAgBAAAAYMQkCAEAAABgxCQIAQAAAGDEJAgBAAAAYMQkCAEAAABgxCQIAQAAAGDEljZycq313yb5qSRdko8neU6Sw5NcmORBSa5I8qzW2lc3GCcAAAAAsAlm7kFYa31Ikhcm+Z7W2rFJDknyzCS/kuR1rbVHJLklyenzCBQAAAAAmL+NDjFeSvL3a61LSf5BkuuTPCnJm4b95yZ5+gZfAwAAAADYJDMPMW6tXVdrfU2Sv0zyN0nenX5I8Rdba3uHw65N8pC1zq+17kqya7hWlpeXZw3loLG0tDSK+9wMm1l3ezblqrOb9336u5udupudugMAADh4zJwgrLV+U5KTkzwsyReT/EGSp+zv+a213Ul2D5vd6urqrKEcNJaXlzOG+9wMY6q7ed/nmOpu3tTd7OZVdysrK3OIBgAAgHuykSHGT07yF621m1prf5fkLUmekOTQYchxkhyR5LoNxggAAAAAbJKNrGL8l0m+r9b6D9IPMT4hyeVJ/ijJT6RfyfjUJG/faJAAAAAAwOaYuQdha+1D6Rcj+UiSjw/X2p3kxUn+Xa316iQPSnL2HOIEAAAAADbBRnoQprX2iiSvmCr+bJLHbeS6AAAAAMDW2MgchAAAAADAQU6CEAAAAABGbENDjAEAADgwtdY3JjkxyY2ttWOHslcmOSPJTcNhL2utvXPY99Ikpye5I8kLW2vv2vKgAdjRJAgBAAC21jlJXp/kvKny17XWXjNZUGs9Jskzkzw6yUqS99ZaH9lau2MrAgVgHAwxBgAA2EKttUuT3Lyfh5+c5MLW2ldaa3+R5OpYFBKAOdODEAAAYHt4Qa312UkuT/Ki1totSR6S5LKJY64dyu6m1rorya4kaa1leXl5wwHt2fAV5mf6fpaWluZyj2Ol/man7man7ma32XUnQQgAALB4b0jyqiTd8PO1SZ57IBdore1OsnvY7FZXV+ca4KJN38/y8vLdyth/6m926m526m5286q7lZWVNcslCAEAABastXZnZ71a61lJ3jFsXpfkyIlDjxjKAGBuzEEIAACwYLXWwyc2n5Hkz4bnFyd5Zq31G2qtD0tydJIPb3V8AOxsehACAABsoVrrBUmOT7Jca702ySuSHF9rPS79EONrkvx0krTWPlFrbUk+mWRvkudbwRiAeZMgBAAA2EKttVPWKD77Ho7/5SS/vHkRATB2hhgDAAAAwIhJEAIAAADAiBliDMCOUWt9Y5ITk9zYWjt2KHtlkjOS3DQc9rLW2juHfS9NcnqSO5K8sLX2ri0PGgAAYMEkCAHYSc5J8vok502Vv6619prJglrrMUmemeTRSVaSvLfW+kgTvwMAAGNjiDEAO0Zr7dIkN+/n4ScnubC19pXW2l8kuTrJ4zYtOAAAgG1KD0IAxuAFtdZnJ7k8yYtaa7ckeUiSyyaOuXYoAwAAGBUJQgB2ujckeVWSbvj52iTPPZAL1Fp3JdmVJK21LC8vbyigPRs6e/6m72dpaWnD9zhW6m526m526m526g4AehKEAOxorbU783G11rOSvGPYvC7JkROHHjGUrXWN3Ul2D5vd6urqJkS6ONP3s7y8fLcy9o+6m526m526m9286m5lZWUO0QDA4piDEIAdrdZ6+MTmM5L82fD84iTPrLV+Q631YUmOTvLhrY4PAABg0fQgBGDHqLVekOT4JMu11muTvCLJ8bXW49IPMb4myU8nSWvtE7XWluSTSfYmeb4VjAEAgDGSIARgx2itnbJG8dn3cPwvJ/nlzYsIAABg+zPEGAAAAABGTIIQAAAAAEZMghAAAAAARkyCEAAAAABGTIIQAAAAAEZsR61ifMcZJy06hLs45KyLFx0CAAAAANwjPQgBAAAAYMQkCAEAAABgxCQIAQAAAGDEJAgBAAAAYMQkCAEAAABgxCQIAQAAAGDEJAgBAAAAYMQkCAEAAABgxCQIAQAAAGDEJAgBAAAAYMQkCAEAAABgxJYWHQAAG3fHGSctOoS7euufLjoCAAAA9pMehAAAAAAwYhKEAAAAADBiEoQAAAAAMGIShAAAAAAwYhKEAAAAADBiEoQAAAAAMGIShAAAAAAwYhKEAAAAADBiEoQAAAAAMGIShAAAAAAwYkuLDgAAAGBMaq1vTHJikhtba8cOZb+W5J8n+WqSzyR5Tmvti7XWo5JcleRTw+mXtdaet/VRA7CTSRACAABsrXOSvD7JeRNl70ny0tba3lrrryR5aZIXD/s+01o7bmtDBGBMDDEGAADYQq21S5PcPFX27tba3mHzsiRHbHlgAIyWHoQAAADby3OTXDSx/bBa60eT3Jbk5a219691Uq11V5JdSdJay/Ly8oYD2bPhK8zP9P0sLS3N5R7HSv3NTt3NTt3NbrPrToIQAABgm6i1/mKSvUnOH4quT/ItrbUv1Fofm+RttdZHt9Zumz63tbY7ye5hs1tdXd2SmLfK9P0sLy/frYz9p/5mp+5mp+5mN6+6W1lZWbPcEGMAAIBtoNZ6WvrFS/5Va61LktbaV1prXxieX3tVfnEAACAASURBVJF+AZNHLixIAHYkCUIAAIAFq7U+JckvJDmptXb7RPmDa62HDM8fnuToJJ9dTJQA7FSGGAMAAGyhWusFSY5PslxrvTbJK9KvWvwNSd5Ta02Sy1prz0vyxCS/VGv9uyRfS/K81trNa14YAGYkQQgAALCFWmunrFF89jrHvjnJmzc3IgDGToIQgB2j1vrG9HM33dhaO3Yo+7Uk/zzJV9PP2/Sc1toXa61HJbkqyaeG0/f11AAAABgVCUIAdpJzkrw+yXkTZe9J8tLW2t5a66+kH8L14mHfZ1prx21tiAAAANuLRUoA2DFaa5cmuXmq7N2ttb3D5mVJjtjywAAAALYxPQgBGJPnJrloYvthtdaPJrktyctba+9fTFgAAACLI0EIwCjUWn8xyd4k5w9F1yf5ltbaF2qtj03ytlrro1trt61x7q4ku5KktZbl5eUNxbJnQ2fP3/T9LC0tbfgex0rdzU7dzU7dzU7dAUBPghCAHa/Welr6xUtOaK11SdJa+0qSrwzPr6i1fibJI5NcPn1+a213kt3DZre6uroVYW+Z6ftZXl6+Wxn7R93NTt3NTt3Nbl51t7KyModoAGBxNpQgrLUemuR3kxybpEs/dOtT6YdvHZXkmiS1tXbLhqIEgBnVWp+S5BeS/GBr7faJ8gcnubm1dket9eFJjk7y2QWFCQAAsDAbXaTkzCR/2Fr7tiTfleSqJC9Jcklr7egklwzbALDpaq0XJPlgkkfVWq+ttZ6eflXjByR5T631ylrrbw+HPzHJx2qtVyZ5U5LntdZuXvPCAAAAO9jMPQhrrf8o/Yer05KktfbVJF+ttZ6c5PjhsHOTvC/JizcSJADsj9baKWsUn73OsW9O8ubNjQgAAGD728gQ44cluSnJ79VavyvJFUn+TZLDWmvXD8fckOSwtU6e94TviUnf78meZ/yThbzueg57658e0PGbWXfb/e9mo0y+PbuDqe6229/xwVR3AAAAY7eRBOFSksck+dnW2odqrWdmajhxa62rtXZrnbzTJ3xPTPp+Tw60HsZUd/O+zzHV3bypu9nt3bvXpO8AAAAHiY3MQXhtkmtbax8att+UPmG4p9Z6eJIMP2/cWIgAAAAAwGaZOUHYWrshyedrrY8aik5I8skkFyc5dSg7NcnbNxQhAAAAALBpNjLEOEl+Nsn5tdb7JflskuekTzq2YeXIzyWpG3wNAAAAAGCTbChB2Fq7Msn3rLHrhI1cFwAAAADYGhuZgxAAAAAAOMhJEAIAAADAiEkQAgAAAMCISRACAAAAwIhJEAIAAADAiEkQAgAAAMCISRACAAAAwIhJEAIAAADAiEkQAgAAAMCISRACAAAAwIhJEAIAAADAiEkQAgAAAMCISRACAAAAwIhJEAIAAADAiEkQAgAAAMCISRACAAAAwIhJEAIAAADAiEkQAgAAAMCISRACAAAAwIhJEAIAAADAiEkQAgAAAMCISRACAAAAwIhJEAIAAADAiEkQAgAAAMCILS06AAAAgDGptb4xyYlJbmytHTuUPTDJRUmOSnJNktpau6XWWpKcmeRpSW5Pclpr7SOLiBuAnUsPQgAAgK11TpKnTJW9JMklrbWjk1wybCfJU5McPTx2JXnDFsUIwIhIEAIAAGyh1tqlSW6eKj45ybnD83OTPH2i/LzWWtdauyzJobXWw7cmUgDGwhBjAACAxTustXb98PyGJIcNzx+S5PMTx107lF2fKbXWXel7Gaa1luXl5Q0HtWfDV5if6ftZWlqayz2Olfqbnbqbnbqb3WbXnQQhAADANtJa62qt3Qzn7U6ye9jsVldX5xvYgk3fz/Ly8t3K2H/qb3bqbnbqbnbzqruVlZU1yw0xBgAAWLw9+4YODz9vHMqvS3LkxHFHDGUAMDd6EAIAACzexUlOTfLq4efbJ8pfUGu9MMnjk9w6MRQZAOZCghCAHaPW+sYkJya5sbV27FD2wCQXJTkqyTVJamvtllprSXJmkqcluT3Jaa21jywibgDGpdZ6QZLjkyzXWq9N8or0icFWaz09yeeS1OHwd6Zvq65O3149Z8sDBmDHkyAEYCc5J8nrk5w3UfaSJJe01l5da33JsP3iJE9NcvTweHySNww/AWBTtdZOWWfXCWsc2yV5/uZGBMDYmYMQgB2jtXZpkpunik9Ocu7w/NwkT58oP6+11rXWLkty6L65nwAAAMZED0IAdrrDJuZquiHJYcPzhyT5/MRx1w5ld5vXqda6K8muJGmtZXl5eUMB7dnQ2fM3fT9LS0sbvsexUnezU3ezU3ezU3cA0JMgBGA0WmtdrbWb4bzdSXYPm93q6up8A1uw6ftZXl6+Wxn7R93NTt3NTt3Nbl51t7KyModoAGBxDDEGYKfbs2/o8PDzxqH8uiRHThx3xFAGAAAwKnoQArDTXZzk1PSrQ56a5O0T5S+otV6YfnGSWyeGIgMAAIyGBCEAO0at9YIkxydZrrVem+QV6RODrdZ6epLPJanD4e9M8rQkVye5PclztjxgAACAbUCCEIAdo7V2yjq7Tljj2C7J8zc3IgAAgO3PHIQAAAAAMGIShAAAAAAwYhKEAAAAADBiEoQAAAAAMGIShAAAAAAwYhKEAAAAADBiEoQAAAAAMGJLiw6AcbrjjJMO6Pg9mxQHAAAAwNjpQQgAAAAAIyZBCAAAAAAjJkEIAAAAACMmQQgAAAAAIyZBCAAAAAAjJkEIAAAAACO2tOgAAPbXHWectKWvt+de9h9y1sVbEgcAAABsJj0IAQAAAGDEJAgBAAAAYMQkCAEAAABgxCQIAQAAAGDEJAgBAAAAYMQkCAEAAABgxCQIAQAAAGDEJAgBAAAAYMQkCAEAAABgxCQIAQAAAGDEJAgBAAAAYMSWNnqBWushSS5Pcl1r7cRa68OSXJjkQUmuSPKs1tpXN/o6AAAAAMD8zaMH4b9JctXE9q8keV1r7RFJbkly+hxeAwAAAADYBBtKENZaj0jyz5L87rBdkjwpyZuGQ85N8vSNvAYAAAAAsHk2OsT4N5L8QpIHDNsPSvLF1treYfvaJA9Z68Ra664ku5KktZbl5eUNhpLs2fAV5mv6npaWluZyn7PYbnXD+ub9N7LIv7t5225/x9upXrdb3eykvzsAAICdbuYEYa31xCQ3ttauqLUef6Dnt9Z2J9k9bHarq6uzhrJtTd/T8vLy3cpg2rz/RvzdbR71ur69e/fOpX5WVlbmEA0AAAD3ZCM9CJ+Q5KRa69OS/L0k/zDJmUkOrbUuDb0Ij0hy3cbDBAAA2NlqrY9KctFE0cOT/MckhyY5I8lNQ/nLWmvv3OLwANjBZk4QttZemuSlSTL0IPz51tq/qrX+QZKfSL+S8alJ3j6HOAEAAHa01tqnkhyXJLXWQ9J3tnhrkuekXwjyNQsMD4AdbB6rGE97cZJ/V2u9Ov2chGdvwmsAAADsZCck+Uxr7XOLDgSAnW+ji5QkSVpr70vyvuH5Z5M8bh7XBQAAGKlnJrlgYvsFtdZnJ7k8yYtaa7csJiwAdqK5JAgBAACYj1rr/ZKclGFKpyRvSPKqJN3w87VJnrvGebuS7EqS1lqWl5c3HMueDV9hfqbvZ2lpaS73OFbqb3bqbnbqbnabXXcShAAAANvLU5N8pLW2J0n2/UySWutZSd6x1kmttd1Jdg+b3erq6mbHuaWm72d5efluZew/9Tc7dTc7dTe7edXdysrKmuUShADseFaFBOAgc0omhhfXWg9vrV0/bD4jyZ8tJCoAdiwJQgB2PKtCAnCwqLV+Y5IfTvLTE8W/Wms9Lv0Q42um9gHAhkkQAjA2d64KWWtddCwAcBettb9O8qCpsmctKBwARkKCEICxOeBVIec96ft2mvA9Men7PKm72am72am72ak7AOhJEAIwGrOuCmnSd/aXupudupudupvdZk/4DgAHCwlCAMZkplUhAQAAdrL7LDoAANhCd1sVcmKfVSEBAIBR0oMQgFGwKiQAAMDaJAgBGAWrQgIAAKzNEGMAAAAAGDEJQgAAAAAYMQlCAAAAABgxCUIAAAAAGDEJQgAAAAAYMQlCAAAAABgxCUIAAAAAGDEJQgAAAAAYMQlCAAAAABixpUUHAAAAjMcdZ5y06BC+7q1/uugIAGBb0IMQAAAAAEZMghAAAAAARkyCEAAAAABGTIIQAAAAAEZMghAAAAAARkyCEAAAAABGTIIQAAAAAEZMghAAAAAARkyCEAAAAABGTIIQAAAAAEZMghAAAAAARmxp0QEAAAAAwHZyxxknLTqEu3rrn27q5fUgBAAAAIARkyAEAAAAgBEzxHgTTXdH3bOgOAAAAABgPXoQAgAAAMCISRACAAAAwIhJEAIAAADAiEkQAgAAAMCISRACAAAAwIhJEAIAAADAiC0tOgDgru4446S5Xm/PBs8/5KyL5xIHAAAAsD3pQQgAAAAAI6YHIQAAwDZRa70myZeS3JFkb2vte2qtD0xyUZKjklyTpLbWbllUjADsPHoQAgAAbC8/1Fo7rrX2PcP2S5Jc0lo7OsklwzYAzI0EIQAAwPZ2cpJzh+fnJnn6AmMBYAcyxBgAAGD76JK8u9baJfmd1truJIe11q4f9t+Q5LC1Tqy17kqyK0laa1leXt5wMBtd8G6epu9naWlpLvc4VupvdupudgdT3W2n979k8+tOghCAUTCnEwAHiR9orV1Xa/3HSd5Ta/3zyZ2ttW5IHt7NkEzcPWx2q6urmxzq1pq+n+Xl5buVsf/U3+zU3ezU3ez27t07l7pbWVlZs9wQYwDGxJxOAGxrrbXrhp83Jnlrkscl2VNrPTxJhp83Li5CAHYiCUIAxsycTgBsG7XWb6y1PmDf8yQ/kuTPklyc5NThsFOTvH0xEQKwUxliDMBYbJs5nbbbfCbmdJofdTc7dTe7g63uttN74Dasu8OSvLXWmvSf1f5ba+0Pa63/K0mrtZ6e5HNJ6gJjBGAHkiAEYCzM6bQOczrNj7qbnbqbnbqb3WbP53SgWmufTfJda5R/IckJc3kRAFiDIcYAjII5nQAAANYmQQjAjmdOJwAAgPVJEAIwBocl+UCt9X8n+XCS/95a+8Mkr07yw7XWTyd58rANAAAwKuYgBGDHM6cTAADA+iQIgXt0xxknLToEAAAAYBMZYgwAAAAAIyZBCAAAAAAjJkEIAAAAACMmQQgAAAAAIyZBCAAAAAAjJkEIAAAAACMmQQgAAAAAI7Y064m11iOTnJfksCRdkt2ttTNrrQ9MclGSo5Jck6S21m7ZeKgAAACwPdxxxkmLDuEuDjnr4kWHABzENtKDcG+SF7XWjknyfUmeX2s9JslLklzSWjs6ySXDNgAAAACwDc2cIGytXd9a+8jw/EtJrkrykCQnJzl3OOzcJE/faJAAAAAAwOaYeYjxpFrrUUm+O8mHkhzWWrt+2HVD+iHIa52zK8muJGmtZXl5ecNx7NnwFQD23zzet+Zlu73/LS0tbav64eCynYZsGa4FAMAYbDhBWGu9f5I3J/m51tpttdY797XWulprt9Z5rbXdSXYPm93q6upGQwHYUt631rd379651M/KysocogEAAOCebChBWGu9b/rk4PmttbcMxXtqrYe31q6vtR6e5MaNBgkAAACs70B74G/mCBQ98OHgM/MchLXWkuTsJFe11n59YtfFSU4dnp+a5O2zhwcAAAAAbKaN9CB8QpJnJfl4rfXKoexlSV6dpNVaT0/yuSR1nfMBAAAAgAWbOUHYWvtAkrLO7hNmvS4AAAAAsHVmHmIMAAAAABz8JAgBAAAAYMQkCAEAAABgxDaySAkAwI52xxknHdDxezYpjn0OOeviTX4FAADGSA9CAAAAABgxCUIAAAAAGDFDjAEAANj2pqd92OxpHQDGRA9CAAAAABgxCUIAAAAAGDEJQgAAAAAYMXMQAsDImdMJAJin6f9bLNohZ1286BBg29ODEAAAAABGTIIQAAAAAEZMghAAAAAARkyCEAAAAABGTIIQAAAAAEbMKsYAAAeJ7bQqpBUhAQB2DglCgBltpw/qAADA2ub9//Y9c73auNxb3fkCcnEkCAEAYM628kskH7Z2jlrrkUnOS3JYki7J7tbambXWVyY5I8lNw6Eva629czFRArATSRACAABsD3uTvKi19pFa6wOSXFFrfc+w73WttdcsMDYAdjAJQgB2PD0yADgYtNauT3L98PxLtdarkjxksVEBMAYShACMgR4ZABxUaq1HJfnuJB9K8oQkL6i1PjvJ5enbtFvWOGdXkl1J0lrL8vLyhuMw1xqwlebxvjUv2+39b2lpaVPrR4IQgB1PjwwADia11vsneXOSn2ut3VZrfUOSV6XvBf+qJK9N8tzp81pru5PsHja71dXVLYoYYD68b61v7969c6mflZWVNcslCAEYle3QI2O7fRsJs9huK0Ie9tY/nUsc87Kd/p1vp94Yyfaqm83ujTGLWut90ycHz2+tvSVJWmt7JvafleQdCwoPgB1KghCA0dAjA3Yu/y7Xp27Wt9m9MQ5UrbUkOTvJVa21X58oP3zoDZ8kz0jyZ3N5QQAYSBACMAp6ZABwEHhCkmcl+Xit9cqh7GVJTqm1Hpf+C61rkvxf9u493rayrhf/55GtVlpHaSWxAcNTWKGllhdKfx6KLmImWL+eo5WiInh+BzM7eArtgr88FnXU4vzq8GsrCqiJz/GSZKQlZebxSqiJcjySooKwcQfewksbx/ljjAWTtdfee625LnOuNd7v12u+5hxjjjnGdz5rMx/mZz7jGU+fTXkAbFcCQgC2PSMyANgKWmvvSFKWeerSza4FgHEREAIwBkZkAAAA7IeAEIBtz4gMAACA/bvTrAsAAAAAAGZHQAgAAAAAIyYgBAAAAIARExACAAAAwIgJCAEAAABgxASEAAAAADBiAkIAAAAAGLEdsy4AAADW6tbTHjvrEgAAtiwjCAEAAABgxASEAAAAADBiAkIAAAAAGDEBIQAAAACMmIAQAAAAAEZMQAgAAAAAIyYgBAAAAIARExACAAAAwIgJCAEAAABgxASEAAAAADBiAkIAAAAAGDEBIQAAAACMmIAQAAAAAEZMQAgAAAAAIyYgBAAAAIARExACAAAAwIgJCAEAAABgxASEAAAAADBiAkIAAAAAGLEdsy4AAAAAAG497bGzLmG0jCAEAAAAgBETEAIAAADAiAkIAQAAAGDEzEEIAADbmPmcAICDMYIQAAAAAEZMQAgAAAAAIyYgBAAAAIARExACAAAAwIgJCAEAAABgxDbsKsa11kclOTfJIUle2lo7Z6OOBQDT0l8BsBXorwDYSBsygrDWekiSP05yYpJjkzyh1nrsRhwLAKalvwJgK9BfAbDRNuoU44cmubq19vHW2teSXJzkpA06FgBMS38FwFagvwJgQ23UKcZHJPn0xPK1SR42uUGt9fQkpydJay07d+5c+1H/4vK17wOAdbEun+sb76D9VbIBfZb+CmBu6K8OQp8FMDc2ss+a2UVKWmu7WmsPbq09OEkZw63W+g+zrmGr3rSdttN2W+u2zm03c2Prs/zb13babmvdtN3ctN3M6a/ctJ+2m/ebtpubttvHRgWE1yU5amL5yGEdAMwT/RUAW4H+CoANtVGnGL8vyTG11vuk77gen+TnN+hYADAt/RUAW4H+CoANtSEjCFtre5M8I8lbklzVr2of3ohjbTG7Zl3AFqbtpqftpqftprcl2k5/tV9b4u83p7Td9LTd9LTd9LZE2+mv9mtL/P3mmPabnrabnrab3oa2Xem6biP3DwAAAADMsZldpAQAAAAAmD0BIQAAAACM2EZdpIRBrfWoJBclOSxJl2RXa+3c2Va1tdRaD0lyeZLrWmuPmXU9W0Wt9R5JXprk/un/7T21tfau2Va1NdRafyXJ09K324eSPKW19pXZVjW/aq0vS/KYJDe21u4/rDs0yWuSHJ3kmiS1tXbzrGpkZfRZa6O/mp4+a3r6rJXTX20f+qu102dNR381Pf3V6syizzKCcOPtTXJma+3YJMclOaPWeuyMa9pqfjn9ZMyszrlJ3txa+54kD4g2XJFa6xFJnpnkwcMH8SHprxTI/l2Q5FFL1p2V5LLW2jFJLhuWmX/6rLXRX01PnzUFfdaqXRD91Xahv1o7fdZ09FdT0F9N5YJscp8lINxgrbXrW2tXDI+/mP4D5IjZVrV11FqPTPJT6X+lYYVqrf8mySOTnJ8krbWvtdY+N9uqtpQdSb6x1rojyTcl+cyM65lrrbW3J7lpyeqTklw4PL4wycmbWhRT0WdNT381PX3WmumzVkh/tX3or9ZGnzUd/dWa6a9WYRZ9loBwE9Vaj07yoCTvmXEpW8kfJvnVJF+fdSFbzH2SfDbJy2ut76+1vrTWerdZF7UVtNauS/LCJJ9Kcn2Sz7fW/mq2VW1Jh7XWrh8e35D+FCC2EH3WqumvpqfPmpI+a13or7Y4/dVU9FnT0V9NSX+1bja0zxIQbpJa692TvC7Js1prX5h1PVtBrXXxfPt/mHUtW9COJD+Q5LzW2oOS/EucMrMitdZ7pv9l5j5Jdia5W631F2db1dbWWuvSzzXCFqHPWh391Zrps6akz1pf+qutR3+1evqsNdFfTUl/tf42os8SEG6CWuud03dcr2qtvX7W9WwhD0/y2FrrNUkuTvKjtdZXzrakLePaJNe21hZ/SX1t+s6Mg/uxJJ9orX22tfavSV6f5IdnXNNWtLvWeniSDPc3zrgeVkifNRX91dros6anz1o7/dUWpb+amj5revqr6emv1seG9lkCwg1Way3p5yi4qrX24lnXs5W01p7TWjuytXZ0+glM/6a15leGFWit3ZDk07XW7x5WnZDkIzMsaSv5VJLjaq3fNPz3e0JMPjyNS5KcMjw+JckbZ1gLK6TPmo7+am30WWuiz1o7/dUWpL+anj5revqrNdFfrY8N7bN2rOfOWNbDkzwxyYdqrR8Y1j23tXbpDGtiHH4pyatqrXdJ8vEkT5lxPVtCa+09tdbXJrki/RXy3p9k12yrmm+11lcnOT7JQq312iRnJzknSau1nprkk0nq7CpkFfRZzIo+awr6rNXRX20r+itmRX81Bf3V6s2izypdZ5oNAAAAABgrpxgDAAAAwIgJCAEAAABgxASEAAAAADBiAkIAAAAAGDEBIQAAAACMmIAQAAAAAEZMQAgAAAAAIyYgBAAAAIARExACAAAAwIgJCAEAAABgxASEAAAAADBiAkIAAAAAGDEBIRxEKeVtpZSXzvN+SynXlFJ+Y2K5K6X84nrs+wDHPH44zpEbeRyAzVZKeV4p5eoN2O/Rw+fmI9Z73+t17PV676WUJ5dS9k4sr7rPWLqP9bQe9Q2v2/D+FoD5NE2/Psv/F4CDERAyl0opFwwfnK9f5rmThuc25EvDMn4myX/apGOllHJEKeWrpZTPlFJ2bNZxp/DOJIcn+cysCwFYqVLKN5ZSnl9K+Vgp5cullJtKKe8rpTxzYrMXJjluVjVOmvgisdzt2avY1afTf2a/Z9jvkcM+jt+Iupexbn1GKeUXSylvL6V8vpTyL6WUK0spv19KOWLtZd7hOI8opfxVKeWzpZSvlFI+WUp5bSnlOyY2OzzJa9fzuABb2cT3uMXb50sp7yqlPHqTjv+24bj/ccn6Rwzrj96MOg7gDv0xzBMBIfPsU0keU0o5bMn6pyf55Fp2XEq580q37brupq7rvrCW463SqUnelORzSX56E4+7Kl3Xfa3ruhu6rvv6rGsBWIXzkjwpyX9OcmySH0nyx0nusbhB13Vf6rpuz2zK26+T0n+hmLz995W+uOu6W4fP7H/doPoOdvx16TNKKecnOT/J25OcmP5v+Mwk357kzDUXevtxvjfJXyf5WJIfS/K9SZ6c5Jok37K43fCevrJexwXYJv4+t/dVxyW5IsmflVK+c9odrub7W5KvJDm7lPLN0x5vo8y6P4YDERAyzz6W5N3p/4c8SVJKuXeSH0/y8ol19yylvLKU8qlhNMhHSylnllLKxDYXlFLeWkr5pVLKNUm+Oowiuc8wOuArpZRPl1LOWHrq7/6WSym/WUq5YRh9clEp5e4T2/xAKeUvSyk3llK+NIxOedTB3nAp5U7pA8ILklyY5PRltnlAKeWdwyjDj5VS6n529y2llFeUUr5YSrm2lPKcJfu5c+lPJfvE8P4/XEp5+pJtnlZKuWp4/qZhxMaRw3P7nI5VSjlu2ObLpZSbSyl/Wkq518TzzyulXF36UaD/axj58bZSyjEHaxuAdXJykv/add2fdV33ia7rPth13QVd1/324gZlyWm2K/3sKqU8oZTyT8Nn5jtLKY8pBzmNqJRy2NBHfXb4vP6fpZRHLrPpTcMXisnbLcM+Fj+Pf7qU8t7h+FeWUn504jhLT2n69HD/t8P6a5bUdbD3+oND//mlofbXlzuOrFv6Pu/QZ5TeS4b2+nIp5eOllN8ppdz1APv42SRPTXJK13W/0XXdO7uu+2TXdX/Tdd2Tkjx/2vqW8ZNJvtR13RnDv5FPdF33t13XPbvrug9NHOe2U4yHfyfLjfS8YGL7Hx/+xl8upVxXSnl5KeVbV1EXwFbwtYm+6qokZyW5c5LvT5JSyi+XUj4wfEbfUEq5uJRy+OKLJ/qMnyqlvKOU8pUkTxue+6Whf/rK8F3o18u+Z129LslXh+Mua7nvMsP6vaWUJ08s32v4rN49HPOjpZSnHmC/B+zXl+mPYW4ICJl3u5I8rZTbwr6nJbksdxxBeNckV6b/0nds+i8I/28mgsXBQ5P8aPpRGA9I8rUkb0jyb5I8Mv1ovZ9K8qAV1PV/Jzk0yfFJHp/kMUl+beL5b0nymvQjU34gyVuSXFJKue9B9nvi8H7+MskrkpxQJobBl1K+Mcml6UcXPjS3j4K519IdJTk7/QiLByb53SS/U0o5YeL5l6Q/ffrp6UdG/HaS3yulnDocSdiLxQAAIABJREFU6weT/P/Da787yb9LctH+Ci+lfHuSv0py7VDbTye5f/Y99erwJP9Pkl9I8sNJvjnJy/a3X4B1dn2SR5VSDl3l6w742TV8Zr4qyavT9zG/n+QPD7TD4TP9b4d9nZi+/7k0yV+XfgTbar04/Wf5g9KfuvTnk1+4lviB4f5nh/f2kInnDvZej03yd0neleTB6fvWW4e6v2GFtZYkNyb5+fR90LOSPCXJcw/wmicmubrruouXe7LrupvXsb7rk9yzlHLiCrdP+lPTJ0d4PjbJ3vR/4wyB7RuTXJz+S/LJSY5O8vqJ/88B2FZKKXdJclr6wO6KiaeeneT7kjwuyb3TfzYu9aIkv5e+n/jzUsrzhtc9Z1j3y+m/y5y95HVfSfLrSX5laQC4ytq/MX1/8oD0feKxSX4pyS0H2H49+3XYXF3XubnN3S39CLq3JvmGJP+cPmg7JH349DPpw7+9B3j9uUn+esn+Ppfk7hPrfjxJl+S7JtYdmv4D/6UT6962zPIHlxzvvCTvOsh7+mCSX9/ffod1b0zyoonlNyf5LxPLT0vypST3nFh3/+F9/MbEui7Jf1uy76uS/O7w+D5Jvp7ke5Zs81tJPjA8flySzyf5lv28n+OH4xw5LD9/+PvcZWKbBwzbPHJYfl76L0vfNrHNvx9q+YZZ/7tzc3Pb/rckD0//I9OtSf4x/Q9RJycpE9s8L30QNbl8wM+u9OHg3y851n8YPgMfMSwfvWT5ycPn5o4lr/ubJH+45DW3DJ//k7cfGrZZ/Dw+dWIfO4b3+fz9HPvIYfn4JcdeyXu9IMnFS15316HGkyfe296J5+/QZ+znb/MrST42sbx0Hx9JcskK/sZrri/9j+gvHd73P6fvj38tyVFL9tsl+cVlajgqfcj4+xPr3pbknCXb3XvYxwNn/d+Gm5ub23rchs/gvRN91deH+585wGseNHwWHjEsL34mP3Fim28aPscfteS1T0ryuYnltw2f3yXJPyS5cFj/iGGfRy85xpFL9rc3yZOHx6emDxuX7buytn79EbP+W7m5Lb3N8wUQIF3XfaWU8or0vzp9c/ovPH+e/hecJLedlvur6UfyHZk+VLxz9p2n8Kqu6740sXxskj1d1912GlnXdTeVUj66gtI+uGT5M+lPR1qs6dvSj2L80fTzIu0Y6jrQ6VdHZN8RjBcmeVEp5Xld1+0dar6qG0ZJDDVfWUr5/DK7/MAyNS7O5/jg9J3m5UsGLexI/6U56ede+niST5RS/jp9x/b6bv/zct0vybu7rvvaRG0fHGq7X/rRjEnyma7rPrukrpJ+FOSn9rNvgHXRdd3/LP0cSA9N8kPpR5C/NslfllIe23Vdt5+XHuyz69j0P2xNetdBynlI+j7ic0s+i++a5MtLtn1K+i86k67d3/G6rttbSnlv+s/f1TrYe31Iku8qpXxpyeu+IcmKp4wopZyW/oevo5PcLX0fdKCzW1Y6ym7N9XX9XIlPK6X8RvofKR+SfpTKb5ZSHtN13dv2W2Q/5cifp/97TJ5d8JAkx5VSnrHMy47Jvv02wFb1niSnDI+/Jf0PTReVUj7Vdd3lpb9A1nPS9533yO2f/d+R5LqJ/bx34vH9knxjkteVUib76kOSfEMp5dsm+66u67pSyn9OP3rvD6Z8Hz+Y5CNd1y3tb/dnNf06zB0BIVvBrvTD0Y9K8vKu6/51yQfumek7mF9J8v4kXxwe/9SS/fzLMvve3xfBg/nakuUud/xSc0H6UQG/muQT6TuEi5Pc5QD7PDV9B/f+Je/vkPSn675hHWtcvP/h7DtEvh8S0XVfKqU8OP1omx9LPxLm90spJ3Rdt/RL6lrrmqwJYEMNP7i8c7i9aJhD7hXpw8K/28/LVvLZtdo+5U7pR3c/bpnnln42Xzf5g9YGO9h7vVP69jpnmdf+80oOUEr5ufQXhzkrfZt/IcnPJXnBAV720aws8FxzfYu6rrsh/Wnjry6lnJX+/zPOTj9CZR/Dj5avTvKv6UcWTv6buFP6U+VescxLb1hNXQBz7stL+qwrSiknJXlWKeW56U+7fUX6aTH2pB/k8dbs+11p8vvbYh/0c0n+9zLHvGnpiq7r/qaU8pdJ/mv6wRuTFi+aNTlv/SFZ23eS1fTrMHcEhMy9rus+Ukp5X/qg6snLbPLIJG/uum5yfqSVjBD4SJJvK6V8Z9d1/zS87p5J7pt9R2ms1iOT/GrXdZcM+71bkn+bfq7EfZTbL07yO+m/WEx6bvqLlbxhqPn0Uso9uq773PDa+6WfR3E1Ft/fvbuue9P+Nuq67tb0I//eXko5ezj+z2f59vlwkqeUUu6yOIqwlPKAobZl3zfAnLhquF9uPteV+kj6EYmTjjvIay5Pf2rUF7quu3ENx5483keSZJiw/aFZPoxKbg8BD5niOJenn0Pvnw4w4vJgHpnk/V3XvXhxxeScu/vxyiT/o5Ty+G6ZeQhLKfccRtivR3376Lrua6WUj6fvz/fnhemn13hoN1xEZsLlSe63iUEvwDy5Nf0IwIcM98/quu7LyW3z+B7Mh9Of7vtvu667dBXH/dX0U4q8b8n6xX53Z26/cNcDc8fR6v+Q5KmllCNXOIpwvft12FRG7LBV/GSShcUgb4mPJjm+lPIjpZT7llL+S5KHrWCfb01/qvArSikPGcKsV6Sfd2KtXyg+muQXSinfV0p5YPrQ70Bfwk5MP0LyT7quu3Lyln404k8MX5z+NP0IyVeW/mrGx6WfOH5VQ9aHLycvS/KSUsoTSynfNezvqaWUX0tuu4Llr5T+SpD3Tj9H11EZvnwu44/Sn0JwQSnl/sOVuV6Rfk6uv19NfQAbpZTyd6WU/1BKeXAp5TuGizf99/Tz1P7tGnb94iQPL6X89tAXPTb9CPdk/33Kq9KPMv+LUspPDFc2fFgp5TmllJOXbHtoKeXbl9y+eck2Z5VSHj1MhH5ekm8b3tty9qSfE+onhn3dcxXv9XfSTw7/ylLKQ0sp9xn64HNLKQcKzyZ9NMn3DX3Nd5ZSfjn9HMP71XXda9NfLOvCUsrzSyk/VEq5dynl35VSXp7kN9ervlLK00spf1JK+cmhj/zeoX88MfsZ0V/6q17+x9x+pc3Fv9Pij3i/leSkUsqLSykPHN73o0op55d+YnuA7eIuE5+Bx5RSfjP96cRvSPKx9P3imcPn88npPx8PaJgq6nfSX3jxjFLKd5dS7ldKeXwp5fcO8LqPJDk//cWwJl2dfkqq55VSvmf47vIHuWOf/ephm0tKKT821HtCKeXf7+dwq+nXYe4ICNkSuq67peu6fYaND56f/vSkN6af7+eeSf7bCvbZpR/+/S9J/j7Jm9JfPfij6X+dWounpP/v671J/iz95OZLf7WadHqS93Rdt9wcfH+Tfsj804bRCI9O8q3Dvl+VviOb5heq04fX/nr60O+y9HOFfHx4/ub0pza/Of0w/t9Pf8GU85fbWdd1u5P8RPpTBN6Xvj2vTH/FZ4B58Zfp57G9NP3n/cvTf1l5+AHmWD2oYeqFXxhuH0o/9cVvDE8v26d0XfeV9FeIv3yo438neX36kX9L59F9Y/qLXkzefnfJNs9O3yd+IP2o+5O6rvvMfo799SRnJKnp5zJ8/8readJ13VXpp6i4e5K3pO9DXpJ+RMjnVribP0n/I9LLh2M/LP0FUg527FPS91/HD8e+Kv2pyrvTn0K2XvW9N/2cUX+cfuTJO9O31bOy/y+yxw+veUvu+Hc6d6jrb9PPTfz96f+/4x/T98NfTH9KMsB28X/l9s/AK5L8bJLTuq57Zdd1/5j+SsBPT//5/OzsG94tq+u65yf5T+nnp/9gknekn1rqmoO89Ldy+zzri/vam35uxHul74f+OP33oq9PbHNL+n76yvTTRS32Ocv+qLPKfh3mTlnHMy9gyxtGY1yb/orA/9+s6wFg6yqlPCn9F4RvXZwWYoOOc3z60Y9HrWIidQAAuI05CBm14RSwvel/DbpX+onHuyRtlnUBsPWUUp6dPqi7Kf0cS7+X5H9sZDgIAADrQUDI2H1T+iHnR6c/1fgfkjxiOF0WAFbj+9PPO3ho+gnPX5n+hycAAJhrTjEGAAAAgBFzkRIAAAAAGLF5OcXYMEYA9qfMuoAl9FkALEd/BcBWsU+fNS8BYT7zmc/MuoQNt7CwkD179sy6jC1J201P201P201vvdpu586d61DN+tvufZZ/+9PTdtPTdtPTdtPTXx3cPP37mqdaEvUcyDzVksxXPfNUS6KeA5mnWpKN77OcYgwAAAAAIyYgBAAAAIARExACAAAAwIgJCAEAAABgxASEAAAAADBiAkIAAAAAGDEBIQAAAACMmIAQAAAAAEZMQAgAAAAAIyYgBAAAAIARExACAAAAwIgJCAEAAABgxASEAAAAADBiAkIAAAAAGDEBIQAAAACMmIAQAAAAAEZsx6wLWE+3nvbYWZdwB4e85JJZlwAAB7W0/9w9ozoW6T8B5sfux/3wrEu43RveOesKALYtIwgBAAAAYMQEhAAAAAAwYgJCAAAAABgxASEAAAAAjJiAEAAAAABGTEAIAAAAACMmIAQAAACAERMQAgAAAMCICQgBAAAAYMQEhAAAAAAwYgJCAAAAABgxASEAAAAAjJiAEAAAAABGTEAIAAAAACMmIAQAAACAERMQAgAAAMCICQgBAAAAYMQEhAAAAAAwYgJCAAAAABgxASEAAAAAjJiAEAAAAABGTEAIAAAAACMmIAQAAACAEdsx6wIAYL3UWo9KclGSw5J0SXa11s6ttR6a5DVJjk5yTZLaWru51lqSnJvk0UluSfLk1toVs6gdAABgVowgBGA72ZvkzNbasUmOS3JGrfXYJGcluay1dkySy4blJDkxyTHD7fQk521+yQAAALMlIARg22itXb84ArC19sUkVyU5IslJSS4cNrswycnD45OSXNRa61pr705yj1rr4ZtcNgAAwEw5xRiAbanWenSSByV5T5LDWmvXD0/dkP4U5KQPDz898bJrh3XXT6xLrfX09CMM01rLwsLCxhU+A7tnXcASW7l9d+zYsaXrnyVtNz1tNz1tBwA9ASEA206t9e5JXpfkWa21L9Rab3uutdbVWrvV7K+1tivJrmGx27Nnz7rVyr62cvsuLCxs6fpnSdtNT9tNb73abufOnetQDQDMjlOMAdhWaq13Th8Ovqq19vph9e7FU4eH+xuH9dclOWri5UcO6wAAAEbDCEIAto3hqsTnJ7mqtfbiiacuSXJKknOG+zdOrH9GrfXiJA9L8vmJU5EBAABGQUAIwHby8CRPTPKhWusHhnXPTR8MtlrrqUk+mWTxnONLkzw6ydVJbknylM0tFwAAYPYEhABsG621dyQp+3n6hGW275KcsaFFAcAStdajklyU/qJZXZJdrbVza62HJnlNkqOTXJOkttZuHkbIn5v+R61bkjy5tXbFLGoHYHsyByEAAMDm2pvkzNbasUmOS3JGrfXYJGcluay1dkySy4blJDkxyTHD7fQk521+yQBsZwJCAACATdRau35xBGBr7YtJrkpyRJKTklw4bHZhkpOHxycluai11rXW3p3kHosX3wKA9eAUYwAAgBmptR6d5EFJ3pPksImLZd2Q/hTkpA8PPz3xsmuHdXe4sFat9fT0IwzTWsvCwsKa69u95j2snx07dqzLe1ov6tm/eaolma965qmWRD0HMk+1JBtfj4AQAABgBmqtd0/yuiTPaq19odZ623Otta7W2q1mf621XUl2DYvdnj171q3WebB3797M03taWFhQz37MUy3JfNUzT7Uk6jmQeaolWb96du7cuex6pxgDAABsslrrndOHg69qrb1+WL178dTh4f7GYf11SY6aePmRwzoAWBdGEAIAAGyi4arE5ye5qrX24omnLklySpJzhvs3Tqx/Rq314iQPS/L5iVORAWDNBIQAAACb6+FJnpjkQ7XWDwzrnps+GGy11lOTfDLJ4jnHlyZ5dJKrk9yS5CmbWy4A252AEAAAYBO11t6RpOzn6ROW2b5LcsaGFgXAqJmDEAAAAABGTEAIAAAAACMmIAQAAACAERMQAgAAAMCICQgBAAAAYMQOehXjWutRSS5KcliSLsmu1tq5tdZDk7wmydFJrklSW2s311pLknOTPDrJLUme3Fq7YmPKBwAAAADWYiUjCPcmObO1dmyS45KcUWs9NslZSS5rrR2T5LJhOUlOTHLMcDs9yXnrXjUAAAAAsC4OGhC21q5fHAHYWvtikquSHJHkpCQXDptdmOTk4fFJSS5qrXWttXcnuUet9fB1rxwAAAAAWLODnmI8qdZ6dJIHJXlPksNaa9cPT92Q/hTkpA8PPz3xsmuHdddPrEut9fT0IwzTWsvCwsJqa9/H7jXvYX0tfU87duxYl/c5RtpuetpuetpuetoOAABg61hxQFhrvXuS1yV5VmvtC7XW255rrXW11m41B26t7Uqya1js9uzZs5qXbwlL39PCwsI+61gZbTc9bTc9bTe99Wq7nTt3rkM1AAAAHMiKrmJca71z+nDwVa211w+rdy+eOjzc3zisvy7JURMvP3JYBwAAAADMmZVcxbgkOT/JVa21F088dUmSU5KcM9y/cWL9M2qtFyd5WJLPT5yKDAAAAADMkZWcYvzwJE9M8qFa6weGdc9NHwy2WuupST6ZZPGc40uTPDrJ1UluSfKUda0YAAAAAFg3Bw0IW2vvSFL28/QJy2zfJTljjXUBAAAAAJtgRXMQAgAAAADbk4AQAAAAAEZMQAgAAAAAIyYgBAAAAIARExACAAAAwIgJCAEAAABgxASEAAAAADBiAkIAAAAAGDEBIQAAAACMmIAQAAAAAEZMQAgAAAAAIyYgBAAAAIARExACAAAAwIgJCAEAAABgxASEAAAAADBiAkIAAAAAGDEBIQAAAACMmIAQAAAAAEZMQAgAAAAAIyYgBAAAAIARExACAAAAwIgJCAEAAABgxASEAAAAADBiAkIAAAAAGDEBIQAAAACMmIAQAAAAAEZMQAgAAAAAIyYgBAAAAIARExACAAAAwIgJCAEAAABgxASEAAAAADBiAkIAAAAAGDEBIQAAAACMmIAQAAAAAEZMQAgAAAAAIyYgBAAAAIARExACAAAAwIgJCAEAAABgxASEAAAAADBiAkIAAAAAGDEBIQAAAACMmIAQAAAAAEZMQAgAAAAAIyYgBAAAAIARExACAAAAwIgJCAEAAABgxASEAAAAADBiAkIAAAAAGDEBIQAAAACMmIAQAAAAAEZMQAgAAAAAIyYgBAAAAIARExACAAAAwIjtmHUBALBeaq0vS/KYJDe21u4/rHtektOSfHbY7LmttUuH556T5NQktyZ5ZmvtLZteNAAAwIwJCAHYTi5I8kdJLlqy/g9aay+cXFFrPTbJ45PcL8nOJG+ttd63tXbrZhQKAAAwL5xiDMC20Vp7e5KbVrj5SUkubq19tbX2iSRXJ3nohhUHAAAwp4wgBGAMnlFrfVKSy5Oc2Vq7OckRSd49sc21wzoAAIBRERACsN2dl+T5Sbrh/kVJnrqaHdRaT09yepK01rKwsLDeNc7U7lkXsMRWbt8dO3Zs6fpnSdtNT9tNT9sBQE9ACMC21lq7Lf+qtb4kyZuGxeuSHDWx6ZHDuuX2sSvJrmGx27NnzwZUyqKt3L4LCwtbuv5Z0nbT03bTW6+227lz5zpUAwCzIyAEYFurtR7eWrt+WHxckiuHx5ck+dNa64vTX6TkmCTvnUGJAIxMrfVlSR6T5MbW2v2Hdc9LclqSzw6bPbe1dunw3HOSnJrk1iTPbK29ZdOLBmBbExACsG3UWl+d5PgkC7XWa5OcneT4WusD059ifE2SpydJa+3DtdaW5CNJ9iY5wxWMAdgkFyT5oyQXLVn/B621F06uqLUem+TxSe6X/gett9Za76vPAmA9CQgB2DZaa09YZvX5B9j+BUlesHEVAcC+Wmtvr7UevcLNT0pycWvtq0k+UWu9OslDk7xro+oDYHwEhAAAAPPhGbXWJyW5PMmZrbWbkxyR5N0T21w7rNvHRlxUa54uZDVvF5VRz/7NUy3JfNUzT7Uk6jmQeaol2fh6BIQAAACzd16S56efEuP5SV6U5Kmr2cF2v6jW3r175+qCPPN2gaB5qmeeaknmq555qiVRz4HMUy3Jxl9YS0AIAAAwY6212wbr1VpfkuRNw+J1SY6a2PTIYR0ArJs7zboAAACAsau1Hj6x+LgkVw6PL0ny+FrrXWut90lyTJL3bnZ9AGxvRhACAABsolrrq5Mcn2Sh1nptkrOTHF9rfWD6U4yvSfL0JGmtfbjW2pJ8JMneJGe4gjEA601ACAAAsIlaa09YZvX5B9j+BUlesHEVATB2TjEGAAAAgBETEAIAAADAiB30FONa68uSPCbJja21+w/rnpfktCSfHTZ7bmvt0uG55yQ5NcmtSZ7ZWnvLBtQNAAAAAKyDlcxBeEGSP0py0ZL1f9Bae+HkilrrsUken+R+SXYmeWut9b4m0QUAAACA+XTQU4xba29PctMK93dSkotba19trX0iydVJHrqG+gAAAACADbSWqxg/o9b6pCSXJzmztXZzkiOSvHtim2uHdfuotZ6e5PQkaa1lYWFhDaX0dq95D+tr6XvasWPHurzPMdJ209N209N209N2AAAAW8e0AeF5SZ6fpBvuX5TkqavZQWttV5Jdw2K3Z8+eKUuZX0vf08LCwj7rWBltNz1tNz1tN731arudO3euQzUAAAAcyFQBYWvttsF6tdaXJHnTsHhdkqMmNj1yWAcAAAAAzKGDzkG4nFrr4ROLj0ty5fD4kiSPr7XetdZ6nyTHJHnv2koEAAAAADbKQUcQ1lpfneT4JAu11muTnJ3k+FrrA9OfYnxNkqcnSWvtw7XWluQjSfYmOcMVjAEAAABgfh00IGytPWGZ1ecfYPsXJHnBWooCAAAAADbHVKcYAwAAAADbg4AQAAAAAEZMQAgAAAAAIyYgBAAAAIARExACAAAAwIgJCAEAAABgxASEAAAAADBiAkIAAAAAGDEBIQAAAACMmIAQAAAAAEZMQAgAAAAAIyYgBAAAAIARExACAAAAwIgJCAEAAABgxASEAAAAADBiO2ZdAAAAABzM7sf98KxLuKM3vHPWFQCsGyMIAQAAAGDEBIQAAAAAMGICQgAAAAAYMQEhAAAAAIyYgBAAAAAARkxACAAAAAAjJiAEAAAAgBETEAIAAADAiAkIAQAAAGDEBIQAAAAAMGICQgAAAAAYMQEhAAAAAIyYgBAAAAAARkxACAAAAAAjJiAEAAAAgBETEAIAAADAiAkIAQAAAGDEBIQAAAAAMGICQgAAAAAYMQEhAAAAAIyYgBAAAAAARkxACAAAAAAjJiAEAAAAgBETEAIAAADAiAkIAQAAAGDEBIQAAAAAMGICQgAAAAAYMQEhAAAAAIyYgBAAAAAARkxACAAAAAAjJiAEAAAAgBETEAIAAADAiAkIAQAAAGDEBIQAAAAAMGICQgAAAAAYMQEhAAAAAIyYgBAAAAAARkxACAAAAAAjJiAEAAAAgBETEAIAAADAiAkIAQAAAGDEBIQAAAAAMGICQgAAAAAYsR2zLgAA1kut9WVJHpPkxtba/Yd1hyZ5TZKjk1yTpLbWbq61liTnJnl0kluSPLm1dsUs6gYAAJglIwgB2E4uSPKoJevOSnJZa+2YJJcNy0lyYpJjhtvpSc7bpBoBAADmioAQgG2jtfb2JDctWX1SkguHxxcmOXli/UWtta619u4k96i1Hr45lQIAAMwPpxgDsN0d1lq7fnh8Q5LDhsdHJPn0xHbXDuuuzxK11tPTjzJMay0LCwsbV+0M7J51AUts5fbdsWPHlq5/lrTd9LTd9LQdAPQEhACMRmutq7V2U7xuV5Jdw2K3Z8+e9S2MO9jK7buwsLCl658lbTc9bTe99Wq7nTt3rmp7c+YCMG+cYgzAdrd78dTh4f7GYf11SY6a2O7IYR0AbLQLYs5cAOaIgBCA7e6SJKcMj09J8saJ9U+qtZZa63FJPj9xKjIAbBhz5gIwb5xiDMC2UWt9dZLjkyzUWq9NcnaSc5K0WuupST6ZpA6bX5r+dK2r05+y9ZRNLxgAbjeXc+bO2zy182Te5rCcp3rmqZZkvuqZp1oS9RzIPNWSbHw9AkIAto3W2hP289QJy2zbJTljYysCgNUzZ+7WsHfv3rma/3Oe5iOdp1qS+apnnmpJ1HMg81RLsvHz5jrFGAAAYPbMmQvAzBhBCAAAMHuLc+aek33nzH1GrfXiJA+LOXMB2AAHDQhrrS9L8pgkN7bW7j+sOzTJa5IcneSaJLW1dnOttSQ5N/2cTrckeXJr7YqNKR0AAGDrMWcuAPNmJSMIL0jyR0kumlh3VpLLWmvn1FrPGpZ/LcmJSY4Zbg9Lct5wDwAAQMyZC8D8OegchK21tye5acnqk5JcODy+MMnJE+svaq11rbV3J7nH4jwaAAAAAMD8mXYOwsMm5r24Iclhw+Mjknx6Yrtrh3X7zJFRaz09yelJ0lpbl0s1717zHtbX0vc0b5fI3kq03fS03fS03fS0HQAAwNax5ouUtNa6Wms3xet2Jdk1LHbzdOno9bL0Pc3bJbK3Em03PW03PW03vfVqu507d65DNQAAABzIQU8x3o/di6cOD/c3DuuvS3LUxHZHDusAAAAAgDk07QjCS5Kckv5KW6ckeePE+mfUWi9Of3GSz0+cigwAAAAAzJmDBoS11lcnOT7JQq312iRnpw8GW6311CSfTFKHzS9N8ugkVye5JclTNqBmAAAAAGCdHDQgbK09YT9PnbDMtl2SM9ZaFAAAAACwOaadgxAAAAAA2AYEhAAAAAAwYgJCAAAAABgxASEAAAAAjJiAEAAAAABGTEAIAAAAACMmIAQAAACAERMQAgAAAMCICQgBAAAAYMQEhACn1csSAAAgAElEQVQAAAAwYgJCAAAAABgxASEAAAAAjJiAEAAAAABGTEAIAAAAACMmIAQAAACAERMQAgAAAMCICQgBAAAAYMQEhAAAAAAwYgJCAAAAABgxASEAAAAAjJiAEAAAAABGTEAIAAAAACMmIAQAAACAERMQAgAAAMCICQgBAAAAYMQEhAAAAAAwYgJCAAAAABgxASEAAAAAjJiAEAAAAABGTEAIAAAAACMmIAQAAACAERMQAgAAAMCICQgBAAAAYMQEhAAAAAAwYgJCAAAAABgxASEAAAAAjJiAEAAAAABGTEAIAAAAACMmIAQAAACAERMQAgAAAMCICQgBAAAAYMQEhAAAAAAwYgJCAAAAABgxASEAAAAAjJiAEAAAAABGTEAIAAAAACMmIAQAAACAERMQAgAAAMCICQgBAAAAYMQEhAAAAAAwYgJCAAAAABgxASEAAAAAjJiAEAAAAABGTEAIAAAAACMmIAQAAACAERMQAgAAAMCICQgBAAAAYMQEhAAAAAAwYgJCAAAAABgxASEAAAAAjJiAEAAAAABGbMesCwAAmHTraY+ddQm3OeQll8y6BAAA2HBGEAIAAADAiAkIAQAAAGDEBIQAAAAAMGLmIARgFGqt1yT5YpJbk+xtrT241npoktckOTrJNUlqa+3mWdUIAAAwC0YQAjAmP9Jae2Br7cHD8llJLmutHZPksmEZAABgVIwgBNgG5umqr0mSN7xz1hWs1ElJjh8eX5jkbUl+bVbFAIAR7wDMgoAQgLHokvxVrbVL8iettV1JDmutXT88f0OSw5Z7Ya319CSnJ0lrLQsLC5tR76bZPesC5thq/9Y7duzYdv8+Nou2m562m94ct92PtNb2TCwvjng/p9Z61rDsBy0A1o2AEICxeERr7bpa672S/HWt9X9NPtla64bwcB9DmLhrWOz27Nmz3GZsQ6v9Wy8sLKz6NfS03fS03fTWq+127ty5DtUckBHvAGyoNQWEhr8DsFW01q4b7m+stb4hyUOT7K61Ht5au77WeniSG2daJADM2Yh3o8z3b95GoM5TPfNUSzJf9cxTLYl6DmSeakk2vp71GEFo+DsAc63Werckd2qtfXF4/BNJfjvJJUlOSXLOcP/G2VUJAEmMeN8y9u7dO1ejd+dpNPE81ZLMVz3zVEuingOZp1qSjR/1vhFXMT4p/bD3DPcnb8AxAGA1DkvyjlrrB5O8N8lftNbenD4Y/PFa68eS/NiwDAAzMzniPckdRrwniRHvAGyEtY4gNPz9AJa+p3kbnrqVaLvpabvpbaW2m7fPv3lru9bax5M8YJn1/5zkhM2vCAD2ZcQ7ALOy1oDQ8PcDWPqe5m146lai7aan7aan7aa3XqfcbMKk7wAwTw5L8oZaa9J/V/vT1tqba63vS9Jqracm+WSSOsMaAdiG1hQQmvAdAABgfRjxDsCsTD0HYa31brXWb158nH74+5W5ffh7Yvg7AAAAAMy1tVykxITvAAAAALDFTX2KseHvAMB2d+tpj13V9ht9waBDXnLJBh8BAIAxWssIQgAAAABgixMQAgAAAMCIrekqxmwdqz1FaqM5RQoAAABgPhhBCAAAAAAjJiAEAAAAgBETEAIAAADAiJmDEACAVVvv+Y13r/H15jcGAJieEYQAAAAAMGICQgAAAAAYMQEhAAAAAIyYgBAAAAAARkxACAAAAAAjJiAEAAAAgBHbMesCAABYmVtPe+ysSwAAYBsyghAAAAAARkxACAAAAAAj5hTjDbT0NKDdM6oDAAAAAPbHCEIAAAAAGDEBIQAAAACMmIAQAAAAAEZMQAgAAAAAI+YiJQAAwKZZeiG/mXrDO2ddAQDMBSMIAQAAAGDEBIQAAAAAMGJOMWYmVntqye4NqiNJDnnJJRu4dwAAAID5ZgQhAAAAAPwf9u4/3raqrhf+Z8Q20ywptxEHMLxJepGu+OMiSRmJ3oC4oP0YF0tDJY4V/korlVvhk9GDXZV43YznHkWBMnGEGlwjtUgjHxMFMhFJJUUB4cC5ImooxHnm88ecx5ab83PtH2vvPd/v12u/zppjjjnXd469zxprfdcYc4yYEYQAsMJW1Q36AQCA0TOCEAAAAABGTIIQAAAAAEZMghAAAAAARkyCEAAAAABGTIIQAAAAAEbMKsYAAAAAI7T5GU+adQjf6l0fmnUEo2UEIQAAAACMmBGEwJqx9ZTjV/T5Nu9i/15vvGRF4gAAAIDlJEEIAAAAe8jUTGA9McUYAAAAAEZMghAAAAAARkyCEAAAAABGzD0IAQAAYI1bVfdEdD9EWHMkCBm9lV4Zd1esjAsAAACsJAlCAABYYiv5BeTmXez35SMAsCsShLDKLPUHil19aNgVHyoAAABYCatpqvxiP0svuWWeum+REgAAAAAYMQlCAAAAABgxCUIAAAAAGDEJQgAAAAAYMQlCAAAAABgxCUIAAAAAGDEJQgAAAAAYMQlCAAAAABgxCUIAAAAAGDEJQgAAAAAYsblZBwCsbltPOX7WIQAAAADLyAhCAAAAABgxCUIAAAAAGDFTjAEAWPPcEgMAYHpGEAIAAADAiEkQAgAAAMCImWIMAAAALJnNz3jSrEP4Vu/60KwjgFXPCEIAAAAAGDEJQgAAAAAYMVOMAQAAgHVrVU15Nt2ZVcoIQgAAAAAYMQlCAAAAABgxU4wBAAAAVsCqmu4ME4wgBAAAAIARM4IQYEpbTzl+1iEAAADAohlBCAAAAAAjJkEIAAAAACO2bFOMa61HJzk7yV5J3tRaO3O5ngsApqW/AtY7t8RYH/RXACynZRlBWGvdK8kbkhyT5OAkz6y1HrwczwUA09JfAbAW6K8AWG7LNcX4sCTXt9Y+21q7J8mFSU5YpucCgGnprwBYC/RXACyr5ZpivF+SGye2b0ryxMkKtdaNSTYmSWstGzZsWPyz/uWViz8HAEtiSV7Xl98u+6tkGfos/RXAqqG/2gV9FsCqsZx91swWKWmtbWqtPaG19oQkZQw/tdarZh3DWv3RdtpO262tnyVuu5kbW5/lb1/babu19aPtVk3bzdxy9Fer6e9rNcUinrUTy2qLZzXFIp61E8syxHMfy5UgvDnJARPb+w9lALCa6K8AWAv0VwAsq+WaYvzRJAfVWh+evuM6McnPL9NzAcC09FcArAX6KwCW1bKMIGyt3ZvkBUnem+S6vqhduxzPtcZsmnUAa5i2m562m562m96aaDv91Q6tid/fKqXtpqftpqftprcm2m7G/dVqaqPVFEsinp1ZTbEkqyue1RRLIp6dWU2xJMscT+m6bjnPDwAAAACsYjNbpAQAAAAAmD0JQgAAAAAYseVapIRBrfWAJBck2SdJl2RTa+3s2Ua1ttRa90pyZZKbW2vHzTqetaLWuneSNyU5JP3f3vNaa/8w26jWhlrrryX5pfTtdk2S57bWvjHbqFavWuubkxyX5LbW2iFD2fcmeXuSA5PckKS21u6YVYzsHn3W4uivpqfPmp4+a/fpr/bM9tpr1s+/Wn5fq6m/rLV+R5LLk9w//ef7i1prp88ilomYXpzklCQlyRtba384ozgemf7vZZv/kOR3ZhjPo5K8Ocl3JflSkp9prW2ZRSwTMd2Q5KtJtia5t7X2hBnGsur6s9Xy3m6l3icZQbj87k3ystbawUkOT3JqrfXgGce01rw4/c2Y2TNnJ3lPa+1RSR4Tbbhbaq37JXlRkicMb0b3Sr9SIDt2XpKjF5S9IsllrbWDklw2bLP66bMWR381PX3WFPRZe+y86K/2xHm5b3vN+vlXy+9rNfWXdyd5SmvtMUkOTXJ0rfXwGcWSWush6ZODh6V/PT+u1vqIWcTSWvtUa+3Q1tqhSR6f5K4k75pFLBOe1Vr74SQfSvLLM45lm58Y2mmWycHV2p+tlvd2K/I+SYJwmbXWbmmtXT08/mr6X+R+s41q7ai17p/kp9Jny9lNtdYHJ3lyknOTpLV2T2vty7ONak2ZS/KAWutckgcm+eKM41nVWmuXp/8WdNIJSc4fHp+f5OkrGhRT0WdNT381PX3WoumzdpP+as/soL1m/fyr4ve1mvrL1lrXWvvasHm/4WeWK5H+xyRXtNbuGlbf/rskPz3DeLY5Ksm/tNY+P6sAWmv/3Fr77LB5/yRGe3+rVdWfrZb3div5PskU4xVUaz0wyWOTXDHjUNaSP0zym+mHYbP7Hp7k9iRvqbU+JslVSV7cWvvX2Ya1+rXWbq61vjbJF5J8Pcn7Wmvvm3FYa9E+rbVbhse3pp+Cwxqiz9pj+qvp6bOmpM9aEvqrtWXV/b5WQ385TIO8KskjkryhtTbLvvsTSc6otT4k/evSsemnaM7aiUneNusgkqTW+pNJjknyI7OOJX0y+X211i7J/2qtbZpFEKu0P1st7+1W7H2SEYQrpNb6oCTvSPKS1tpXZh3PWlBr3XbPkatmHcsaNJfkcUnOaa09Nsm/xpSZ3VJr/Z70304/PMmGJN9Za33WbKNa21prXWb7TTZ7SJ+1Z/RXi6bPmpI+a2npr9aW1fD7Wi39ZWtt6zCNdv8khw3TfGcVy3VJXpPkfUnek+Rj6e9vNzO11m9PcnySP59lHEMs35Z+JNjxq2S0/I+21h6XPmF5aq31ybMIYrX1Z6vsvd2KvU+SIFwBtdb7pe843tpae+es41lDjkhy/HDj1AuTPKXW+qezDWnNuCnJTRPfHl6U/kWFXXtqks+11m5vrf1bkncmedKMY1qLNtda902S4d/bZhwPu0mfNRX91eLos6anz1o8/dXasmp+X6uxvxwSTu/PbO8dmdbaua21x7fWnpzkjiSfnmU86ZNfV7fWNs84jqRPft3ZWvvMrANJ+pF7w7+3pb8/42EzCmW19Wer6b3dir1PkiBcZrXWkv4bgutaa6+fdTxrSWvtla21/VtrB6YfEv63rTXfiu+G1tqtSW4cVu5K+ntufHKGIa0lX0hyeK31gcP/36OyOm5Mu9ZckuSk4fFJSS6eYSzsJn3WdPRXi6PPWhR91uLpr9aWVfH7Wk39Za31ocMKp6m1PiDJ05L884xj+r7h34elv//gn80yniTPzCqZXpw+YfqyWQeRJLXW76y1fte2x0n+S/op4rOwqvqz1fTebiXfJ7kH4fI7Ismzk1xTa/3YUHZaa+3SGcbEOLwwyVuHIfWfTfLcGcezJrTWrqi1XpTk6vQr1P1jkpnci2OtqLW+LcmRSeZrrTclOT3JmUlarfXkJJ9PUmcXIXtAn8Ws6LOmoM/aM/qrPbO99mqtnTvL58/q+X2tpv5y3yTnD/ch/LYkrbX27hnEMekdwz0I/y3JqbOcSjskvp6W5PmzimGBByf5pfTTr2dtnyTvqrUmfW7oz1prM4lLf7ZLK/I+qXSd22wAAAAAwFiZYgwAAAAAIyZBCAAAAAAjJkEIAAAAACMmQQgAAAAAIyZBCAAAAAAjJkEIAAAAACMmQQgAAAAAIyZBCAAAAAAjJkEIAAAAACMmQQgAAAAAIyZBCAAAAAAjJkEIAAAAACMmQci6U0q5oZTyWyv0XB8opbxpiuNWLMblVko5sJTSlVJ+dNaxALD0htf4Z83ouY8cnn//JT7vq0op109sP6eUcu9SPgcAS2u5+gSgJ0HImlJKOW/oFLb93FlK+YdSyrGzjm2bUsrDSinnlFI+V0q5u5RycynlvaWUp5dSyqzjW4xSyvWllFctKL4xyb5Jrlj5iADWhon+6w8WlO8/lB85o9D22PAlV7ew7y2lPKuU0s0qrkV6e5L9Zh0EwNhM9I/v3M6+E4Z9277A+VD6zx1fHPb/6LD/wBULGNYxCULWor9P3zHsm+TwJFcn+YtSyg/ONKokpZRDk3wsyROTvDTJDyd5apJLkpyV5MGLOPe3L0WMS63ruq1d193add2/zToWgFXuG0leVEr5gaU6Yendb6nOtwe+keQPSil7zeC5l1zXdV/vum7zrOMAGKkvJDmulLLPgvLnJ/n8to2u6+4ZPnf8fysaHYyEBCFr0baO4dau665L8ook90vyn7ZXuZTy86WUK4bRhltKKX9ZSvmhif3bpsjWUsq7Syl3lVI+W0p5zoLz/EAp5T2llK+XUm4spbxwwf6S5PwkNyc5rOu6d3Vd9+mu667ruu4N6ZOFX5s45NtLKWeXUr5UStlcSjmrlDI3cb4PlFLOLaW8upRyS/qOM6WUw0splw9x3FFK+bNSyvdNHPeqYaRfLaV8ZrievyilfHcp5adLKZ8qpXy1lHJRKeXBE8c9rpTyV6WU20opXyulfLSUcvRkPEl+MMnpEyM4D1w4xXh32xNghD6U5J+S/P6OKpRSHjn0U18bfv53KeURE/ufU0q5t5TyE6WUf0xyd5KnTvQZvze8jn+5lHJGKeXbSim/M/Qzt5dSzljwfDvtI3fiTUl+IMnzdnIt95m2u70Rk6WUHxz6pC8NfcbHSynH7eS8jyilvGO4xjtKKe8rpfzwgjrHllKuKv1I/ttKKX9cSvnOPYkVgBXzmSQfTvKcbQWllIcleVqSt0yUfXOKcelHDf79sOtzQ/kHhnqllPLrw2eQe0op/1JKecnkE5Z+dOI/Dv3Ol0spHymlPHZi/077muGz1VtKKbcOfc2NpZTXL3XDwEqSIGRNK/2oulPSf0C6egfV7p/k95I8Ln0nszXJX5b7jsg7M8kF6RONFyZ507YPSaWUkuRdSR6S5Mgk/zXJ8cM5t3nMcOxruq67z4eMruu+tqD8hUluST/a8IVJXpDkpAWH1SQPTXJUkqeVUr4/yfuS3JTksCGOQ5JctOC4fYdz/UySY5IcMdT5peGcxyT5sSSnTRzz3emnWP3EcF3vTXLJxAfFn05yQ5LX5d9HcN648Don7LA9AUaqS/LrSZ5ZSnnCwp2llAekf43/jiQ/Pvw8KMl7FvRZ35bkNelHqj8qyZVD+c+m/8LsR4d9pyX5y+EcPzY892mllGMmzrW7feRCm5P8QZLf3VnibVeGfu1DSfZO36/+cJLfTrLd0SGlH13ywSS3Ddd0eJJPJflAKeWhQ53/lH7k/uXp++aTkhyX5P+ZNk4Alt2mJL80fO5K+s8tl2ViBOECNyY5YXh8WPrPJj89bP9qklen/zzy6CT/I8mZpZSTk2/2PX+e5G3D/h9J8odJ7h3277Kvyb/3nSckOSjJf0ty3dRXD6vA3K6rwKpzZCll20i8Bya5K8nPd1233c6j67q3TG4PI9n+T5L/nOT/ndj1R13XtaHOb6dP2v1Ekk+nT9A9Nskju6779FDn5zOM6htsS359cjev4++7rjtzePyZUspz009HPneizi1JfnXbMPpSyquTfCXJc7quu2coe3aSj5VSntx13eXDcfdPclLXdVuGOi3JLyf5/q7rbh/KLhyua1s7fWBBfL9VSvmvSX4uyRld132plLI1yde6rrt1W6Wy49sq7qw9AUap67q/L6VcnOS16b9wmvTz6b8UevzE6/eJ6b+cOTH9ly5JUpK8rOu6bSMntr0Wf67rupcPRZ8upbwsyf5d1x0zUfbS9K/9fzXEs7t95Pa8Ln3f8ptJTt9F3R05NX3i9ISu6/51KPuXndT/lSQ3dF33KxMxvyjJsUl+If0HvN9IcnXXdb82VPnn0o/6f1cp5bd29H4BgJm6KMnZ6T/rXZ5+hPqL0g9iuI+u67aWUr40bN4++fkk/Qyz/9l13aZh+zOllEcm+e/pP2vtm/4LtdZ13Q1Dncnk3u70NT+Q5B+7rtt2H/YvpP/CC9YsIwhZi65Icujw84Qkb0hywfZGYyT9fQFLKe8q/aIhX82/J/UW3gPqY9sedF23Nf03Rtvug3Fwki3bkoNDndvTf5P0zafaw+v42ILtL0483zZXLbjHxqOTfHhbcnCI45+S3Dns2+bmbR8uB7cmuXVbcnCibHJq8kOHKVj/PAyl/9pwzmnvlbWz9gQYs5cnOaKUcvyC8kcn+eTk6/dwX7xP5Vtf45Pko9s57z8t2L41yce3Uzb52r+7feR9dF13V/rRfi8rpey7q/o78PgkH5pIDu7Kf07y+PLvU7C/luSrSQ5MP4Ij6dvq8gXH/V36fvrgKeMEYBl1XfeNJH+SfnbYT6UfzPS/9/Q8pZTvTrJ/tt8PHFhKeWD6vvG9ST4x9IEvLqUcMFF3d/qaP07ys6WUT5T+tlHHlFLkV1jTjCBkLfp613XXT2xfXUo5IclLkjxrsuLQAbwv/RDx56afEpUk1yZZOH3qngXbXfYsib4tWXhwdjzdeU+fb3c/MC20cMGQbgdlk893XpKHpR8J8rkkX08/NXjaxVEW254A61LXdZ8upfyv9NOEj9lV/e3YOnyQWmiPXvv3sI/ckfOSvDj9VK4PLNi3vWnCi11Q5dvSTzl7wXb23bnIcwMwW5vSf446IMlbuq77t53MVpraMPrwmPSJwKemvy3TmaWUn+u67t3Zjb6m67r3DvdJ/Mn0MwL+NMk1pZSjhsERsOb4sM56sTXJA7ZT/h/TT9f6713XfWBY1OR7suej/T6ZZL6Usu0bo5RS5pM8cqLOPyW5JsnLy8RiIxP1H7S98j10bZLDJ+8NVUp5TPrVkT+xyHM/Ockfd113Sdd116Sf3vwfFtS5J8m6WLESYMb+ryQbkmycKLs2ycFD/5Lkm/dBemQW/xq/PYvuI4dR7r+R/sbyhyzYfVuSvcq3rkr5uAV1rkrypD24j+GV6UcI3tR13fULfraNkr82fZ826cfTJ0ev3c3nAWCFdV33yfQj5I9IvxjWrmwbkPDNzydd130l/f3at9cPfG4Y/Z6u95Gu636/67onpx9h+Nyh7u70Nem67ktd172t67rnpx/1+OMxUp01TIKQtejbSynfP/wcNNzf7uD0i4gs9Pn0C5i8sPSrJB6V/t4W3R4+52XpE4B/Wko5rJRyaJK3ZmJkRtd1XfoPSPsnuaKU8vQhvkeVUp6ffij7g/bweRf6o/T34TivlHJI6VcO/pP09zP8+50fukufSvILpZQfHq7vbblvMvBz6afFPayUMm8YPcB0hg8YZ6Yf/b7NnyW5PcnbS7+y/OPTj+S+Of0iUkttSfrIruvel76ffNGCXR9JPyXrzKE/PDrJ7yyo88fp349eXEo5opTy8FLKcQsWUpn0R+n7potLKT9WSjmwlPKjpV+x+UlDnf+R5HGllLOGPvjoJP8zyVu7rvvCDs4LwOrwk0nmu67b2f1ot/l8+tHqx5ZSvq+U8uCh/P9O37edMvQ/z09/X8HfT5JSypNKKb9dSnni8LnmqPQLK267l/wu+5rh8U+XUh45DCL5hSRfy7feox7WFB/uWYt+LP3otlvSD0H/mSSndF33pwsrDvdxelb6lRmvTX9T+F/PDlZH3JEh+ff09EPKL0/y7iSXZsFU4q7rrk6/mMmV6W9ee22Sv03yjPQfAhc1/Wm4F9V/SZ+E/OgQxyfSr1y5WM9N/5rwkSR/keQ9ue89rk5Pv9Lkp9J/iH3YEjwvwFidlWTyfoNfT/8af3f6vubv0t9q4ujJe88ulaXqIwe/nn6BrMnzfynJM9Ov/vjx9Pcr/M0FdW5Jv+ryV9P3q9cmOSM7GMU49IM/kr7d3pm+P3pr+nsm3jLU+Xj6FZGfnP7LvT9Jv5rzL09xXQCsoK7r7hr6j92puznJK9MvSnJLkouHXeek/0LqtPRJv5cneUXXddsWg7wzfV9ycZLPJHlz+r7k1RPn3Wlfk+QbSX43/Uj4K9MnGI/pus7tLlizSp/3AAAAAADGyAhCAAAAABgxCUIAAAAAGDEJQgAAAAAYMQlCAAAAABixuVkHMLBSCgA7st3VTGdInwXA9uivAFgr7tNnrZYEYb74xS/OOoRlNz8/ny1btsw6jDVJ201P201P201vqdpuw4YNSxDN0lvvfZa//elpu+lpu+lpu+npr9Y2f/uLo/2mp+2mp+2mt9x9linGAAAAADBiEoQAAAAAMGIShAAAAAAwYhKEAAAAADBiEoQAAAAAMGIShAAAAAAwYhKEAAAAADBiEoQAAAAAMGIShAAAAAAwYhKEAAAAADBiEoQAAAAAMGIShAAAAAAwYhKEAAAAADBiEoQAAAAAMGIShAAAAAAwYhKEAAAAADBic7MOgJWx9ZTjZx3Ct9jrjZfMOgSAmfGaDMBasZr6LP0VwPIxghAAAAAARkyCEAAAAABGTIIQAAAAAEbMPQgBWBdqrQckuSDJPkm6JJtaa2fXWl+V5JQktw9VT2utXToc88okJyfZmuRFrbX3rnjgAAAAMyZBCMB6cW+Sl7XWrq61fleSq2qtfz3sO6u19trJyrXWg5OcmOTRSTYk+Zta6w+11rauaNQAAAAzZooxAOtCa+2W1trVw+OvJrkuyX47OeSEJBe21u5urX0uyfVJDlv+SAEAAFYXIwgBWHdqrQcmeWySK5IckeQFtdZfTHJl+lGGd6RPHn544rCbsvOEIgAAwLokQQjAulJrfVCSdyR5SWvtK7XWc5K8Ov19CV+d5HVJnreH59yYZGOStNYyPz+/qBg3L+ropbfweubm5hZ9jWOl7aan7aan7aan7QCgJ0EIwLpRa71f+uTgW1tr70yS1trmif1vTPLuYfPmJAdMHL7/UHYfrbVNSTYNm92WLVuWOPLZWng98/Pz9ylj92i76Wm76Wm76S1V223YsGEJogGA2XEPQgDWhVprSXJukutaa6+fKN93otozknxieHxJkhNrrfevtT48yUFJPrJS8QIAAKwWRhACsF4ckeTZSa6ptX5sKDstyTNrrYemn2J8Q5LnJ0lr7dpaa0vyyfQrIJ9qBWMAAGCMJAgBWBdaax9MUraz69KdHHNGkjOWLSgAAIA1QIIQAABgBdVavyPJ5Unun/4z2UWttdNrrecl+fEkdw5Vn9Na+9hwG42zkxyb5K6h/OqVjxyA9UqCEAAAYGXdneQprbWvDQtsfbDW+lfDvt9orV20oPAa3Y8AACAASURBVP4x6e+Ve1CSJyY5Z/gXAJaERUoAAABWUGuta619bdi83/DT7eSQE5JcMBz34SR7L1iECwAWxQhCAACAFVZr3SvJVUkekeQNrbUraq2/kuSMWuvvJLksyStaa3cn2S/JjROH3zSU3bLgnBuTbEyS1lrm5+cXHefmRZ9h6Sy8nrm5uSW5xrHSftPTdtPTdtNb7raTIAQAAFhhrbWtSQ6tte6d5F211kOSvDLJrUm+PcmmJC9P8rt7cM5Nw3FJ0m3ZsmVpg56xhdczPz9/nzJ2n/abnrabnrab3lK13YYNG7ZbbooxAADAjLTWvpzk/UmObq3dMkwjvjvJW5IcNlS7OckBE4ftP5QBwJKQIAQAAFhBtdaHDiMHU2t9QJKnJfnnbfcVHFYtfnqSTwyHXJLkF2utpdZ6eJI7W2u3bOfUADAVCUIAAICVtW+S99daP57ko0n+urX27iRvrbVek+SaJPNJfm+of2mSzya5Pskbk/zqyocMwHrmHoQAAAArqLX28SSP3U75U3ZQv0ty6nLHBcB4GUEIAAAAACMmQQgAAAAAIyZBCAAAAAAjJkEIAAAAACMmQQgAAAAAI7bLVYxrrW9OclyS21prhwxl35vk7UkOTHJDktpau6PWWpKcneTYJHcleU5r7erlCR0AAAAAWKzdGUF4XpKjF5S9IsllrbWDklw2bCfJMUkOGn42JjlnacIEAAAAAJbDLhOErbXLk3xpQfEJSc4fHp+f5OkT5Re01rrW2oeT7F1r3XepggUAAAAAlta09yDcp7V2y/D41iT7DI/3S3LjRL2bhjIAAAAAYBXa5T0Id6W11tVauz09rta6Mf005LTWMj8/v9hQVr25ubmZXefmmTzrju1pO8yy7dY6bTc9bTc9bQcAALB2TJsg3Fxr3be1dsswhfi2ofzmJAdM1Nt/KLuP1tqmJJuGzW7Lli1ThrJ2zM/PZwzXuTv2tB203fS03fS03fSWqu02bNiwBNEAAACwM9MmCC9JclKSM4d/L54of0Gt9cIkT0xy58RUZAAAAABgldllgrDW+rYkRyaZr7XelOT09InBVms9Ocnnk9Sh+qVJjk1yfZK7kjx3GWIGAAAAAJbILhOErbVn7mDXUdup2yU5dbFBAQAAAAArY9pVjAEAAACAdUCCEAAAAABGTIIQAAAAAEZMghAAAAAARkyCEAAAAABGTIIQAAAAAEZMghAAAAAARkyCEAAAAABGTIIQAAAAAEZMghAAAAAARkyCEAAAAABGTIIQAAAAAEZMghAAAAAARkyCEAAAAABGTIIQAAAAAEZMghAAAAAARkyCEAAAAABGTIIQAAAAAEZMghAAAAAARkyCEAAAAABGTIIQAAAAAEZsbtYBrGdbTzn+W7Y3zygOAAAAANgRIwgBAAAAYMQkCAEAAABgxCQIAQAAAGDEJAgBAAAAYMQkCAEAAABgxKxiDAAAsIJqrd+R5PIk90//meyi1trptdaHJ7kwyUOSXJXk2a21e2qt909yQZLHJ/k/Sf5ba+2GmQQPwLpkBCEAAMDKujvJU1prj0lyaJKja62HJ3lNkrNaa49IckeSk4f6Jye5Yyg/a6gHAEtGghAAAGAFtda61trXhs37DT9dkqckuWgoPz/J04fHJwzbGfYfVWstKxQuACNgijEAAMAKq7XulX4a8SOSvCHJvyT5cmvt3qHKTUn2Gx7vl+TGJGmt3VtrvTP9NOQtC865McnGoV7m5+cXHefmRZ9h6Sy8nrm5uSW5xrHSftPTdtPTdtNb7raTIAQAAFhhrbWtSQ6tte6d5F1JHrUE59yUZNOw2W3ZsmVn1dechdczPz9/nzJ2n/abnrabnrab3lK13YYNG7ZbbooxAADAjLTWvpzk/Ul+JMnetdZtgzj2T3Lz8PjmJAckybD/wekXKwGAJSFBCAAAsIJqrQ8dRg6m1vqAJE9Lcl36ROHPDtVOSnLx8PiSYTvD/r9trXUrFzEA650EIQAAwMraN8n7a60fT/LRJH/dWnt3kpcneWmt9fr09xg8d6h/bpKHDOUvTfKKGcQMwDrmHoQAAAArqLX28SSP3U75Z5Mctp3ybyT5uRUIDYCRMoIQAAAAAEZMghAAAAAARkyCEAAAAABGTIIQAAAAAEbMIiUArBu11gOSXJBknyRdkk2ttbNrrd+b5O1JDkxyQ5LaWruj1lqSnJ3k2CR3JXlOa+3qWcQOAAAwK0YQArCe3JvkZa21g5McnuTUWuvBSV6R5LLW2kFJLhu2k+SYJAcNPxuTnLPyIQMAAMyWBCEA60Zr7ZZtIwBba19Ncl2S/ZKckOT8odr5SZ4+PD4hyQWtta619uEke9da913hsAEAAGbKFGMA1qVa64FJHpvkiiT7tNZuGXbdmn4KctInD2+cOOymoeyWibLUWjemH2GY1lrm5+cXFdvmRR299BZez9zc3KKvcay03fS03fS03fS0HQD0JAgBWHdqrQ9K8o4kL2mtfaXW+s19rbWu1trtyflaa5uSbBo2uy1btixZrKvBwuuZn5+/Txm7R9tNT9tNT9tNb6nabsOGDUsQDQDMjinGAKwrtdb7pU8OvrW19s6hePO2qcPDv7cN5TcnOWDi8P2HMgAAgNEwghCAdWNYlfjcJNe11l4/seuSJCclOXP49+KJ8hfUWi9M8sQkd05MRQYAABgFCUIA1pMjkjw7yTW11o8NZaelTwy2WuvJST6fZNuc40uTHJvk+iR3JXnuyoYLAAAwexKEAKwbrbUPJik72H3Udup3SU5d1qAAAABWOfcgBAAAAIARkyAEAAAAgBGTIAQAAACAEZMgBAAAAIARkyAEAAAAgBGTIAQAAACAEZMgBAAAAIARkyAEAAAAgBGTIAQAAACAEZtbzMG11l9L8ktJuiTXJHlukn2TXJjkIUmuSvLs1to9i4wTAAAAAFgGU48grLXul+RFSZ7QWjskyV5JTkzymiRntdYekeSOJCcvRaAAAAAAwNJb7BTjuSQPqLXOJXlgkluSPCXJRcP+85M8fZHPAQAAAAAsk6kThK21m5O8NskX0icG70w/pfjLrbV7h2o3JdlvsUECAAAAAMtj6nsQ1lq/J8kJSR6e5MtJ/jzJ0Xtw/MYkG5OktZb5+flpQ1m1Ns86gFVsT3/fc3Nz6/JvZCVou+lpu+lpOwAAgLVjMYuUPDXJ51prtydJrfWdSY5IsnetdW4YRbh/kpu3d3BrbVOSTcNmt2XLlkWEwlqzp7/v+fn5PT6Gnrabnrab3lK13YYNG5YgGgAAAHZmMQnCLyQ5vNb6wCRfT3JUkiuTvD/Jz6ZfyfikJBcvNkgAAAAAYHks5h6EV6RfjOTqJNcM59qU5OVJXlprvT7JQ5KcuwRxAgAAAADLYDEjCNNaOz3J6QuKP5vksMWcFwAAAABYGVOPIAQAAAAA1j4JQgAAAAAYMQlCAAAAABgxCUIAAAAAGDEJQgAAAAAYMQlCAAAAABgxCUIAAAAAGDEJQgAAAAAYsblZB7CUtp5y/KxDAAAAAIA1xQhCAAAAABixdTWCEAAAYLWrtR6Q5IIk+yTpkmxqrZ1da31VklOS3D5UPa21dulwzCuTnJxka5IXtdbeu+KBA7BuSRACAACsrHuTvKy1dnWt9buSXFVr/eth31mttddOVq61HpzkxCSPTrIhyd/UWn+otbZ1RaMGYN0yxRgAAGAFtdZuaa1dPTz+apLrkuy3k0NOSHJha+3u1trnklyf5LDljxSAsTCCEAAAYEZqrQcmeWySK5IckeQFtdZfTHJl+lGGd6RPHn544rCbsp2EYq11Y5KNSdJay/z8/KLj27zoMyydhdczNze3JNc4VtpvetpuetpuesvddhKEAAAAM1BrfVCSdyR5SWvtK7XWc5K8Ov19CV+d5HVJnre752utbUqyadjstmzZssQRz9bC65mfn79PGbtP+01P201P201vqdpuw4YN2y2XIAQAAFhhtdb7pU8OvrW19s4kaa1tntj/xiTvHjZvTnLAxOH7D2UAsCTcgxAAAGAF1VpLknOTXNdae/1E+b4T1Z6R5BPD40uSnFhrvX+t9eFJDkrykZWKF4D1zwhCAACAlXVEkmcnuabW+rGh7LQkz6y1Hpp+ivENSZ6fJK21a2utLckn06+AfKoVjAFYShKEAAAAK6i19sEkZTu7Lt3JMWckOWPZggJg1EwxBgAAAIARkyAEAAAAgBGTIAQAAACAEZMgBAAAAIARkyAEAAAAgBGTIAQAAACAEZMgBAAAAIARkyAEAAAAgBGTIAQAAACAEZMgBAAAAIARkyAEAAAAgBGTIAQAAACAEZMgBAAAAIARm5t1AMDqtvWU42cdwjft9cZLZh0CAAAArDtGEAIAAADAiEkQAgAAAMCISRACAAAAwIhJEAIAAADAiEkQAgAAAMCISRACAAAAwIhJEAIAAADAiEkQAgAAAMCISRACAAAAwIhJEAIAAADAiEkQAgAAAMCISRACAAAAwIjNzToAAFgqtdY3JzkuyW2ttUOGslclOSXJ7UO101prlw77Xpnk5CRbk7yotfbeFQ8aAABgxiQIAVhPzkvyR0kuWFB+VmvttZMFtdaDk5yY5NFJNiT5m1rrD7XWtq5EoAAAAKuFKcYArButtcuTfGk3q5+Q5MLW2t2ttc8luT7JYcsWHAAAwCplBCEAY/CCWusvJrkyyctaa3ck2S/Jhyfq3DSU3UetdWOSjUnSWsv8/Pyigtm8qKOX3sLrmZubW/Q1jpW2m562m562m562A4CeBCEA6905SV6dpBv+fV2S5+3JCVprm5JsGja7LVu2LGmAs7bweubn5+9Txu7RdtPTdtPTdtNbqrbbsGHDEkQDALMjQQjAutZa++aAvVrrG5O8e9i8OckBE1X3H8oAAABGxT0IAVjXaq37Tmw+I8knhseXJDmx1nr/WuvDkxyU5CMrHR8AAMCsGUEIwLpRa31bkiOTzNdab0pyepIja62Hpp9ifEOS5ydJa+3aWmtL8skk9yY51QrGAADAGEkQArButNaeuZ3ic3dS/4wkZyxfRAAAAKufKcYAAAAAMGIShAAAAAAwYhKEAAAAADBiEoQAAAAAMGKLWqSk1rp3kjclOST96pDPS/KpJG9PcmD61SJra+2ORUUJAAAAACyLxY4gPDvJe1prj0rymCTXJXlFkstaawcluWzYBgAAAABWoalHENZaH5zkyUmekySttXuS3FNrPSHJkUO185N8IMnLFxMkAADAelFrPSDJBUn2ST8Ta1Nr7exa6/dmO7Oxaq0l/eCMY5PcleQ5rbWrZxE7AOvTYkYQPjzJ7UneUmv9x1rrm2qt35lkn9baLUOdW9N3egAAAPTuTfKy1trBSQ5Pcmqt9eDseDbWMUkOGn42Jjln5UMGYD1bzD0I55I8LskLW2tX1FrPzoLpxK21rtbabe/gWuvG9J1bWmuZn59fRCi9zYs+AytlT3/fc3NzS/I3MkaLbbvV9P9qpf8G/N1NT9sBwI4NAypuGR5/tdZ6XZL9kuxoNtYJSS5orXVJPlxr3bvWuu/EwAwAWJTFJAhvSnJTa+2KYfui9AnCzds6q1rrvklu297BrbVNSTYNm92WLVsWEQprzZ7+vufn5/f4GHrrqe1W+jrWU9uttKVquw0bNixBNACwetVaD0zy2CRXZMezsfZLcuPEYTcNZd+SIFzvgzAWXo8vJBdH+01P201P201vudtu6gRha+3WWuuNtdZHttY+leSoJJ8cfk5Kcubw78VLEikAAMA6Umt9UJJ3JHlJa+0rtdZv7tvZbKwdWe+DMBZejy9zF0f7TU/bTU/bTW+5B2EsdhXjFyZ5a63140kOTfL76RODT6u1fibJU4dtAAAABrXW+6VPDr61tfbOoXjzMAsrC2Zj3ZzkgInD9x/KAGBJLGaKcVprH0vyhO3sOmox5wUAAFivhlWJz01yXWvt9RO7Lsn2Z2NdkuQFtdYLkzwxyZ3uPwjAUlpUghAAAIA9dkSSZye5ptb6saHstPSJwVZrPTnJ55Nsm3N8aZJjk1yf5K4kz13ZcAFY7yQIAQAAVlBr7YNJyg5232c21rB68anLGhQAo7bYexACAAAAAGuYBCEAAAAAjJgEIQAAAACMmAQhAAAAAIyYBCEAAAAAjJgEIQAAAACMmAQhAAAAAIyYBCEAAAAAjJgEIQAAAACMmAQhAAAAAIyYBCEAAAAAjJgEIQAAAACMmAQhAAAAAIyYBCEAAAAAjJgEIQAAAACMmAQhAAAAAIyYBCEAAAAAjJgEIQAAAACMmAQhAAAAAIyYBCEAAAAAjJgEIQAAAACMmAQhAAAAAIyYBCEAAAAAjJgEIQAAAACMmAQhAAAAAIyYBCEAAAAAjJgEIQAAAACMmAQhAAAAAIyYBCEAAAAAjJgEIQAAAACMmAQhAAAAAIyYBCEAAAAAjJgEIQAAAACMmAQhAAAAAIyYBCEAAAAAjJgEIQAAAACMmAQhAAAAAIyYBCEAAAAAjJgEIQAAAACMmAQhAAAAAIyYBCEAAAAAjNjcrAMAAAAYk1rrm5Mcl+S21tohQ9mrkpyS5Pah2mmttUuHfa9McnKSrUle1Fp774oHDcC6JkEIAACwss5L8kdJLlhQflZr7bWTBbXWg5OcmOTRSTYk+Zta6w+11rauRKAAjIMpxgAAACuotXZ5ki/tZvUTklzYWru7tfa5JNcnOWzZggNglIwgBAAAWB1eUGv9xSRXJnlZa+2OJPsl+fBEnZuGsvuotW5MsjFJWmuZn59fdECbF32GpbPweubm5pbkGsdK+01P201P201vudtOghAAAGD2zkny6iTd8O/rkjxvT07QWtuUZNOw2W3ZsmVJA5y1hdczPz9/nzJ2n/abnrabnrab3lK13YYNG7ZbLkEIAAAwY621bw7Wq7W+Mcm7h82bkxwwUXX/oQwAlowEIQDrxg5WhfzeJG9PcmCSG5LU1todtdaS5Owkxya5K8lzWmtXzyJuAKi17ttau2XYfEaSTwyPL0nyZ7XW16dfpOSgJB+ZQYgArGMWKQFgPTkvydELyl6R5LLW2kFJLhu2k+SY9B+yDkp/v6ZzVihGAEau1vq2JP+Q5JG11ptqrScn+YNa6zW11o8n+Ykkv5YkrbVrk7Qkn0zyniSnWsEYgKVmBCEA60Zr7fJa64ELik9IcuTw+PwkH0jy8qH8gtZal+TDtda9F4zeAIBl0Vp75naKz91J/TOSnLF8EQEwdkYQArDe7TOR9Ls1yT7D4/2S3DhRb4erQgIAAKxnRhACMBqtta7W2u3pcbXWjemnIae1lvn5+UXFsXnXVVbUwuuZm5tb9DWOlbabnrabnrabnrYDgJ4EIQDr3eZtU4drrfsmuW0o3+1VIVtrm5JsGja7LVu2LFuws7Dweubn5+9Txu7RdtPTdtPTdtNbqrbbsGHDEkQDALMjQQjAendJkpOSnDn8e/FE+QtqrRcmeWKSO91/EAAAGCMJQgDWjWFVyCOTzNdab0pyevrEYBtWiPx8kjpUvzTJsUmuT3JXkueueMAAAACrgAQhAOvGDlaFTJKjtlO3S3Lq8kYEAACw+lnFGAAAAABGbNEjCGuteyW5MsnNrbXjaq0PT3JhkockuSrJs1tr9yz2eQAAAACApbcUIwhfnOS6ie3XJDmrtfaIJHckOXkJngMAAAAAWAaLShDWWvdP8lNJ3jRslyRPSXLRUOX8JE9fzHMAAAAAAMtnsVOM/zDJbyb5rmH7IUm+3Fq7d9i+Kcl+2zuw1roxycYkaa1lfn5+kaEkmxd9BlbKnv6+5+bmluRvZIwW23ar6f/VSv8N+LubnrYDAABYO6ZOENZaj0tyW2vtqlrrkXt6fGttU5JNw2a3ZcuWaUNhDdrT3/f8/PweH0NvPbXdSl/Hemq7lbZUbbdhw4YliAYAAICdWcwU4yOSHF9rvSH9oiRPSXJ2kr1rrdsSj/snuXlREQIAAAAAy2bqBGFr7ZWttf1bawcmOTHJ37bWfiHJ+5P87FDtpCQXLzpKAAAAAGBZLMUqxgu9PMlLa63Xp78n4bnL8BwAAAAAwBJY7CIlSZLW2geSfGB4/Nkkhy3FeQEAAACA5bUcIwgBAAAAgDVCghAAAAAARkyCEAAAAABGTIIQAAAAAEZMghAAAAAARkyCEAAAAABGTIIQAAAAAEZMghAAAAAARkyCEAAAAABGTIIQAAAAAEZsbtYBME5bTzl+j+pvXqY4kmSvN16yjGcHAAAAWN2MIAQAAACAEZMgBAAAAIARkyAEAAAAgBGTIAQAAACAEZMgBAAAAIARkyAEAAAAgBGTIAQAAACAEZMgBAAAAIARkyAEAAAAgBGTIAQAAACAEZMgBAAAAIARkyAEAAAAgBGTIIT/v707CpX0LO8A/l/2WKhRasPBJZsE1ovQEgS1LCoqRRsVtZKkNw+1VLbWZm+0rUUoqTfe5qJIc1HEjdqsVDQPasgWxSrbCxGrVqOibQQlXTXbza6rqYZKsbs9vTgTWTe73T3fzJxvZr/fD4bzfd/MmXnm3T3nD89533cAAAAAJmxj7AJgbOfvun3sEn7J3vuOjV0CAAAAMCEahAAAALuoqj6Y5I1JznT382fXrk/yQJIDSU4kqe5+oqr2JLk3yRuS/CzJH3X3w2PUDcC1yxJjAACA3XV/ktdddO3uJMe7+5Ykx2fnSfL6JLfMboeTvHeXagRgQjQIAQAAdlF3fy7Jjy+6fEeSo7Pjo0nuvOD6h7p7q7u/mOQ5VXXD7lQKwFRYYgwAADC+fd19anb8eJJ9s+Mbk/zggsc9Nrt2KhepqsPZnmWY7s7m5ubcRZ2e+xkW5+L3s7GxsZD3OFXGbzhjN5yxG27ZY6dBCAAAsEK6e6uqtgZ835EkR2anW2fPnl1sYSO7+P1sbm4+7RpXz/gNZ+yGM3bDLWrs9u/ff8nrlhgDAACM7/RTS4dnX8/Mrp9McvMFj7tpdg0AFsYMQgAAgPEdS3IoyT2zrw9dcP3tVfXRJC9J8pMLliIDwEJoEAIAAOyiqvpIklcm2ayqx5K8O9uNwa6qtyb5XpKaPfxTSd6Q5LtJfpbkLbteMADXPA1CAACAXdTdb7rMXbdd4rFbSd623IoAmDp7EAIAAADAhGkQAgAAAMCEaRACAAAAwITZgxBYG+fvun1XX+/0Fe7fe9+xXakDAAAAlskMQgAAAACYMA1CAAAAAJgwS4wBAIBds9tbhvy/HvzC2BUAwEowgxAAAAAAJkyDEAAAAAAmTIMQAAAAACZMgxAAAAAAJkyDEAAAAAAmTIMQAAAAACZMgxAAAAAAJkyDEAAAAAAmTIMQAAAAACZMgxAAAAAAJkyDEAAAAAAmTIMQAAAAACZsY+wCAGA3VNWJJE8mOZ/kXHcfrKrrkzyQ5ECSE0mqu58Yq0YAAIAxmEEIwJS8qrtf2N0HZ+d3Jzne3bckOT47BwAAmBQNQgCm7I4kR2fHR5PcOWItAAAAo7DEGICp2ErymaraSvK+7j6SZF93n5rd/3iSfZf6xqo6nORwknR3Njc35yrk9FzfvXgXv5+NjY253+NUGbvhjN1w6zZ2q/Q7cN3GDgCWRYMQgKl4RXefrKrnJvlsVX37wju7e2vWPHyaWTPxyOx06+zZs0sudXdd/H42Nzefdo2rY+yGM3bDGbvhzp07t5Cx279//wKqAYDxDG4QVtXNST6U7dkWW0mOdPe9NnwHYBV198nZ1zNV9WCSFyc5XVU3dPepqrohyZlRiwQAABjBPHsQnkvyzu6+NclLk7ytqm6NDd8BWDFVdV1VPfup4ySvTfKtJMeSHJo97FCSh8apEAAAYDyDG4Tdfaq7H54dP5nkkSQ3xobvAKyefUk+X1XfSPLlJJ/s7k8nuSfJa6rqO0lePTsHAACYlIXsQVhVB5K8KMmXMtKG78lqbXgMQy16o+x5N9/2c3V5q7Sp+enfe9nYJfySjX/48kqNT3c/muQFl7j+oyS37X5FAAAAq2PuBmFVPSvJx5O8o7t/WlW/uG/KG77DUIv+WbBx+fIY18uz6TsAAMD6mGcPwlTVM7LdHPxwd39idvn0bKP32PAdAAAAAFbb4AZhVe1J8oEkj3T3ey64y4bvAAAAALAm5lli/PIkb07yzar6+uzau7K9wXtX1VuTfC9JXeb7AQAAAICRDW4Qdvfnk+y5zN02fAcAAACANTDXHoQAAAAAwHrTIAQAAACACZtnD0IAgIU7f9ftY5fwC3vvOzZ2CQAAsHRmEAIAAADAhGkQAgAAAMCEaRACAAAAwIRpEAIAAADAhGkQAgAAAMCE+RRjAACAFVFVJ5I8meR8knPdfbCqrk/yQJIDSU4kqe5+YqwaAbj2mEEIAACwWl7V3S/s7oOz87uTHO/uW5Icn50DwMJoEAIAAKy2O5IcnR0fTXLniLUAcA2yxBgAAGB1bCX5TFVtJXlfdx9Jsq+7T83ufzzJvkt9Y1UdTnI4Sbo7m5ubcxdzeu5nWJyL38/GxsZC3uNUGb/hjN1wxm64ZY+dBiEAAMDqeEV3n6yq5yb5bFV9+8I7u3tr1jx8mlkz8cjsdOvs2bNLLnV3Xfx+Njc3n3aNq2f8hjN2wxm74RY1dvv377/kdUuMAQAAVkR3n5x9PZPkwSQvTnK6qm5IktnXM+NVCMC1SIMQAABgBVTVdVX17KeOk7w2ybeSHEtyaPawQ0keGqdCAK5VGoQAAACrYV+Sz1fVN5J8Ocknu/vTSe5J8pqq+k6SV8/OAWBh7EEIAACwArr70SQvuMT1HyW5bfcrAmAqzCAEAAAAgAnTIAQAAACACdMgBAAAAIAJ0yAEAAAAgAnTIAQAAACACdMgBAAAAIAJ0yAEAAAAgAnbGLsAgHV1/q7bxy4BAAAA5mYGIQAAAABMmAYhAAAAAEyYJcawYha9bPX0Qp8NAAAAuNaYQQgAAAAAE2YGIQAAAOzQZjkQjgAABsdJREFUqn1g3d77jo1dArDGNAgBAABYeRc35GylA7A4GoQAALBguzmz6EpNErOKAIArsQchAAAAAEyYBiEAAAAATJglxgAAa2LVNsRfpHn3ErOMFgBgOA1CAJg4m74DAMC0aRACAFzGTmfsaa4CALCO7EEIAAAAABOmQQgAAAAAE2aJMQAAa+9a/gAXAIBlM4MQAAAAACbMDEIAALiGmV0JAFyJGYQAAAAAMGEahAAAAAAwYRqEAAAAADBhGoQAAAAAMGEahAAAAAAwYT7FGAAAAAAucP6u28cu4Zc9+IWlPr0ZhAAAAAAwYWYQAgAAwJrb6Wyn00uqI0n23ndsic8OLIMZhAAAAAAwYRqEAAAAADBhlhgDAAAA7IJV++ALy8F5ihmEAAAAADBhZhACAAAATNBuz2i80ofjmNE4Hg1CAAAAYGEso4X1Y4kxAAAAAEyYBiEAAAAATNjSlhhX1euS3Jtkb5L3d/c9y3otABhKXgGwDuQVDLfoJc9X2kcP1tFSZhBW1d4kf5vk9UluTfKmqrp1Ga8FAEPJKwDWgbwCYNmWtcT4xUm+292PdvfPk3w0yR1Lei0AGEpeAbAO5BUAS7WsJcY3JvnBBeePJXnJhQ+oqsNJDidJd2f//v3zv+onvzL/cwCwEAv5vb58V8yrZAmZJa8AVoa8ugKZBUzVCv7+W2ZmjfYhJd19pLsPdvfBJHumcKuqr45dw7rejJ2xM3brdVvw2I1uapnl/76xM3brdTN2KzN2o5NXbsbP2K36zditzNg9zbIahCeT3HzB+U2zawCwSuQVAOtAXgGwVMtaYvwvSW6pqudlO7h+P8kfLOm1AGAoeQXAOpBXACzVUmYQdve5JG9P8o9JHtm+1P+6jNdaM0fGLmCNGbvhjN1wxm64tRg7eXVZa/Hvt6KM3XDGbjhjN9xajJ28uqy1+PdbYcZvOGM3nLEbbqljt2dra2uZzw8AAAAArLDRPqQEAAAAABifBiEAAAAATNiyPqSEmaq6OcmHkuxLspXkSHffO25V66Wq9ib5SpKT3f3GsetZF1X1nCTvT/L8bP/f++Pu/udxq1oPVfUXSf4k2+P2zSRv6e7/Hreq1VVVH0zyxiRnuvv5s2vXJ3kgyYEkJ5JUdz8xVo1cHZk1H3k1nMwaTmZdPXl17ZBX85NZw8ir4eTVzoyRWWYQLt+5JO/s7luTvDTJ26rq1pFrWjd/nu3NmNmZe5N8urt/M8kLYgyvSlXdmOTPkhyc/SLem+1PCuTy7k/yuouu3Z3keHffkuT47JzVJ7PmI6+Gk1kDyKwduz/y6lohr+Yns4aRVwPIq0Huzy5nlgbhknX3qe5+eHb8ZLZ/gdw4blXro6puSvK72f4rDVepqn4tyW8n+UCSdPfPu/s/x61qrWwk+dWq2kjyzCT/MXI9K627P5fkxxddviPJ0dnx0SR37mpRDCKzhpNXw8msucmsqySvrh3yaj4yaxh5NTd5tQNjZJYG4S6qqgNJXpTkSyOXsk7+JslfJvnfsQtZM89L8sMkf1dVX6uq91fVdWMXtQ66+2SSv07y/SSnkvykuz8zblVraV93n5odP57tJUCsEZm1Y/JqOJk1kMxaCHm15uTVIDJrGHk1kLxamKVmlgbhLqmqZyX5eJJ3dPdPx65nHVTVU+vtvzp2LWtoI8lvJXlvd78oyX/FkpmrUlW/nu2/zDwvyf4k11XVH45b1Xrr7q1s7zXCmpBZOyOv5iazBpJZiyWv1o+82jmZNRd5NZC8WrxlZJYG4S6oqmdkO7g+3N2fGLueNfLyJLdX1YkkH03yO1X19+OWtDYeS/JYdz/1l9SPZTvMuLJXJ/n37v5hd/9Pkk8kednINa2j01V1Q5LMvp4ZuR6ukswaRF7NR2YNJ7PmJ6/WlLwaTGYNJ6+Gk1eLsdTM0iBcsqrak+09Ch7p7veMXc866e6/6u6buvtAtjcw/afu9leGq9Ddjyf5QVX9xuzSbUn+bcSS1sn3k7y0qp45+/m9LTYfHuJYkkOz40NJHhqxFq6SzBpGXs1HZs1FZs1PXq0heTWczBpOXs1FXi3GUjNrY5FPxiW9PMmbk3yzqr4+u/au7v7UiDUxDX+a5MNV9StJHk3ylpHrWQvd/aWq+liSh7P9CXlfS3Jk3KpWW1V9JMkrk2xW1WNJ3p3kniRdVW9N8r0kNV6F7IDMYiwyawCZtTPy6poirxiLvBpAXu3cGJm1Z2vLNhsAAAAAMFWWGAMAAADAhGkQAgAAAMCEaRACAAAAwIRpEAIAAADAhGkQAgAAAMCEaRACAAAAwIRpEAIAAADAhP0ffXUDfJk1zQUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1296x1296 with 9 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cancer.dtypes.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0BCLppFqngu",
        "outputId": "d960b3ce-95d2-4b06-a5e8-03523395bbb1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "int64     9\n",
              "object    1\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cancer.select_dtypes('object')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9tfUtBPsqnps",
        "outputId": "15f11745-6fed-4f62-cbcd-ced120affc72"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2dbeb7fc-cace-4feb-8c97-290e56e7fece\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BareNuclei</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>236</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>238</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>240</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>242</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>264</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>276</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>281</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>283</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>289</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>291</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>308</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>310</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>312</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>315</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>317</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>322</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>324</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>328</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>330</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>331</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>332</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>333</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>335</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>336</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>337</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>338</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>339</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>345</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>351</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>352</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>358</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>359</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>360</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>364</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>365</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>367</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>368</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>369</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>372</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>376</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>378</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>380</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>381</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>382</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>384</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>385</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>386</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>387</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>388</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>389</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>390</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>391</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>401</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>403</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>405</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>406</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>407</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>408</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>409</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>410</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>411</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>412</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>418</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>419</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>423</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>424</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>425</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>426</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>427</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>429</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>430</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>432</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>433</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>434</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>436</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>437</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>441</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>442</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>443</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>444</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>445</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>446</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>452</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>453</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>454</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>459</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>461</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>463</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>465</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>466</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>467</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>468</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>469</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>470</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>471</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>472</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>473</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>474</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>475</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>476</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>477</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>478</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>479</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2dbeb7fc-cace-4feb-8c97-290e56e7fece')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2dbeb7fc-cace-4feb-8c97-290e56e7fece button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2dbeb7fc-cace-4feb-8c97-290e56e7fece');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    BareNuclei\n",
              "0            1\n",
              "1           10\n",
              "2            2\n",
              "3            1\n",
              "4           10\n",
              "5           10\n",
              "6            1\n",
              "7            1\n",
              "8            1\n",
              "9            3\n",
              "10           9\n",
              "11           1\n",
              "12           1\n",
              "13          10\n",
              "14          10\n",
              "15           7\n",
              "16           1\n",
              "17           ?\n",
              "18           7\n",
              "19           1\n",
              "20           1\n",
              "21           1\n",
              "22           1\n",
              "23           5\n",
              "24           1\n",
              "25           1\n",
              "26           1\n",
              "27          10\n",
              "28           7\n",
              "29           3\n",
              "30          10\n",
              "31           1\n",
              "32           1\n",
              "33           1\n",
              "34           9\n",
              "35           8\n",
              "36           3\n",
              "37           4\n",
              "38           5\n",
              "39           8\n",
              "40           8\n",
              "41           5\n",
              "42           6\n",
              "43           1\n",
              "44          10\n",
              "45           2\n",
              "46           3\n",
              "47           2\n",
              "48           8\n",
              "49           2\n",
              "50           2\n",
              "51           1\n",
              "52          10\n",
              "53           9\n",
              "54           1\n",
              "55           1\n",
              "56           2\n",
              "57           1\n",
              "58          10\n",
              "59           4\n",
              "60           1\n",
              "61           1\n",
              "62           1\n",
              "63           9\n",
              "64           4\n",
              "65           8\n",
              "66          10\n",
              "67           1\n",
              "68           1\n",
              "69           1\n",
              "70           1\n",
              "71           6\n",
              "72          10\n",
              "73           5\n",
              "74           5\n",
              "75           1\n",
              "76           3\n",
              "77           1\n",
              "78           3\n",
              "79          10\n",
              "80          10\n",
              "81           1\n",
              "82           9\n",
              "83           9\n",
              "84          10\n",
              "85           8\n",
              "86           3\n",
              "87           2\n",
              "88          10\n",
              "89           3\n",
              "90           2\n",
              "91          10\n",
              "92          10\n",
              "93           7\n",
              "94           1\n",
              "95          10\n",
              "96           1\n",
              "97          10\n",
              "98           1\n",
              "99           1\n",
              "100          1\n",
              "101         10\n",
              "102          1\n",
              "103          2\n",
              "104          1\n",
              "105          ?\n",
              "106          1\n",
              "107          5\n",
              "108          8\n",
              "109         10\n",
              "110          1\n",
              "111         10\n",
              "112          5\n",
              "113         10\n",
              "114          1\n",
              "115         10\n",
              "116         10\n",
              "117          1\n",
              "118          1\n",
              "119          3\n",
              "120         10\n",
              "121          1\n",
              "122         10\n",
              "123         10\n",
              "124         10\n",
              "125          1\n",
              "126          1\n",
              "127          1\n",
              "128         10\n",
              "129          1\n",
              "130          1\n",
              "131         10\n",
              "132         10\n",
              "133          8\n",
              "134         10\n",
              "135          8\n",
              "136          8\n",
              "137         10\n",
              "138          1\n",
              "139          1\n",
              "140          1\n",
              "141          1\n",
              "142          1\n",
              "143          1\n",
              "144         10\n",
              "145         10\n",
              "146          1\n",
              "147          1\n",
              "148          1\n",
              "149         10\n",
              "150          5\n",
              "151          1\n",
              "152          1\n",
              "153         10\n",
              "154          8\n",
              "155          1\n",
              "156         10\n",
              "157         10\n",
              "158          5\n",
              "159          1\n",
              "160          4\n",
              "161         10\n",
              "162          5\n",
              "163          8\n",
              "164         10\n",
              "165          1\n",
              "166          5\n",
              "167          1\n",
              "168         10\n",
              "169          7\n",
              "170          8\n",
              "171         10\n",
              "172         10\n",
              "173          2\n",
              "174          9\n",
              "175         10\n",
              "176          2\n",
              "177          1\n",
              "178          1\n",
              "179         10\n",
              "180          9\n",
              "181          1\n",
              "182          ?\n",
              "183         10\n",
              "184         10\n",
              "185         10\n",
              "186          8\n",
              "187         10\n",
              "188          1\n",
              "189          1\n",
              "190          1\n",
              "191         10\n",
              "192         10\n",
              "193         10\n",
              "194         10\n",
              "195          3\n",
              "196         10\n",
              "197         10\n",
              "198          4\n",
              "199          1\n",
              "200         10\n",
              "201          1\n",
              "202         10\n",
              "203          4\n",
              "204          7\n",
              "205         10\n",
              "206         10\n",
              "207         10\n",
              "208         10\n",
              "209         10\n",
              "210          5\n",
              "211         10\n",
              "212          1\n",
              "213          1\n",
              "214          ?\n",
              "215         10\n",
              "216         10\n",
              "217          5\n",
              "218          ?\n",
              "219          1\n",
              "220         10\n",
              "221          4\n",
              "222          1\n",
              "223         10\n",
              "224          1\n",
              "225         10\n",
              "226         10\n",
              "227          3\n",
              "228          5\n",
              "229          1\n",
              "230          1\n",
              "231          1\n",
              "232         10\n",
              "233          8\n",
              "234          1\n",
              "235          5\n",
              "236         10\n",
              "237         10\n",
              "238          1\n",
              "239          1\n",
              "240         10\n",
              "241          4\n",
              "242         10\n",
              "243          8\n",
              "244         10\n",
              "245         10\n",
              "246         10\n",
              "247          1\n",
              "248          1\n",
              "249         10\n",
              "250         10\n",
              "251          1\n",
              "252         10\n",
              "253          1\n",
              "254          1\n",
              "255          8\n",
              "256          1\n",
              "257         10\n",
              "258          3\n",
              "259         10\n",
              "260          4\n",
              "261          7\n",
              "262         10\n",
              "263         10\n",
              "264          3\n",
              "265          1\n",
              "266          1\n",
              "267         10\n",
              "268         10\n",
              "269          1\n",
              "270          1\n",
              "271          1\n",
              "272          1\n",
              "273          1\n",
              "274          1\n",
              "275         10\n",
              "276         10\n",
              "277          1\n",
              "278          2\n",
              "279         10\n",
              "280          1\n",
              "281          1\n",
              "282          1\n",
              "283          1\n",
              "284          9\n",
              "285          1\n",
              "286          4\n",
              "287          1\n",
              "288          1\n",
              "289          2\n",
              "290          1\n",
              "291          1\n",
              "292          4\n",
              "293         10\n",
              "294          3\n",
              "295         10\n",
              "296          1\n",
              "297          2\n",
              "298          3\n",
              "299         10\n",
              "300          1\n",
              "301          1\n",
              "302         10\n",
              "303          2\n",
              "304          1\n",
              "305          1\n",
              "306          1\n",
              "307          1\n",
              "308          1\n",
              "309         10\n",
              "310          1\n",
              "311          1\n",
              "312          1\n",
              "313          1\n",
              "314         10\n",
              "315          4\n",
              "316          2\n",
              "317          1\n",
              "318         10\n",
              "319          1\n",
              "320          1\n",
              "321          1\n",
              "322         10\n",
              "323          1\n",
              "324          6\n",
              "325         10\n",
              "326          3\n",
              "327          1\n",
              "328          4\n",
              "329         10\n",
              "330         10\n",
              "331          1\n",
              "332          1\n",
              "333          1\n",
              "334          1\n",
              "335          1\n",
              "336          1\n",
              "337         10\n",
              "338          1\n",
              "339          1\n",
              "340          5\n",
              "341         10\n",
              "342          1\n",
              "343          3\n",
              "344          1\n",
              "345         10\n",
              "346          3\n",
              "347          4\n",
              "348         10\n",
              "349         10\n",
              "350          1\n",
              "351          1\n",
              "352          1\n",
              "353          1\n",
              "354          1\n",
              "355          1\n",
              "356          5\n",
              "357          1\n",
              "358          1\n",
              "359          1\n",
              "360         10\n",
              "361         10\n",
              "362          1\n",
              "363          1\n",
              "364          1\n",
              "365         10\n",
              "366          1\n",
              "367          5\n",
              "368         10\n",
              "369          1\n",
              "370          1\n",
              "371          1\n",
              "372          1\n",
              "373          1\n",
              "374         10\n",
              "375          1\n",
              "376          1\n",
              "377          1\n",
              "378          1\n",
              "379          1\n",
              "380          1\n",
              "381          2\n",
              "382          1\n",
              "383          1\n",
              "384         10\n",
              "385          1\n",
              "386          5\n",
              "387          1\n",
              "388          1\n",
              "389          1\n",
              "390          5\n",
              "391          1\n",
              "392          1\n",
              "393          1\n",
              "394          1\n",
              "395          1\n",
              "396          1\n",
              "397          1\n",
              "398          1\n",
              "399         10\n",
              "400         10\n",
              "401          5\n",
              "402         10\n",
              "403         10\n",
              "404          1\n",
              "405          2\n",
              "406          1\n",
              "407          1\n",
              "408         10\n",
              "409         10\n",
              "410          1\n",
              "411          1\n",
              "412         10\n",
              "413          3\n",
              "414          1\n",
              "415          1\n",
              "416         10\n",
              "417         10\n",
              "418          1\n",
              "419         10\n",
              "420          1\n",
              "421          1\n",
              "422          1\n",
              "423          1\n",
              "424          1\n",
              "425         10\n",
              "426          8\n",
              "427          1\n",
              "428         10\n",
              "429          1\n",
              "430         10\n",
              "431          2\n",
              "432         10\n",
              "433          1\n",
              "434          1\n",
              "435          1\n",
              "436          1\n",
              "437          2\n",
              "438          1\n",
              "439          6\n",
              "440          5\n",
              "441          1\n",
              "442          1\n",
              "443          3\n",
              "444          1\n",
              "445          2\n",
              "446          1\n",
              "447          1\n",
              "448          1\n",
              "449          1\n",
              "450          1\n",
              "451          1\n",
              "452          1\n",
              "453          2\n",
              "454          1\n",
              "455          1\n",
              "456          1\n",
              "457          1\n",
              "458          1\n",
              "459         10\n",
              "460          1\n",
              "461          1\n",
              "462          1\n",
              "463          1\n",
              "464          1\n",
              "465          1\n",
              "466          5\n",
              "467          8\n",
              "468          1\n",
              "469          1\n",
              "470          1\n",
              "471         10\n",
              "472         10\n",
              "473          1\n",
              "474          5\n",
              "475          1\n",
              "476          2\n",
              "477          3\n",
              "478          4\n",
              "479          5"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cancer = cancer.replace('?' ,np.nan)\n",
        "##Finding the the count and percentage of values that are missing in the dataframe.\n",
        "null1 = pd.DataFrame({'Count': cancer.isnull().sum(), 'Percent': 100*cancer.isnull().sum()/len(cancer)})\n",
        "\n",
        "##printing columns with null count more than 0\n",
        "null1[null1['Count'] > 0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "2D_5_XqoqjYa",
        "outputId": "28bcfe8a-efdb-414a-a843-92d6e4037915"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-630a9c69-f727-4058-959d-707b3a992ae2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Count</th>\n",
              "      <th>Percent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>BareNuclei</th>\n",
              "      <td>5</td>\n",
              "      <td>1.041667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-630a9c69-f727-4058-959d-707b3a992ae2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-630a9c69-f727-4058-959d-707b3a992ae2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-630a9c69-f727-4058-959d-707b3a992ae2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            Count   Percent\n",
              "BareNuclei      5  1.041667"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cancer[\"BareNuclei\"]=cancer[\"BareNuclei\"].astype(float)\n",
        "cancer=cancer.fillna(cancer.mean())"
      ],
      "metadata": {
        "id": "N9iTB1xuq12I"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation between feature and target variables\n",
        "# Delete the variables having low or no correlation with target variables\n",
        "corr_list1=cancer.corr()['classes'].abs().sort_values(ascending=False)\n",
        "corr_list_new=corr_list1[corr_list1>0.01].index.values.tolist()\n",
        "corr_list1\n",
        "cancer=cancer[corr_list_new]\n",
        "cancer.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "7T7BpKp2q2B7",
        "outputId": "0fb916f9-f188-4175-9914-0179b68fc4c7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-53e8dcd7-b096-40d2-84ec-82bfc9faa835\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>classes</th>\n",
              "      <th>UniformityofCellShape</th>\n",
              "      <th>UniformityofCellSize</th>\n",
              "      <th>BareNuclei</th>\n",
              "      <th>BlandChromatin</th>\n",
              "      <th>ClumpThickness</th>\n",
              "      <th>NormalNucleoli</th>\n",
              "      <th>MarginalAdhesion</th>\n",
              "      <th>SingleEpithelialCellSize</th>\n",
              "      <th>Mitoses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53e8dcd7-b096-40d2-84ec-82bfc9faa835')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-53e8dcd7-b096-40d2-84ec-82bfc9faa835 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-53e8dcd7-b096-40d2-84ec-82bfc9faa835');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   classes  UniformityofCellShape  UniformityofCellSize  BareNuclei  BlandChromatin  ClumpThickness  NormalNucleoli  MarginalAdhesion  SingleEpithelialCellSize  Mitoses\n",
              "0        0                      1                     1         1.0               3               5               1                 1                         2        1\n",
              "1        0                      4                     4        10.0               3               5               2                 5                         7        1\n",
              "2        0                      1                     1         2.0               3               3               1                 1                         2        1"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#find the variables with high correlations\n",
        "cor1 = cancer.corr().abs()\n",
        "list1 = cor1.stack().sort_values(ascending=False).drop_duplicates()  \n",
        "high_corr= list1[list1>0.70].index.values.tolist()\n",
        "high_corr.remove(high_corr[0])\n",
        "\n",
        "display(list1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "id": "ICgWIikRq7jF",
        "outputId": "df6a9e25-e6b7-431f-fd2f-1d3a131a23f4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Mitoses                   Mitoses                     1.000000\n",
              "UniformityofCellSize      UniformityofCellShape       0.899454\n",
              "classes                   UniformityofCellShape       0.810122\n",
              "                          UniformityofCellSize        0.799975\n",
              "BareNuclei                classes                     0.794158\n",
              "BlandChromatin            UniformityofCellSize        0.740364\n",
              "classes                   BlandChromatin              0.738089\n",
              "SingleEpithelialCellSize  UniformityofCellSize        0.728269\n",
              "UniformityofCellShape     BlandChromatin              0.721964\n",
              "ClumpThickness            classes                     0.700278\n",
              "UniformityofCellShape     SingleEpithelialCellSize    0.697336\n",
              "                          NormalNucleoli              0.688131\n",
              "NormalNucleoli            classes                     0.686994\n",
              "UniformityofCellSize      NormalNucleoli              0.685009\n",
              "                          MarginalAdhesion            0.678232\n",
              "UniformityofCellShape     BareNuclei                  0.672275\n",
              "classes                   MarginalAdhesion            0.667926\n",
              "SingleEpithelialCellSize  classes                     0.661948\n",
              "MarginalAdhesion          UniformityofCellShape       0.660651\n",
              "                          BlandChromatin              0.646206\n",
              "BareNuclei                BlandChromatin              0.643609\n",
              "                          UniformityofCellSize        0.637756\n",
              "                          MarginalAdhesion            0.630292\n",
              "BlandChromatin            NormalNucleoli              0.627962\n",
              "ClumpThickness            UniformityofCellShape       0.622286\n",
              "UniformityofCellSize      ClumpThickness              0.609471\n",
              "BlandChromatin            SingleEpithelialCellSize    0.587679\n",
              "SingleEpithelialCellSize  NormalNucleoli              0.576414\n",
              "MarginalAdhesion          NormalNucleoli              0.560620\n",
              "                          SingleEpithelialCellSize    0.557897\n",
              "ClumpThickness            BareNuclei                  0.549638\n",
              "BareNuclei                SingleEpithelialCellSize    0.534546\n",
              "                          NormalNucleoli              0.523289\n",
              "ClumpThickness            BlandChromatin              0.511431\n",
              "NormalNucleoli            ClumpThickness              0.484673\n",
              "ClumpThickness            SingleEpithelialCellSize    0.480802\n",
              "SingleEpithelialCellSize  Mitoses                     0.467525\n",
              "Mitoses                   UniformityofCellSize        0.434842\n",
              "MarginalAdhesion          ClumpThickness              0.426670\n",
              "UniformityofCellShape     Mitoses                     0.418462\n",
              "NormalNucleoli            Mitoses                     0.407428\n",
              "MarginalAdhesion          Mitoses                     0.393712\n",
              "classes                   Mitoses                     0.383559\n",
              "ClumpThickness            Mitoses                     0.329094\n",
              "Mitoses                   BlandChromatin              0.312838\n",
              "BareNuclei                Mitoses                     0.296946\n",
              "dtype: float64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for variable pairs with high correlation, keep only one of them\n",
        "columnlist=list(cancer.columns)\n",
        "len(high_corr)\n",
        "for i in range(len(high_corr)):\n",
        "    if \"classes\" in high_corr[i]:\n",
        "        columnlist=columnlist\n",
        "    else:\n",
        "        if high_corr[i][0] in columnlist and high_corr[i][1] in columnlist:\n",
        "            columnlist.remove(high_corr[i][1])\n",
        "        else:\n",
        "            columnlist=columnlist\n",
        "cancer_final=cancer[columnlist]\n",
        "#['ClumpThickness','UniformityofCellSize','UniformityofCellShape','MarginalAdhesion',\n",
        "#'SingleEpithelialCellSize','BareNuclei','BlandChromatin','NormalNucleoli','Mitoses']\n"
      ],
      "metadata": {
        "id": "QPJFovOPrDe6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "training_data, test_data = train_test_split(cancer_final,random_state=None, shuffle=True)\n",
        "train_x=training_data.drop(['classes'], 1) \n",
        "train_y=training_data[['classes']]\n",
        "test_x=test_data.drop(['classes'], 1)\n",
        "test_y=test_data[['classes']]"
      ],
      "metadata": {
        "id": "mQo-K2z6rDod"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Re-do data preparation: delete the outliers and perform normalisation\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# Remove outliers\n",
        "cancer_norm = cancer_final[(np.abs(scipy.stats.zscore(cancer_final)) < 3).all(axis=1)]\n",
        "# Zero mean normalisation\n",
        "cancer_norm.iloc[:,1:]=(cancer_norm.iloc[:,1:]-cancer_norm.iloc[:,1:].mean())/cancer_norm.iloc[:,1:].std()"
      ],
      "metadata": {
        "id": "uLfRhPH9pi-a"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cancer_norm.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2ec16ByZrrtz",
        "outputId": "81d41cd9-4955-4122-b59d-3518b1ee87e1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1bb10a2c-cf5f-455c-9590-f19afcf98b11\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>classes</th>\n",
              "      <th>BareNuclei</th>\n",
              "      <th>BlandChromatin</th>\n",
              "      <th>ClumpThickness</th>\n",
              "      <th>NormalNucleoli</th>\n",
              "      <th>MarginalAdhesion</th>\n",
              "      <th>SingleEpithelialCellSize</th>\n",
              "      <th>Mitoses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.867095</td>\n",
              "      <td>-0.364273</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.722638</td>\n",
              "      <td>-0.750496</td>\n",
              "      <td>-0.658219</td>\n",
              "      <td>-0.408805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1.438747</td>\n",
              "      <td>-0.364273</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.417495</td>\n",
              "      <td>0.556819</td>\n",
              "      <td>1.512200</td>\n",
              "      <td>-0.408805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.610890</td>\n",
              "      <td>-0.364273</td>\n",
              "      <td>-0.692337</td>\n",
              "      <td>-0.722638</td>\n",
              "      <td>-0.750496</td>\n",
              "      <td>-0.658219</td>\n",
              "      <td>-0.408805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.867095</td>\n",
              "      <td>-0.364273</td>\n",
              "      <td>-0.346168</td>\n",
              "      <td>-0.722638</td>\n",
              "      <td>-0.096838</td>\n",
              "      <td>-0.658219</td>\n",
              "      <td>-0.408805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1.438747</td>\n",
              "      <td>1.968768</td>\n",
              "      <td>1.038505</td>\n",
              "      <td>1.108223</td>\n",
              "      <td>1.537306</td>\n",
              "      <td>1.512200</td>\n",
              "      <td>-0.408805</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1bb10a2c-cf5f-455c-9590-f19afcf98b11')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1bb10a2c-cf5f-455c-9590-f19afcf98b11 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1bb10a2c-cf5f-455c-9590-f19afcf98b11');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   classes  BareNuclei  BlandChromatin  ClumpThickness  NormalNucleoli  MarginalAdhesion  SingleEpithelialCellSize   Mitoses\n",
              "0        0   -0.867095       -0.364273        0.000000       -0.722638         -0.750496                 -0.658219 -0.408805\n",
              "1        0    1.438747       -0.364273        0.000000       -0.417495          0.556819                  1.512200 -0.408805\n",
              "2        0   -0.610890       -0.364273       -0.692337       -0.722638         -0.750496                 -0.658219 -0.408805\n",
              "3        0   -0.867095       -0.364273       -0.346168       -0.722638         -0.096838                 -0.658219 -0.408805\n",
              "4        1    1.438747        1.968768        1.038505        1.108223          1.537306                  1.512200 -0.408805"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#split the new dataset\n",
        "training_data_norm, test_data_norm = train_test_split(cancer_norm,random_state=None, shuffle=True)\n",
        "train_x_norm=training_data_norm.drop(['classes'], 1) \n",
        "train_y_norm=training_data_norm[['classes']]\n",
        "test_x_norm=test_data_norm.drop(['classes'], 1)\n",
        "test_y_norm=test_data_norm[['classes']]"
      ],
      "metadata": {
        "id": "I1zdyDR3rxef"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.array(train_x_norm)\n",
        "print(x_train.shape)\n",
        "y_train = np.array(train_y_norm)\n",
        "print(y_train.shape)\n",
        "x_test = np.array(test_x_norm)\n",
        "print(x_test.shape)\n",
        "y_test = np.array(test_y_norm)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_tPN49VsH8F",
        "outputId": "4cdf17b4-0447-44be-e857-a10707b10c06"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(344, 7)\n",
            "(344, 1)\n",
            "(115, 7)\n",
            "(115, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mZ7OZAlgsHUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classifier "
      ],
      "metadata": {
        "id": "wTTnJFrVbfkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(dim):\n",
        "    ''' In this function, we will initialize our weights and bias'''\n",
        "    # Here dimenstion refer to the number of the attributes in the data\n",
        "    w = np.zeros(shape=len(dim))\n",
        "    b = 0\n",
        "    return w,b"
      ],
      "metadata": {
        "id": "O6c7m4dIpaRp"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dim=x_train[0]\n",
        "w,b = initialize_weights(dim)\n",
        "print('w =',(w))\n",
        "print('b =',b)\n",
        "print('w',np.sum(w))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DI9GGd5tb3Dp",
        "outputId": "00320de6-4ffe-42ee-bb87-641812bd3f2c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w = [0. 0. 0. 0. 0. 0. 0.]\n",
            "b = 0\n",
            "w 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Grader Function\n",
        "## Dont run this cell untill and unless you want to check wether everything is fine or not \n",
        "w,b = initialize_weights(dim)\n",
        "def grader_weights(w,b):\n",
        "  assert((len(w)==len(dim)) and b==0 and np.sum(w)==0.0)\n",
        "  return True\n",
        "grader_weights(w,b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJtjAaW4s6LU",
        "outputId": "2e5d30ae-8881-4f0f-c45e-4045ba7ea947"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    ''' In this function, we will return sigmoid of z'''\n",
        "    # compute sigmoid(z) and return\n",
        "    return 1/(1+np.exp(-z))"
      ],
      "metadata": {
        "id": "SjvsOGnDs9ni"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_loss(y_labels,y_predicted):\n",
        "    '''This function will return the log loss of the function'''\n",
        "    loss = -1 * (np.sum((y_labels * np.log10(y_predicted))+ \\\n",
        "                      ((1-y_labels)*np.log10(1-y_predicted))))/len(y_labels)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "dJ2pCyT8s_3u"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_dw(x,y,w,b,alpha,N):\n",
        "    '''In this function, we will compute the gardient w.r.to w '''\n",
        "    # Calculcating the graindent of weighted vectors\n",
        "    return x * (y - sigmoid(np.dot(w, x) + b)) - alpha/N*w"
      ],
      "metadata": {
        "id": "KXWKlYehtDun"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_db(x,y,w,b):\n",
        "    '''In this function, we will compute gradient w.r.to b '''\n",
        "    # Calculating the gradient of bais\n",
        "    return y - sigmoid(np.dot(w, x) + b)"
      ],
      "metadata": {
        "id": "sGfPtyogtHKg"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(X_train,y_train,X_test,y_test,epochs,alpha,eta0,p):\n",
        "    ''' In this function, we will implement logistic regression'''\n",
        "    \n",
        "    w,b = initialize_weights(X_train[0]) # intilize weight vectors\n",
        "    same_loss_counter = 0\n",
        "    N = len(X_train)\n",
        "    train_loss , test_loss = [],[]\n",
        "    part_no = 0\n",
        "    part_size = 25\n",
        "    ctr = 0\n",
        "    n = len(X_train)\n",
        "    \n",
        "    # Loop to traveres in epoches\n",
        "    for i in tqdm(range(0,epochs)):\n",
        "        # Loop to access data point in the \n",
        "        for j in range(part_size):\n",
        "            \n",
        "            # Calculating gradient of w and adding it to the existing one    \n",
        "            w = w + eta0*gradient_dw(X_train[(j+part_no)%n], y_train[(j+part_no)%n],w, b, alpha, len(X_train))\n",
        "            \n",
        "            #Calculating gradient of b and adding it to the existing one\n",
        "            b = b + eta0*gradient_db(X_train[(j+part_no)%n], y_train[(j+part_no)%n], w, b)\n",
        "        \n",
        "\n",
        "        part_no = (part_no + part_size)%n # To updtae the new part\n",
        "\n",
        "        #Predicting the traing data in comparison of the the xtrain\n",
        "        y_pred_train = np.array([sigmoid(np.dot(w, x)+b) for x in X_train])\n",
        "        \n",
        "        #Predicting the test data in comaprison of the xtest\n",
        "        y_pred_test = np.array([sigmoid(np.dot(w, x)+b) for x in X_test])\n",
        "\n",
        "        #Calculating the loss on for training data\n",
        "        loss = log_loss(y_train,y_pred_train)\n",
        "        train_loss.append(loss)\n",
        "        \n",
        "        #Calculatig the loss onfor testing data\n",
        "        loss = log_loss(y_test,y_pred_test)\n",
        "        test_loss.append(loss)\n",
        "\n",
        "        ## Printing values\n",
        "        print('\\n-- Epoch no(iteration no) ', i+1,'\\n Train data set : ')\n",
        "        #print('Actual values: ', y_train ,'\\n Predicted Values : ', y_pred_train)\n",
        "        #print('Test data set :') \n",
        "       # print('Actual values: ', y_test, '\\nPredicated Values : ', y_pred_test)\n",
        "        print('W intercept: {}, B intercept: {}, Train loss: {}, Test loss: {}'\\\n",
        "              .format(w, b, train_loss[i], test_loss[i]))\n",
        "    return w,b,train_loss,test_loss"
      ],
      "metadata": {
        "id": "-4IK2VhhtLjD"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "alpha=0.0001\n",
        "eta0=0.01\n",
        "N=len(x_train)\n",
        "epochs=100\n",
        "p = 2\n",
        "w,b,train_loss,test_loss=train(x_train,y_train,x_test,y_test,epochs,alpha,eta0,p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzpYsPoGtO9i",
        "outputId": "06a6ea66-d1e2-4b6b-c655-c7b68ab5b1ad"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-- Epoch no(iteration no)  1 \n",
            " Train data set : \n",
            "W intercept: [0.09378934 0.06366788 0.09572743 0.06796474 0.05708348 0.06488083\n",
            " 0.0611691 ], B intercept: [-0.00312706], Train loss: 0.23553051531111385, Test loss: 0.2341105140679492\n",
            "\n",
            "-- Epoch no(iteration no)  2 \n",
            " Train data set : \n",
            "W intercept: [0.16794052 0.13108358 0.1404377  0.11812889 0.11665895 0.13682411\n",
            " 0.09999935], B intercept: [-0.01006816], Train loss: 0.1933144566824417, Test loss: 0.18973948112310438\n",
            "\n",
            "-- Epoch no(iteration no)  3 \n",
            " Train data set : \n",
            "W intercept: [0.22175959 0.17176707 0.19030704 0.17191471 0.16332354 0.18712552\n",
            " 0.134391  ], B intercept: [-0.01068979], Train loss: 0.1658378373813592, Test loss: 0.1603334296937495\n",
            "\n",
            "-- Epoch no(iteration no)  4 \n",
            " Train data set : \n",
            "W intercept: [0.2771237  0.23953116 0.21884103 0.22139958 0.2122456  0.22733558\n",
            " 0.15176247], B intercept: [-0.02598477], Train loss: 0.14367332992193463, Test loss: 0.13664567818033144\n",
            "\n",
            "-- Epoch no(iteration no)  5 \n",
            " Train data set : \n",
            "W intercept: [0.32632161 0.2521527  0.28101369 0.24758167 0.23099415 0.2483478\n",
            " 0.17482092], B intercept: [-0.01197918], Train loss: 0.13070379264954976, Test loss: 0.12259947750839033\n",
            "\n",
            "-- Epoch no(iteration no)  6 \n",
            " Train data set : \n",
            "W intercept: [0.37412552 0.30888067 0.31443522 0.27980594 0.24710848 0.27204797\n",
            " 0.17640481], B intercept: [0.00128271], Train loss: 0.11863822262006357, Test loss: 0.10961652051152627\n",
            "\n",
            "-- Epoch no(iteration no)  7 \n",
            " Train data set : \n",
            "W intercept: [0.3850398  0.33765466 0.34665303 0.31907844 0.26226022 0.30833435\n",
            " 0.17343325], B intercept: [0.00826326], Train loss: 0.11101823178799032, Test loss: 0.1008863584969407\n",
            "\n",
            "-- Epoch no(iteration no)  8 \n",
            " Train data set : \n",
            "W intercept: [0.41091153 0.36690359 0.36849086 0.34705975 0.28520394 0.30420281\n",
            " 0.18985391], B intercept: [-0.01433892], Train loss: 0.10495214426253853, Test loss: 0.09440775485800781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 12/100 [00:00<00:00, 110.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-- Epoch no(iteration no)  9 \n",
            " Train data set : \n",
            "W intercept: [0.43915741 0.39912085 0.38434936 0.37318642 0.31129422 0.31360439\n",
            " 0.19598178], B intercept: [-0.01307352], Train loss: 0.09913488696638285, Test loss: 0.08804338972694817\n",
            "\n",
            "-- Epoch no(iteration no)  10 \n",
            " Train data set : \n",
            "W intercept: [0.47590177 0.42276529 0.41866623 0.38253291 0.32592848 0.32892655\n",
            " 0.19678204], B intercept: [-0.01423935], Train loss: 0.09380085195199855, Test loss: 0.08220463868344767\n",
            "\n",
            "-- Epoch no(iteration no)  11 \n",
            " Train data set : \n",
            "W intercept: [0.49568375 0.44737946 0.45027876 0.3948015  0.34970449 0.34491012\n",
            " 0.19566299], B intercept: [-0.01548183], Train loss: 0.08936355983338884, Test loss: 0.07735050881017397\n",
            "\n",
            "-- Epoch no(iteration no)  12 \n",
            " Train data set : \n",
            "W intercept: [0.51710031 0.46903146 0.45873599 0.40600496 0.39352599 0.35945702\n",
            " 0.19047966], B intercept: [0.00644922], Train loss: 0.08565780533716735, Test loss: 0.07333474265317921\n",
            "\n",
            "-- Epoch no(iteration no)  13 \n",
            " Train data set : \n",
            "W intercept: [0.54266788 0.48974628 0.47550036 0.41741743 0.41341413 0.37801546\n",
            " 0.19946064], B intercept: [-0.00114662], Train loss: 0.08223743221911399, Test loss: 0.06942036381262125\n",
            "\n",
            "-- Epoch no(iteration no)  14 \n",
            " Train data set : \n",
            "W intercept: [0.57220132 0.49968037 0.49722021 0.43001117 0.42412195 0.39340689\n",
            " 0.22114587], B intercept: [-0.00651243], Train loss: 0.0792079889712228, Test loss: 0.06585196251055407\n",
            "\n",
            "-- Epoch no(iteration no)  15 \n",
            " Train data set : \n",
            "W intercept: [0.58114796 0.50440018 0.52678169 0.44429891 0.42707121 0.39918335\n",
            " 0.24335314], B intercept: [-0.0093611], Train loss: 0.07725208249825359, Test loss: 0.0635560342800743\n",
            "\n",
            "-- Epoch no(iteration no)  16 \n",
            " Train data set : \n",
            "W intercept: [0.60288743 0.51717606 0.53119537 0.44814848 0.4388702  0.43219966\n",
            " 0.24674298], B intercept: [-0.00376945], Train loss: 0.07518771291056191, Test loss: 0.06093742234670188\n",
            "\n",
            "-- Epoch no(iteration no)  17 \n",
            " Train data set : \n",
            "W intercept: [0.62298408 0.52706932 0.54046641 0.46111217 0.45107545 0.43713704\n",
            " 0.24879501], B intercept: [-0.00330762], Train loss: 0.07352963413568411, Test loss: 0.05898575886561417\n",
            "\n",
            "-- Epoch no(iteration no)  18 \n",
            " Train data set : \n",
            "W intercept: [0.64024586 0.53899476 0.56983382 0.46193787 0.44985411 0.44070307\n",
            " 0.25694217], B intercept: [0.0082535], Train loss: 0.07183367103268909, Test loss: 0.05715616922747694\n",
            "\n",
            "-- Epoch no(iteration no)  19 \n",
            " Train data set : \n",
            "W intercept: [0.66309722 0.54652248 0.58790029 0.47481616 0.4623021  0.45208676\n",
            " 0.2627529 ], B intercept: [0.00779455], Train loss: 0.06997347509171908, Test loss: 0.054896879723703024\n",
            "\n",
            "-- Epoch no(iteration no)  20 \n",
            " Train data set : \n",
            "W intercept: [0.67119571 0.57550761 0.59585465 0.47981932 0.45955911 0.45943856\n",
            " 0.24949017], B intercept: [0.00918171], Train loss: 0.06890846956286761, Test loss: 0.053694699036321465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 24/100 [00:00<00:00, 86.74it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-- Epoch no(iteration no)  21 \n",
            " Train data set : \n",
            "W intercept: [0.6836621  0.58555522 0.61314195 0.50030686 0.46649149 0.47364201\n",
            " 0.25507402], B intercept: [0.02134273], Train loss: 0.06731675065795889, Test loss: 0.051639542717136826\n",
            "\n",
            "-- Epoch no(iteration no)  22 \n",
            " Train data set : \n",
            "W intercept: [0.68641257 0.60157373 0.61780991 0.51661719 0.47593117 0.45336834\n",
            " 0.25822735], B intercept: [0.01615135], Train loss: 0.0667141741617078, Test loss: 0.051125135851758784\n",
            "\n",
            "-- Epoch no(iteration no)  23 \n",
            " Train data set : \n",
            "W intercept: [0.69975307 0.61507705 0.62580383 0.52973426 0.48527944 0.46106378\n",
            " 0.26156868], B intercept: [0.01277009], Train loss: 0.06557508109239056, Test loss: 0.049702300649560514\n",
            "\n",
            "-- Epoch no(iteration no)  24 \n",
            " Train data set : \n",
            "W intercept: [0.71974867 0.62652808 0.6457792  0.53106025 0.48993913 0.46575787\n",
            " 0.26347994], B intercept: [0.01528751], Train loss: 0.06435163783396117, Test loss: 0.0483242910653748\n",
            "\n",
            "-- Epoch no(iteration no)  25 \n",
            " Train data set : \n",
            "W intercept: [0.7241869  0.63741834 0.66228591 0.53915318 0.50351917 0.47234392\n",
            " 0.26170211], B intercept: [0.02027051], Train loss: 0.06337596381244881, Test loss: 0.047188416149252344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 33/100 [00:00<00:00, 85.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-- Epoch no(iteration no)  26 \n",
            " Train data set : \n",
            "W intercept: [0.73511287 0.65132681 0.66312535 0.53708248 0.531703   0.48176752\n",
            " 0.25709528], B intercept: [0.03915209], Train loss: 0.06241489657900932, Test loss: 0.04617720132875163\n",
            "\n",
            "-- Epoch no(iteration no)  27 \n",
            " Train data set : \n",
            "W intercept: [0.75131058 0.66273473 0.66954297 0.54468411 0.54421873 0.49130956\n",
            " 0.26197087], B intercept: [0.02858791], Train loss: 0.0615003096234926, Test loss: 0.04501124035281429\n",
            "\n",
            "-- Epoch no(iteration no)  28 \n",
            " Train data set : \n",
            "W intercept: [0.76997757 0.66211756 0.69236294 0.54782195 0.54376781 0.49464723\n",
            " 0.29113106], B intercept: [0.03866887], Train loss: 0.060475794387717934, Test loss: 0.043831157016328316\n",
            "\n",
            "-- Epoch no(iteration no)  29 \n",
            " Train data set : \n",
            "W intercept: [0.77447672 0.66341625 0.70357962 0.56067532 0.54966991 0.49867646\n",
            " 0.29683666], B intercept: [0.027777], Train loss: 0.059980939445334884, Test loss: 0.04311607116267215\n",
            "\n",
            "-- Epoch no(iteration no)  30 \n",
            " Train data set : \n",
            "W intercept: [0.7893613  0.67135673 0.70830494 0.56147196 0.55441391 0.52533832\n",
            " 0.29622446], B intercept: [0.03617915], Train loss: 0.059208535534782475, Test loss: 0.04198157635870956\n",
            "\n",
            "-- Epoch no(iteration no)  31 \n",
            " Train data set : \n",
            "W intercept: [0.80002014 0.67749432 0.70775062 0.56524375 0.56436046 0.52441863\n",
            " 0.295047  ], B intercept: [0.03963536], Train loss: 0.05880848456565572, Test loss: 0.041527330975713504\n",
            "\n",
            "-- Epoch no(iteration no)  32 \n",
            " Train data set : \n",
            "W intercept: [0.81015432 0.67801588 0.73322661 0.56189389 0.55554901 0.52336316\n",
            " 0.30197784], B intercept: [0.05202153], Train loss: 0.058238296849328214, Test loss: 0.040940755627094774\n",
            "\n",
            "-- Epoch no(iteration no)  33 \n",
            " Train data set : \n",
            "W intercept: [0.82823464 0.68357963 0.74890045 0.56689581 0.56293467 0.53008081\n",
            " 0.30493271], B intercept: [0.05068711], Train loss: 0.0574513408565478, Test loss: 0.03994610068575943\n",
            "\n",
            "-- Epoch no(iteration no)  34 \n",
            " Train data set : \n",
            "W intercept: [0.82791063 0.70368161 0.750304   0.57517905 0.55806561 0.53822445\n",
            " 0.29309449], B intercept: [0.05163585], Train loss: 0.05714269228632689, Test loss: 0.03946705056264582\n",
            "\n",
            "-- Epoch no(iteration no)  35 \n",
            " Train data set : \n",
            "W intercept: [0.83936622 0.70481602 0.75404427 0.59014738 0.56631712 0.5412136\n",
            " 0.29284061], B intercept: [0.06622157], Train loss: 0.05660095342709617, Test loss: 0.03869283877602739\n",
            "\n",
            "-- Epoch no(iteration no)  36 \n",
            " Train data set : \n",
            "W intercept: [0.83465412 0.7219974  0.76463409 0.59761427 0.56680207 0.52055863\n",
            " 0.29698082], B intercept: [0.05757811], Train loss: 0.056402578682148215, Test loss: 0.03867691762822849\n",
            "\n",
            "-- Epoch no(iteration no)  37 \n",
            " Train data set : \n",
            "W intercept: [0.84593075 0.73228337 0.77047562 0.60278207 0.57074329 0.52869839\n",
            " 0.30178711], B intercept: [0.04994932], Train loss: 0.0559241210830848, Test loss: 0.03801406386088755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 42/100 [00:00<00:00, 84.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-- Epoch no(iteration no)  38 \n",
            " Train data set : \n",
            "W intercept: [0.85285398 0.74033122 0.7897064  0.6005975  0.57210187 0.52676844\n",
            " 0.30086325], B intercept: [0.06249135], Train loss: 0.05540597469831728, Test loss: 0.03751493138377074\n",
            "\n",
            "-- Epoch no(iteration no)  39 \n",
            " Train data set : \n",
            "W intercept: [0.8559583  0.74461544 0.79050111 0.61009917 0.596923   0.537143\n",
            " 0.29906964], B intercept: [0.06709426], Train loss: 0.054947463034536986, Test loss: 0.036867059105593826\n",
            "\n",
            "-- Epoch no(iteration no)  40 \n",
            " Train data set : \n",
            "W intercept: [0.86709953 0.75791035 0.79101238 0.60910129 0.60969975 0.5424684\n",
            " 0.29705655], B intercept: [0.07663541], Train loss: 0.05447974282295415, Test loss: 0.036337290930876225\n",
            "\n",
            "-- Epoch no(iteration no)  41 \n",
            " Train data set : \n",
            "W intercept: [0.87838418 0.76231488 0.79783694 0.61311022 0.61881538 0.54884651\n",
            " 0.30052846], B intercept: [0.07030028], Train loss: 0.05408326810306707, Test loss: 0.035787160902669306\n",
            "\n",
            "-- Epoch no(iteration no)  42 \n",
            " Train data set : \n",
            "W intercept: [0.89179822 0.76225371 0.81519272 0.61483462 0.61763454 0.54998041\n",
            " 0.32631547], B intercept: [0.07924752], Train loss: 0.053528639717405416, Test loss: 0.03516677010506294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 51/100 [00:00<00:00, 82.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-- Epoch no(iteration no)  43 \n",
            " Train data set : \n",
            "W intercept: [0.90122731 0.76111627 0.81970271 0.61961156 0.61704051 0.55822117\n",
            " 0.32804301], B intercept: [0.07691409], Train loss: 0.05330574242457102, Test loss: 0.03475592952696723\n",
            "\n",
            "-- Epoch no(iteration no)  44 \n",
            " Train data set : \n",
            "W intercept: [0.9050148  0.76563787 0.82630743 0.62391895 0.62399048 0.57395026\n",
            " 0.32938176], B intercept: [0.07860194], Train loss: 0.052969845533084675, Test loss: 0.03420475204614926\n",
            "\n",
            "-- Epoch no(iteration no)  45 \n",
            " Train data set : \n",
            "W intercept: [0.91548321 0.76970019 0.82618611 0.62526813 0.62981148 0.57069659\n",
            " 0.32692264], B intercept: [0.08359193], Train loss: 0.052755544112800055, Test loss: 0.033973480490480705\n",
            "\n",
            "-- Epoch no(iteration no)  46 \n",
            " Train data set : \n",
            "W intercept: [0.92619689 0.76838569 0.84876302 0.62287538 0.62033506 0.5696091\n",
            " 0.33194701], B intercept: [0.0988581], Train loss: 0.052350895344297675, Test loss: 0.033543736857660794\n",
            "\n",
            "-- Epoch no(iteration no)  47 \n",
            " Train data set : \n",
            "W intercept: [0.93768898 0.77432662 0.85885738 0.6268019  0.62669236 0.57580321\n",
            " 0.33451953], B intercept: [0.09602989], Train loss: 0.051959471825629065, Test loss: 0.03300269362671301\n",
            "\n",
            "-- Epoch no(iteration no)  48 \n",
            " Train data set : \n",
            "W intercept: [0.93508076 0.78778405 0.85903011 0.63202884 0.6233563  0.57843923\n",
            " 0.32131686], B intercept: [0.09674048], Train loss: 0.05188674040566107, Test loss: 0.03285223807143307\n",
            "\n",
            "-- Epoch no(iteration no)  49 \n",
            " Train data set : \n",
            "W intercept: [0.94431848 0.79031264 0.86041961 0.64320492 0.63108499 0.57929603\n",
            " 0.32263085], B intercept: [0.10692861], Train loss: 0.051576016379478694, Test loss: 0.03239270418972095\n",
            "\n",
            "-- Epoch no(iteration no)  50 \n",
            " Train data set : \n",
            "W intercept: [0.93517803 0.80257139 0.86924168 0.64686887 0.62839969 0.56056566\n",
            " 0.32591617], B intercept: [0.09941763], Train loss: 0.05156804927036558, Test loss: 0.032581221912222416\n",
            "\n",
            "-- Epoch no(iteration no)  51 \n",
            " Train data set : \n",
            "W intercept: [0.94572215 0.81252796 0.8760578  0.65135958 0.62972329 0.56838046\n",
            " 0.32499618], B intercept: [0.09176074], Train loss: 0.05127509445330274, Test loss: 0.03211194177771319\n",
            "\n",
            "-- Epoch no(iteration no)  52 \n",
            " Train data set : \n",
            "W intercept: [0.94960146 0.81775887 0.88720107 0.64902605 0.63170136 0.56648847\n",
            " 0.33147505], B intercept: [0.10135123], Train loss: 0.0510006449411968, Test loss: 0.031878598094927386\n",
            "\n",
            "-- Epoch no(iteration no)  53 \n",
            " Train data set : \n",
            "W intercept: [0.94936883 0.81969084 0.88860919 0.65558347 0.65223724 0.57406795\n",
            " 0.32868275], B intercept: [0.10915466], Train loss: 0.05075349449258419, Test loss: 0.031511240432902286\n",
            "\n",
            "-- Epoch no(iteration no)  54 \n",
            " Train data set : \n",
            "W intercept: [0.96207867 0.82986664 0.88819615 0.65307792 0.66577147 0.57746091\n",
            " 0.32532602], B intercept: [0.11976694], Train loss: 0.050428478634383045, Test loss: 0.031141225551377813\n",
            "\n",
            "-- Epoch no(iteration no)  55 \n",
            " Train data set : \n",
            "W intercept: [0.96959299 0.8350863  0.89417637 0.6591395  0.67077866 0.58272245\n",
            " 0.32980899], B intercept: [0.11001992], Train loss: 0.05021490159138325, Test loss: 0.03078350470340832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 60/100 [00:00<00:00, 81.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-- Epoch no(iteration no)  56 \n",
            " Train data set : \n",
            "W intercept: [0.97887337 0.82787597 0.9113691  0.66501391 0.66764158 0.58709791\n",
            " 0.35341889], B intercept: [0.11880233], Train loss: 0.04986122096770495, Test loss: 0.030305712068144572\n",
            "\n",
            "-- Epoch no(iteration no)  57 \n",
            " Train data set : \n",
            "W intercept: [0.98769633 0.83087485 0.91226342 0.66273791 0.66800298 0.59053748\n",
            " 0.35515356], B intercept: [0.11754098], Train loss: 0.04974731459507007, Test loss: 0.030145012553244206\n",
            "\n",
            "-- Epoch no(iteration no)  58 \n",
            " Train data set : \n",
            "W intercept: [0.99066751 0.83420047 0.91708357 0.66708007 0.67522626 0.60545167\n",
            " 0.35602143], B intercept: [0.11766441], Train loss: 0.04954470171828, Test loss: 0.02974587065745141\n",
            "\n",
            "-- Epoch no(iteration no)  59 \n",
            " Train data set : \n",
            "W intercept: [0.99919065 0.83691501 0.91640319 0.66667101 0.67950729 0.60081045\n",
            " 0.35294887], B intercept: [0.12327505], Train loss: 0.04942685407146083, Test loss: 0.02964406276700697\n",
            "\n",
            "-- Epoch no(iteration no)  60 \n",
            " Train data set : \n",
            "W intercept: [1.00949319 0.83295821 0.93943084 0.66048162 0.67257165 0.60096824\n",
            " 0.35905214], B intercept: [0.13560242], Train loss: 0.049118230960751366, Test loss: 0.029340251791384858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 69/100 [00:00<00:00, 81.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-- Epoch no(iteration no)  61 \n",
            " Train data set : \n",
            "W intercept: [1.02074569 0.84466686 0.94326935 0.66397506 0.67310822 0.60202841\n",
            " 0.35691434], B intercept: [0.14136959], Train loss: 0.048860100217872106, Test loss: 0.028993391024704312\n",
            "\n",
            "-- Epoch no(iteration no)  62 \n",
            " Train data set : \n",
            "W intercept: [1.01125586 0.85122882 0.94671975 0.67003381 0.67026022 0.60921164\n",
            " 0.34837516], B intercept: [0.14247282], Train loss: 0.04885130223601201, Test loss: 0.02888439674948416\n",
            "\n",
            "-- Epoch no(iteration no)  63 \n",
            " Train data set : \n",
            "W intercept: [1.02008325 0.8523396  0.94523971 0.67189118 0.67931908 0.60520144\n",
            " 0.34960202], B intercept: [0.13803031], Train loss: 0.04875970692564629, Test loss: 0.028781588330495933\n",
            "\n",
            "-- Epoch no(iteration no)  64 \n",
            " Train data set : \n",
            "W intercept: [1.01207486 0.86506005 0.94989069 0.68290913 0.67478088 0.58756709\n",
            " 0.34930414], B intercept: [0.13980095], Train loss: 0.048716544188202086, Test loss: 0.028836448576453063\n",
            "\n",
            "-- Epoch no(iteration no)  65 \n",
            " Train data set : \n",
            "W intercept: [1.01880716 0.86894051 0.95819865 0.68245537 0.67170218 0.59035908\n",
            " 0.35642926], B intercept: [0.14091042], Train loss: 0.048542860817581246, Test loss: 0.02861557964897847\n",
            "\n",
            "-- Epoch no(iteration no)  66 \n",
            " Train data set : \n",
            "W intercept: [1.02227276 0.87576295 0.9676274  0.68270403 0.6760101  0.59089048\n",
            " 0.35499093], B intercept: [0.14178841], Train loss: 0.04835945159942994, Test loss: 0.028407485322364184\n",
            "\n",
            "-- Epoch no(iteration no)  67 \n",
            " Train data set : \n",
            "W intercept: [1.02378424 0.87990266 0.96308557 0.68559366 0.70289608 0.59529892\n",
            " 0.34846596], B intercept: [0.15839393], Train loss: 0.04814932453259351, Test loss: 0.02814262592006393\n",
            "\n",
            "-- Epoch no(iteration no)  68 \n",
            " Train data set : \n",
            "W intercept: [1.03176712 0.88593329 0.96709002 0.68657462 0.70755112 0.60102971\n",
            " 0.34949265], B intercept: [0.15794894], Train loss: 0.04797502799087601, Test loss: 0.02787195798428362\n",
            "\n",
            "-- Epoch no(iteration no)  69 \n",
            " Train data set : \n",
            "W intercept: [1.04299475 0.88795201 0.9742772  0.69062504 0.71141094 0.60635674\n",
            " 0.35987317], B intercept: [0.15553544], Train loss: 0.047755763162802146, Test loss: 0.027526154906158472\n",
            "\n",
            "-- Epoch no(iteration no)  70 \n",
            " Train data set : \n",
            "W intercept: [1.04193911 0.87968182 0.98910084 0.69525307 0.70792578 0.60055405\n",
            " 0.37743852], B intercept: [0.15206577], Train loss: 0.04767085916203148, Test loss: 0.027463717762572813\n",
            "\n",
            "-- Epoch no(iteration no)  71 \n",
            " Train data set : \n",
            "W intercept: [1.050644   0.8828608  0.98780564 0.69177666 0.71122461 0.6213392\n",
            " 0.37578436], B intercept: [0.15932248], Train loss: 0.04752162167582616, Test loss: 0.027120194094840885\n",
            "\n",
            "-- Epoch no(iteration no)  72 \n",
            " Train data set : \n",
            "W intercept: [1.05800219 0.88097102 0.98845142 0.69164465 0.71432399 0.61658857\n",
            " 0.37322162], B intercept: [0.16379176], Train loss: 0.04745413598245201, Test loss: 0.02706456685343222\n",
            "\n",
            "-- Epoch no(iteration no)  73 \n",
            " Train data set : \n",
            "W intercept: [1.06230294 0.88729916 0.99776074 0.68979013 0.71043927 0.6177038\n",
            " 0.37469235], B intercept: [0.17199435], Train loss: 0.047285741140060386, Test loss: 0.02688492649160836\n",
            "\n",
            "-- Epoch no(iteration no)  74 \n",
            " Train data set : \n",
            "W intercept: [1.07343008 0.88376805 1.01301002 0.68938009 0.71152108 0.61942956\n",
            " 0.37909843], B intercept: [0.17479389], Train loss: 0.047072872767167234, Test loss: 0.026605316531561368\n",
            "\n",
            "-- Epoch no(iteration no)  75 \n",
            " Train data set : \n",
            "W intercept: [1.0688549  0.89822292 1.01157578 0.68736483 0.7056108  0.62227782\n",
            " 0.36506206], B intercept: [0.17086679], Train loss: 0.047111624707328804, Test loss: 0.02663790422781305\n",
            "\n",
            "-- Epoch no(iteration no)  76 \n",
            " Train data set : \n",
            "W intercept: [1.07374326 0.90112465 1.01831628 0.69620802 0.7089046  0.627605\n",
            " 0.3678071 ], B intercept: [0.17878629], Train loss: 0.046913895629494044, Test loss: 0.026290681739754154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 87/100 [00:01<00:00, 78.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-- Epoch no(iteration no)  77 \n",
            " Train data set : \n",
            "W intercept: [1.06489146 0.90696198 1.01659175 0.70305637 0.70928475 0.60321115\n",
            " 0.36968317], B intercept: [0.17480159], Train loss: 0.04699204390815393, Test loss: 0.02657392643248761\n",
            "\n",
            "-- Epoch no(iteration no)  78 \n",
            " Train data set : \n",
            "W intercept: [1.07127884 0.91257449 1.01909346 0.70895438 0.7114327  0.60511743\n",
            " 0.36916845], B intercept: [0.17682617], Train loss: 0.04685973385238063, Test loss: 0.026340370452947626\n",
            "\n",
            "-- Epoch no(iteration no)  79 \n",
            " Train data set : \n",
            "W intercept: [1.07805052 0.91631638 1.02776341 0.708377   0.70916671 0.6072726\n",
            " 0.37550172], B intercept: [0.17808737], Train loss: 0.046712718193692576, Test loss: 0.026152813232311733\n",
            "\n",
            "-- Epoch no(iteration no)  80 \n",
            " Train data set : \n",
            "W intercept: [1.07774851 0.92155094 1.03582849 0.71135717 0.71418497 0.60824762\n",
            " 0.37374067], B intercept: [0.18235462], Train loss: 0.04657785464957487, Test loss: 0.025979536963964416\n",
            "\n",
            "-- Epoch no(iteration no)  81 \n",
            " Train data set : \n",
            "W intercept: [1.07933196 0.92723009 1.03143664 0.70886041 0.7360474  0.61363119\n",
            " 0.36843532], B intercept: [0.19697467], Train loss: 0.04643026034660103, Test loss: 0.025812340074192506\n",
            "\n",
            "-- Epoch no(iteration no)  82 \n",
            " Train data set : \n",
            "W intercept: [1.08732755 0.93223179 1.03291021 0.71163578 0.74231384 0.61775541\n",
            " 0.37046349], B intercept: [0.1924998], Train loss: 0.0463209515902279, Test loss: 0.025607235637416684\n",
            "\n",
            "-- Epoch no(iteration no)  83 \n",
            " Train data set : \n",
            "W intercept: [1.09812876 0.93285385 1.04047008 0.71561729 0.74408391 0.62134185\n",
            " 0.37838907], B intercept: [0.19403915], Train loss: 0.04614645386088783, Test loss: 0.025323410692992477\n",
            "\n",
            "-- Epoch no(iteration no)  84 \n",
            " Train data set : \n",
            "W intercept: [1.09716792 0.92395399 1.05294924 0.72017077 0.74213076 0.61587316\n",
            " 0.39641653], B intercept: [0.18806479], Train loss: 0.04609564934612913, Test loss: 0.0252962117094612\n",
            "\n",
            "-- Epoch no(iteration no)  85 \n",
            " Train data set : \n",
            "W intercept: [1.10432367 0.92710168 1.05258307 0.71814614 0.74422027 0.63593594\n",
            " 0.39429808], B intercept: [0.19538078], Train loss: 0.04598159034771448, Test loss: 0.024989789333602318\n",
            "\n",
            "-- Epoch no(iteration no)  86 \n",
            " Train data set : \n",
            "W intercept: [1.11140123 0.92578816 1.05050743 0.71579913 0.74766763 0.63033002\n",
            " 0.3911695 ], B intercept: [0.20091449], Train loss: 0.04594258379920817, Test loss: 0.02499268311701386\n",
            "\n",
            "-- Epoch no(iteration no)  87 \n",
            " Train data set : \n",
            "W intercept: [1.11594581 0.92378247 1.06817851 0.70935706 0.73902675 0.62750648\n",
            " 0.39461784], B intercept: [0.2133812], Train loss: 0.04578799722523343, Test loss: 0.024895286726015754\n",
            "\n",
            "-- Epoch no(iteration no)  88 \n",
            " Train data set : \n",
            "W intercept: [1.12503966 0.92592673 1.07585449 0.71094858 0.74304936 0.63153432\n",
            " 0.39634659], B intercept: [0.2114051], Train loss: 0.04565206054347419, Test loss: 0.024666308079816533\n",
            "\n",
            "-- Epoch no(iteration no)  89 \n",
            " Train data set : \n",
            "W intercept: [1.11926005 0.93873426 1.0736442  0.71116741 0.73741462 0.63542456\n",
            " 0.38298945], B intercept: [0.20681346], Train loss: 0.045702596827549465, Test loss: 0.02468579508483653\n",
            "\n",
            "-- Epoch no(iteration no)  90 \n",
            " Train data set : \n",
            "W intercept: [1.12563695 0.93622322 1.06960067 0.72219793 0.74338629 0.63496811\n",
            " 0.38240499], B intercept: [0.22010802], Train loss: 0.04560354571770536, Test loss: 0.024470481875239546\n",
            "\n",
            "-- Epoch no(iteration no)  91 \n",
            " Train data set : \n",
            "W intercept: [1.11590249 0.94916458 1.07394886 0.72586673 0.74386299 0.61464689\n",
            " 0.38800979], B intercept: [0.2069419], Train loss: 0.04562790220711697, Test loss: 0.02468925141719018\n",
            "\n",
            "-- Epoch no(iteration no)  92 \n",
            " Train data set : \n",
            "W intercept: [1.12053583 0.95189953 1.07860032 0.72887539 0.74290329 0.61737256\n",
            " 0.38698661], B intercept: [0.21057422], Train loss: 0.045536355680925525, Test loss: 0.024520839277835764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 80.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-- Epoch no(iteration no)  93 \n",
            " Train data set : \n",
            "W intercept: [1.12206419 0.956749   1.09307359 0.72439181 0.73704621 0.61530485\n",
            " 0.39086374], B intercept: [0.21781969], Train loss: 0.04540289279002667, Test loss: 0.024435695464937936\n",
            "\n",
            "-- Epoch no(iteration no)  94 \n",
            " Train data set : \n",
            "W intercept: [1.12111875 0.95830136 1.08958259 0.73075158 0.75590322 0.62270987\n",
            " 0.38935791], B intercept: [0.22147245], Train loss: 0.04532192628506749, Test loss: 0.024243311653756334\n",
            "\n",
            "-- Epoch no(iteration no)  95 \n",
            " Train data set : \n",
            "W intercept: [1.12636682 0.96502018 1.08874708 0.72888117 0.76583477 0.6246203\n",
            " 0.38635061], B intercept: [0.23037417], Train loss: 0.04520831272190201, Test loss: 0.024109089692353456\n",
            "\n",
            "-- Epoch no(iteration no)  96 \n",
            " Train data set : \n",
            "W intercept: [1.13408618 0.96807586 1.09110256 0.73143952 0.77152413 0.62896455\n",
            " 0.38864895], B intercept: [0.2255038], Train loss: 0.045125980785393864, Test loss: 0.02393236858302144\n",
            "\n",
            "-- Epoch no(iteration no)  97 \n",
            " Train data set : \n",
            "W intercept: [1.14154051 0.96652027 1.10273672 0.73168982 0.76946853 0.6287015\n",
            " 0.40820431], B intercept: [0.23170582], Train loss: 0.04495907951107793, Test loss: 0.023755369194142173\n",
            "\n",
            "-- Epoch no(iteration no)  98 \n",
            " Train data set : \n",
            "W intercept: [1.14827625 0.96086797 1.10496315 0.73452144 0.76727606 0.63213262\n",
            " 0.41013702], B intercept: [0.22765776], Train loss: 0.044945334151877826, Test loss: 0.023654097794534795\n",
            "\n",
            "-- Epoch no(iteration no)  99 \n",
            " Train data set : \n",
            "W intercept: [1.14895857 0.96294846 1.10813865 0.73621716 0.77234541 0.64492117\n",
            " 0.41017397], B intercept: [0.22940383], Train loss: 0.04487578287766619, Test loss: 0.02345300196986869\n",
            "\n",
            "-- Epoch no(iteration no)  100 \n",
            " Train data set : \n",
            "W intercept: [1.1558451  0.96231157 1.10619944 0.73438029 0.77547536 0.63921149\n",
            " 0.40697878], B intercept: [0.23486845], Train loss: 0.044837441255093424, Test loss: 0.02345120984393605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
        "clf\n",
        "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
        "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
        "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
        "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
        "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
        "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)\n",
        "clf.fit(X=x_train, y=y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ql0A2xfZt8Am",
        "outputId": "3fef3c10-390c-42c7-8951-5682ce3315dd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: 0.03, NNZs: 7, Bias: -0.000690, T: 344, Avg. loss: 0.680013\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.06, NNZs: 7, Bias: -0.001393, T: 688, Avg. loss: 0.654740\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.09, NNZs: 7, Bias: -0.002091, T: 1032, Avg. loss: 0.631178\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 0.11, NNZs: 7, Bias: -0.002782, T: 1376, Avg. loss: 0.609183\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 0.14, NNZs: 7, Bias: -0.003473, T: 1720, Avg. loss: 0.588641\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 0.17, NNZs: 7, Bias: -0.004158, T: 2064, Avg. loss: 0.569440\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 0.19, NNZs: 7, Bias: -0.004842, T: 2408, Avg. loss: 0.551483\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 0.21, NNZs: 7, Bias: -0.005514, T: 2752, Avg. loss: 0.534666\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 0.24, NNZs: 7, Bias: -0.006179, T: 3096, Avg. loss: 0.518896\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 0.26, NNZs: 7, Bias: -0.006833, T: 3440, Avg. loss: 0.504098\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 0.28, NNZs: 7, Bias: -0.007469, T: 3784, Avg. loss: 0.490192\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 0.30, NNZs: 7, Bias: -0.008092, T: 4128, Avg. loss: 0.477108\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 0.32, NNZs: 7, Bias: -0.008707, T: 4472, Avg. loss: 0.464786\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 0.34, NNZs: 7, Bias: -0.009305, T: 4816, Avg. loss: 0.453166\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 0.36, NNZs: 7, Bias: -0.009890, T: 5160, Avg. loss: 0.442193\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 0.38, NNZs: 7, Bias: -0.010462, T: 5504, Avg. loss: 0.431825\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 0.40, NNZs: 7, Bias: -0.011015, T: 5848, Avg. loss: 0.422012\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 0.41, NNZs: 7, Bias: -0.011550, T: 6192, Avg. loss: 0.412713\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 0.43, NNZs: 7, Bias: -0.012067, T: 6536, Avg. loss: 0.403893\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 0.45, NNZs: 7, Bias: -0.012568, T: 6880, Avg. loss: 0.395519\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 0.46, NNZs: 7, Bias: -0.013052, T: 7224, Avg. loss: 0.387560\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 0.48, NNZs: 7, Bias: -0.013523, T: 7568, Avg. loss: 0.379989\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 0.50, NNZs: 7, Bias: -0.013973, T: 7912, Avg. loss: 0.372779\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 0.51, NNZs: 7, Bias: -0.014407, T: 8256, Avg. loss: 0.365903\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 0.53, NNZs: 7, Bias: -0.014822, T: 8600, Avg. loss: 0.359341\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 0.54, NNZs: 7, Bias: -0.015217, T: 8944, Avg. loss: 0.353072\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 0.55, NNZs: 7, Bias: -0.015597, T: 9288, Avg. loss: 0.347079\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 0.57, NNZs: 7, Bias: -0.015963, T: 9632, Avg. loss: 0.341344\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 0.58, NNZs: 7, Bias: -0.016313, T: 9976, Avg. loss: 0.335854\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 30\n",
            "Norm: 0.60, NNZs: 7, Bias: -0.016642, T: 10320, Avg. loss: 0.330592\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 31\n",
            "Norm: 0.61, NNZs: 7, Bias: -0.016961, T: 10664, Avg. loss: 0.325544\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 32\n",
            "Norm: 0.62, NNZs: 7, Bias: -0.017264, T: 11008, Avg. loss: 0.320699\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 33\n",
            "Norm: 0.63, NNZs: 7, Bias: -0.017547, T: 11352, Avg. loss: 0.316044\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 34\n",
            "Norm: 0.65, NNZs: 7, Bias: -0.017816, T: 11696, Avg. loss: 0.311570\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 35\n",
            "Norm: 0.66, NNZs: 7, Bias: -0.018071, T: 12040, Avg. loss: 0.307266\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 36\n",
            "Norm: 0.67, NNZs: 7, Bias: -0.018311, T: 12384, Avg. loss: 0.303123\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 37\n",
            "Norm: 0.68, NNZs: 7, Bias: -0.018536, T: 12728, Avg. loss: 0.299133\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 38\n",
            "Norm: 0.69, NNZs: 7, Bias: -0.018746, T: 13072, Avg. loss: 0.295287\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 39\n",
            "Norm: 0.70, NNZs: 7, Bias: -0.018942, T: 13416, Avg. loss: 0.291577\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 40\n",
            "Norm: 0.72, NNZs: 7, Bias: -0.019122, T: 13760, Avg. loss: 0.287997\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 41\n",
            "Norm: 0.73, NNZs: 7, Bias: -0.019289, T: 14104, Avg. loss: 0.284540\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 42\n",
            "Norm: 0.74, NNZs: 7, Bias: -0.019444, T: 14448, Avg. loss: 0.281201\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 43\n",
            "Norm: 0.75, NNZs: 7, Bias: -0.019583, T: 14792, Avg. loss: 0.277973\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 44\n",
            "Norm: 0.76, NNZs: 7, Bias: -0.019712, T: 15136, Avg. loss: 0.274851\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 45\n",
            "Norm: 0.77, NNZs: 7, Bias: -0.019828, T: 15480, Avg. loss: 0.271830\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 46\n",
            "Norm: 0.78, NNZs: 7, Bias: -0.019932, T: 15824, Avg. loss: 0.268905\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 47\n",
            "Norm: 0.79, NNZs: 7, Bias: -0.020025, T: 16168, Avg. loss: 0.266071\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 48\n",
            "Norm: 0.80, NNZs: 7, Bias: -0.020107, T: 16512, Avg. loss: 0.263325\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 49\n",
            "Norm: 0.81, NNZs: 7, Bias: -0.020175, T: 16856, Avg. loss: 0.260663\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 50\n",
            "Norm: 0.82, NNZs: 7, Bias: -0.020234, T: 17200, Avg. loss: 0.258081\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 51\n",
            "Norm: 0.82, NNZs: 7, Bias: -0.020281, T: 17544, Avg. loss: 0.255576\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 52\n",
            "Norm: 0.83, NNZs: 7, Bias: -0.020317, T: 17888, Avg. loss: 0.253144\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 53\n",
            "Norm: 0.84, NNZs: 7, Bias: -0.020342, T: 18232, Avg. loss: 0.250781\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 54\n",
            "Norm: 0.85, NNZs: 7, Bias: -0.020357, T: 18576, Avg. loss: 0.248486\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 55\n",
            "Norm: 0.86, NNZs: 7, Bias: -0.020362, T: 18920, Avg. loss: 0.246254\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 56\n",
            "Norm: 0.87, NNZs: 7, Bias: -0.020359, T: 19264, Avg. loss: 0.244085\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 57\n",
            "Norm: 0.88, NNZs: 7, Bias: -0.020342, T: 19608, Avg. loss: 0.241974\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 58\n",
            "Norm: 0.89, NNZs: 7, Bias: -0.020320, T: 19952, Avg. loss: 0.239921\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 59\n",
            "Norm: 0.89, NNZs: 7, Bias: -0.020287, T: 20296, Avg. loss: 0.237922\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 60\n",
            "Norm: 0.90, NNZs: 7, Bias: -0.020246, T: 20640, Avg. loss: 0.235976\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 61\n",
            "Norm: 0.91, NNZs: 7, Bias: -0.020194, T: 20984, Avg. loss: 0.234079\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 62\n",
            "Norm: 0.92, NNZs: 7, Bias: -0.020136, T: 21328, Avg. loss: 0.232232\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 63\n",
            "Norm: 0.93, NNZs: 7, Bias: -0.020070, T: 21672, Avg. loss: 0.230431\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 64\n",
            "Norm: 0.93, NNZs: 7, Bias: -0.019995, T: 22016, Avg. loss: 0.228675\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 65\n",
            "Norm: 0.94, NNZs: 7, Bias: -0.019911, T: 22360, Avg. loss: 0.226962\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 66\n",
            "Norm: 0.95, NNZs: 7, Bias: -0.019821, T: 22704, Avg. loss: 0.225290\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 67\n",
            "Norm: 0.96, NNZs: 7, Bias: -0.019722, T: 23048, Avg. loss: 0.223659\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 68\n",
            "Norm: 0.96, NNZs: 7, Bias: -0.019618, T: 23392, Avg. loss: 0.222067\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 69\n",
            "Norm: 0.97, NNZs: 7, Bias: -0.019504, T: 23736, Avg. loss: 0.220512\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 70\n",
            "Norm: 0.98, NNZs: 7, Bias: -0.019384, T: 24080, Avg. loss: 0.218993\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 71\n",
            "Norm: 0.98, NNZs: 7, Bias: -0.019256, T: 24424, Avg. loss: 0.217509\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 72\n",
            "Norm: 0.99, NNZs: 7, Bias: -0.019122, T: 24768, Avg. loss: 0.216059\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 73\n",
            "Norm: 1.00, NNZs: 7, Bias: -0.018982, T: 25112, Avg. loss: 0.214642\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 74\n",
            "Norm: 1.01, NNZs: 7, Bias: -0.018834, T: 25456, Avg. loss: 0.213256\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 75\n",
            "Norm: 1.01, NNZs: 7, Bias: -0.018681, T: 25800, Avg. loss: 0.211900\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 76\n",
            "Norm: 1.02, NNZs: 7, Bias: -0.018521, T: 26144, Avg. loss: 0.210574\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 77\n",
            "Norm: 1.03, NNZs: 7, Bias: -0.018355, T: 26488, Avg. loss: 0.209276\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 78\n",
            "Norm: 1.03, NNZs: 7, Bias: -0.018184, T: 26832, Avg. loss: 0.208005\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 79\n",
            "Norm: 1.04, NNZs: 7, Bias: -0.018007, T: 27176, Avg. loss: 0.206761\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 80\n",
            "Norm: 1.05, NNZs: 7, Bias: -0.017824, T: 27520, Avg. loss: 0.205544\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 81\n",
            "Norm: 1.05, NNZs: 7, Bias: -0.017636, T: 27864, Avg. loss: 0.204351\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 82\n",
            "Norm: 1.06, NNZs: 7, Bias: -0.017442, T: 28208, Avg. loss: 0.203183\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 83\n",
            "Norm: 1.06, NNZs: 7, Bias: -0.017243, T: 28552, Avg. loss: 0.202038\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 84\n",
            "Norm: 1.07, NNZs: 7, Bias: -0.017039, T: 28896, Avg. loss: 0.200916\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 85\n",
            "Norm: 1.08, NNZs: 7, Bias: -0.016828, T: 29240, Avg. loss: 0.199817\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 86\n",
            "Norm: 1.08, NNZs: 7, Bias: -0.016614, T: 29584, Avg. loss: 0.198739\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 87\n",
            "Norm: 1.09, NNZs: 7, Bias: -0.016394, T: 29928, Avg. loss: 0.197682\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 88\n",
            "Norm: 1.09, NNZs: 7, Bias: -0.016170, T: 30272, Avg. loss: 0.196645\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 89\n",
            "Norm: 1.10, NNZs: 7, Bias: -0.015941, T: 30616, Avg. loss: 0.195628\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 90\n",
            "Norm: 1.11, NNZs: 7, Bias: -0.015708, T: 30960, Avg. loss: 0.194630\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 91\n",
            "Norm: 1.11, NNZs: 7, Bias: -0.015469, T: 31304, Avg. loss: 0.193651\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 92\n",
            "Norm: 1.12, NNZs: 7, Bias: -0.015227, T: 31648, Avg. loss: 0.192690\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 93\n",
            "Norm: 1.12, NNZs: 7, Bias: -0.014980, T: 31992, Avg. loss: 0.191746\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 94\n",
            "Norm: 1.13, NNZs: 7, Bias: -0.014728, T: 32336, Avg. loss: 0.190820\n",
            "Total training time: 0.13 seconds.\n",
            "Convergence after 94 epochs took 0.13 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(eta0=0.0001, learning_rate='constant', loss='log',\n",
              "              random_state=15, verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w-clf.coef_, b-clf.intercept_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U38-LNUuuJQ6",
        "outputId": "d1d4339a-d78f-44e6-83c6-b6091bae0d7f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.61337223, 0.4797943 , 0.62296646, 0.32708156, 0.36797163,\n",
              "         0.26175656, 0.21081022]]), array([0.24959687]))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pred(w,b, X):\n",
        "    N = len(X)\n",
        "    predict = []\n",
        "    for i in range(N):\n",
        "        z=np.dot(w,X[i])+b\n",
        "        if sigmoid(z) > 0.5: \n",
        "            predict.append(1)\n",
        "        else:\n",
        "            predict.append(0)\n",
        "    return np.array(predict)\n",
        "\n",
        "print(pred(w,b,x_train))\n",
        "#y_train=y_train.to_numpy()\n",
        "y_train=y_train.reshape(pred(w,b,x_train).shape)\n",
        "#print(y_train)\n",
        "print('Train _ Accuracy',1-np.sum(y_train - pred(w,b,x_train))/len(x_train))\n",
        "y_test=y_test.reshape(pred(w,b,x_test).shape)\n",
        "print('Test _ Accuracy',1-np.sum(y_test  - pred(w,b,x_test))/len(x_test))\n",
        "#print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8XAtbU3uMLf",
        "outputId": "a2813fc5-7b67-4d29-8ef4-6d607bc7ae89"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 1 1\n",
            " 1 1 0 1 1 0 0 1 0 0 1 1 0 1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 1 1 0 0 0 1 0 0 0\n",
            " 0 1 0 0 0 0 1 1 1 1 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 0 1 1\n",
            " 1 0 0 1 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 1 1 1 1 0 0 0 1 0 1 1 0 1 0 1 1 0 1\n",
            " 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 0 0 0 0 0\n",
            " 0 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 0\n",
            " 0 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1 1 1 1 1 0\n",
            " 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 0 1 1 1 1\n",
            " 1 1 1 0 1 0 1 1 1 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0\n",
            " 1 1 0 0 1 0 1 0 0 0 1]\n",
            "[1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 1 1\n",
            " 1 1 0 1 1 0 0 1 0 0 1 1 0 1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 1 1 0 0 0 1 0 0 0\n",
            " 1 1 0 0 0 0 1 1 1 1 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 1 1 1 0 1 1\n",
            " 1 0 0 1 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 1 1 1 1 0 0 0 1 0 1 1 0 1 0 1 1 0 1\n",
            " 1 1 0 1 0 1 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 0 0 0 0 1\n",
            " 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 1 1 0 1 1 0 1 0\n",
            " 0 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 0\n",
            " 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 0 1 1 0 0 1 0 1 1 1 0 0 0 1 1 1 1\n",
            " 1 1 1 0 1 0 1 1 1 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0\n",
            " 1 1 0 0 1 0 1 0 0 0 1]\n",
            "0.9912790697674418\n",
            "0.991304347826087\n",
            "[0 1 0 1 1 0 1 1 0 0 1 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 1 1 0 0 0\n",
            " 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0\n",
            " 1 1 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 0 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0\n",
            " 0 0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = np.arange(1, epochs+1, 1)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs, train_loss, label='Train Loss')\n",
        "plt.plot(epochs, test_loss, label='Test Loss')\n",
        "plt.title('Epoch vs Train,Test Loss')\n",
        "plt.xlabel(\"Epoch_no\")\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "print(100*'==')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "wBndkH48ucH-",
        "outputId": "f252a459-bbea-44e9-a66a-0b3eeb1f7e51"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================================================================================================================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cm = confusion_matrix(y_true = y_train , y_pred = pred(w,b,x_train))"
      ],
      "metadata": {
        "id": "By-_XuAl2Uhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## This function the official sklearn function\n",
        "## Refer https://scikit-learn.org/0.18/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            plt.text(j, i, cm[i, j],\n",
        "                horizontalalignment=\"center\",\n",
        "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "metadata": {
        "id": "4yGYH3Oy2Y1_"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ploting the confusion matrix\n",
        "# cm_plot_labels = ['B','M']\n",
        "# plot_confusion_matrix(cm=cm,classes = cm_plot_labels , title = 'Confusion_Matrix')"
      ],
      "metadata": {
        "id": "d8s54dBA2b91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cFw-58QZs5eV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy Plots and Stuff \n"
      ],
      "metadata": {
        "id": "SNNGSB4Vb2CE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qq2Z7Etj6yun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "057fGPgc6x3_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}